[["index.html", "SCI 1031 Visualisation et analyse de données spatiales sous R ", " SCI 1031 Visualisation et analyse de données spatiales sous R 2023-03-07 Bienvenue sur le site du cours SCI 1031! Lentièreté du contenu du cours est disponible en accès libre sur ce site. Les évaluations sont disponibles sur le site web de la TÉLUQ aux étudiantes et aux étudiants inscrits dans ce cours. Avant de débuter le cours, familiarisez-vous avec la structure de ce site en utilisant le menu vertical à gauche. Lisez attentivement la section Présentation avant de vous plonger dans les apprentissages. "],["à-propos-du-cours.html", "À propos du cours", " À propos du cours Présentation Comme son nom lindique, le cours SCI1031 porte sur la visualisation et lanalyse de données spatiales avec le langage de programmation et logiciel libre R. Pourquoi suivre ce cours ? Lintérêt du cours SCI 1031 est lié plusieurs aspects. Tout dabord, nos sociétés sont confrontées à une incroyable augmentation des données spatiales. Cest-à-dire des données qui possèdent une composante spatiale, comme des coordonnées géographiques. Pensons, par exemple, aux données de télédétection récoltées par des satellites et des véhicules aériens télépilotés (drones). Ou encore, aux données échantillonnées par des technologies de notre vie quotidienne qui sont munis dun système de géo-positionnement par satellite (GPS!) intégré comme les téléphones intelligents, les caméras, et les tablettes. Cet accroissement des données spatiales est interrelié avec une explosion dapplications qui dépendent des données spatiales et qui en génèrent dans des domaines aussi variés que le marketing, lévaluation des risques par les compagnies dassurances, la logistique des réseaux de transports, et les études dimpact environnementaux. Ainsi, cette effervescence des données spatiales et de leurs applications entrainement nécessairement une hausse de la demande pour des compétences spécialisées dans la manipulation, la visualisation et lanalyse de données spatiales. Lobjectif général du cours SCI 1031 est donc de permettre aux étudiantes et aux étudiants de développer ces compétences essentielles pour traiter les données spatiales, tant dans leurs études que sur le marché de lemploi. Pourquoi R ? R1 est un logiciel libre et un langage de programmation qui offre un environnement riche permettant de réaliser une multitude de tâches incluant des calculs statistiques, des graphiques scientifiques, de la manipulation de bases de données, et de la modélisation. R est devenu un outil incontournable en sciences des données. La communauté R est constituée non seulement dutilisatrices et dutilisateurs, mais aussi de créatrices et de créateurs. Ceux-ci améliorent constamment les capacités de R par le développement de nouvelles fonctionnalités et de bibliothèques spécialisées qui deviennent accessibles à toute la communauté. Dans les dernières années, plusieurs expertes et experts de lanalyse et de la visualisation de données spatiales se sont affairés à bâtir des bibliothèques simples et efficaces destinées aux traitements des données spatiales. Ces bibliothèques sont mise-à-jour continuellement alors que dautres bibliothèques voient le jour pour répondre à des nouveaux besoins. Un avantage indéniable à utiliser R, en comparaison aux autres outils de visualisation de données spatiales, est sa grande flexibilité. Labondance des bibliothèques permet dutiliser R pour accomplir des opérations diverses. Il est ainsi possible de produire des cartes géographiques de grande qualité avec R et de faire des analyses statistiques spatiales très poussées. Tout cela sans changer de logiciel et en conservant la même syntaxe générale. Objectifs Voici ce que vous serez en mesure de faire à la fin du cours SCI 1031: Identifier les concepts fondamentaux propres à la représentation spatiale. Décrire les types de données spatiales et leurs caractéristiques. Appliquer lusage dopérateurs spatiaux de base à la réalisation danalyses spatiales simples. Créer une carte thématique respectant les règles cartographiques. Appliquer les fonctions de base des principales librairies R destinées à la manipulation, la visualisation et lanalyse de données spatiales. Représenter des données spatiotemporelles. Contenu sommaire Le cours est divisé en 9 modules: Module 1 : Introduction Ce module donne un aperçu de lévolution historique dans la représentation des données spatiales, des premières cartes jusquà lavènement des systèmes dinformation géographiques. Il fait une revue des outils existants pour visualiser et analyser les données spatiales. Il présente aussi les concepts essentiels à létude des données spatiales. Module 2 : Modèles de données spatiales Ce module sintéresse à la façon dont nous représentons les phénomènes spatiaux se déroulant à la surface de la Terre par des données spatiales. Il présente les propriétés des deux types de modèle de données spatiales: les données vectorielles et les données matricielles. Module 3 : Systèmes de coordonnées de référence Ce module porte sur les systèmes de coordonnées de référence. Il explique les concepts mathématiques et cartographiques pour représenter la position des données sur la surface de la Terre. Module 4 : Données vectorielles Ce module se veut une introduction à la bibliothèque R sf. Il présente les fonctions de base pour lire, interpréter et visualiser des données vectorielles. Module 5 : Données matricielles Ce module se veut une introduction à la bibliothèque R raster. Il présente les fonctions de base pour lire, interpréter et visualiser des données matricielles. Module 6 : Cartographie Ce module explique les principes essentiels de la cartographie, des informations indispensables comme la légende, jusquau choix des couleurs. Il présente les fonctions de la bibliothèque R tmap pour créer des projets cartographiques. Module 7 : Manipulation de données vectorielles Ce module présente les fonctions R pour manipuler les attributs de données vectorielles et faire des opérations spatiales sur ces données comme faire des jointures spatiales ou trouver lintersection entre des données. Module 8 : Manipulation de données matricielles Ce module présente les fonctions R pour filtrer les valeurs des données matricielles et faire des opérations spatiales sur ces données tel que découper un raster. Module 9 : Données spatiotemporelles Ce module explique comment manipuler des données spatiales qui possèdent une dimension temporelle. Il présente certaines fonctions des bibliothèques R lubridate et animation. Fonctionnement du cours Organisation des modules Le cours séchelonne sur 15 semaines. La feuille de route constitue un guide pour vous aider à répartir vos apprentissages tout au long de votre cheminement. Les modules sont tous divisés en deux parties: une partie Leçon et une partie Exercices. Pour les modules 1, 2, et 3 La partie Leçon comprend des apprentissages théoriques. Vous apprendrez les concepts de base propres aux données géospatiales. Ces apprentissages sont essentiels avant de se lancer dans lapprentissage des fonctions R spécifiques à la manipulation, lanalyse et la visualisation de données spatiales. La partie Exercices comprend une révision des bases de R (module 1) et une introduction à RMarkdown (module 2 et 3). Vous serez également amenés à mettre en pratique ces apprentissages en répondant à quelques questions. Pour les modules 4, 5, 6, 7, 8, et 9 La partie Leçon comprend des apprentissages théoriques et aussi pratiques: vous serez guidé dans lutilisation de fonctions R et dans la résolution de problèmes. La partie Exercices comprend des questions pour mettre en pratique vos apprentissages. Bien que les réponses aux questions soient disponibles, il est important de tenter dy répondre par vous-mêmes. Les questions des travaux notés et de lexamen sont très semblables à celles des parties Exercices. Apprentissage de R Il est important dorganiser sur votre ordinateur un environnement de travail optimal pour faciliter vos apprentissages. Il est fortement recommandé de créer un répertoire, par exemple SCI1031, dédié exclusivement à ce cours. Dans ce répertoire, créé également un répertoire pour chacun des neuf modules du cours (p. ex. Module1, Module2, , Module9). À chaque module du cours, vous serez amené à utiliser des données sur lesquelles vous pratiquerez des opérations R. Ces données seront fournies dans un dossier zippé à télécharger (Module1_donnees.zip, Module2_donnees.zip, , Module9_donnees.zip). Sauvegarder le dossier de données dans le répertoire correspondant à son module sur votre ordinateur. Il est également recommandé de vous créer un fichier R (ou Rmd) pour chaque module (p.ex. Mod1.R, Mod2.R, , Mod9.R) dans lequel vous pourrez copier-coller les opérations R enseignées. Vous pourrez ainsi vous exercer à utiliser ces opérations et vous assurer de comprendre leur fonctionnement. Il facile de copier les blocs de codes R à partir de la page web en utilisant le bouton dédié à cette fin dans le coin supérieur droit de chaque bloc. FIGURE 0.1: Le bouton supérieur droit vous permet de copier facilement un bloc de codes R. Travaux notés Le cours comprend trois (3) travaux notés (chacun 20%) et un examen final (40%). La date de remise des travaux notés, telle que suggérée dans la feuille de route est flexible: vous ne serez pas pénalisé si vous remettez votre travail après cette date. Toutefois, il est préférable despacer la remise des travaux pour pouvoir bénéficier dune rétroaction de la part de la personne qui corrige. Noter que vous devez faire lexamen au plus tard au cours de la dernière semaine. Il sagit dun examen à faire chez soi. Lexamen dure 3 heures mais vous avez 3 jours (72 heures) pour remettre vos réponses à partir du moment où vous lentamez. Les consignes, les données à utiliser, et les gabarits de réponses pour les travaux notés et lexamen sont disponibles sur la page web du cours sur le site de la TÉLUQ. Seuls les étudiants inscrits à la TÉLUQ ont accès aux évaluations. Rétroaction Le mode de communication le plus efficace pour rejoindre la personne qui vous encadre est le courriel. Si cela savère nécessaire une rencontre zoom ou un appel téléphonique pourront être planifiés. Le sujet de votre courriel doit contenir le sigle du cours. De plus, vous devez clairement vous identifier dans votre courriel: nom, prénom, numéro détudiant. La personne qui vous encadre, encadre beaucoup détudiantes et détudiants, et cela dans plusieurs cours! Si votre courriel comporte une question sur une ou des opérations R qui vous causent problème, vous devez absolument inclure toutes les commandes R depuis limportation des données jusquau problème rencontré. Il est recommandé denvoyer un fichier R avec vos commandes pour faciliter lintervention de la personne qui vous encadre. Sauf exception (en cas de maladie, de vacances ou de déplacements dans le cadre de travaux de recherche) vous recevrez une réponse à votre courriel dans les 48h. Les travaux corrigés seront remis au plus tard deux semaines suivant leur dépôt mais généralement dans un délai dune semaine. Feuille de route Modules Semaines 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Module 1 Introduction Module 2 La représentation spatiale Module 3 Systèmes de coordonnées de référence Module 4 Données vectorielles Module 5 Données matricielles Travail noté 1: 20 % X Module 6 Cartographie Travail noté 2: 20 % X Module 7 Opérations sur les données vectorielles Module 8 Opérations sur les données matricielles Travail noté 3: 20 % X Module 9 Opérations sur les données spatio-temporelles Examen: 40 % X Crédits Équipe Direction pédagogique, conception et rédaction: Élise Filotas Soutien à la conception: Kevin Cazelles et Steve Vissault Direction multi-média: Mathieu Corriveau et Élodie Bussières Conception graphique: Marie-Sol Lapointe Intégration: Elise Filotas, Kevin Cazelles et Simon Gaudreau Reproduction du contenu Vous êtes autorisé à copier, distribuer et communiquer le matériel contenu sur ce site selon la licence Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0). Contact Élise Filotas Je suis professeure au Département Science et technologie de la TELUQ en écologie quantitative et je suis responsable du cours SCI 1031. Vous pouvez me rejoindre à ladresse suivante: elise.filotas@teluq.ca Consultez mon site web pour en savoir plus sur ma recherche. R est soutenu par le R Core Team et la R Foundation for Statistical Computing: www.r-project.org "],["ressources.html", "Ressources", " Ressources Travaux notés Le cours comprend trois (3) travaux notés (chacun 20%) et un examen final (40%). La date de remise des travaux notés, telle que suggérée dans la feuille de route est flexible: vous ne serez pas pénalisé si vous remettez votre travail après cette date. Toutefois, il est préférable despacer la remise des travaux pour pouvoir bénéficier dune rétroaction de la part de la personne qui corrige. Noter que vous devez faire lexamen au plus tard au cours de la dernière semaine. Il sagit dun examen à faire chez soi. Lexamen dure 3 heures mais vous avez 3 jours (72 heures) pour remettre vos réponses à partir du moment où vous lentamez. Les consignes, les données à utiliser, et les gabarits de réponses pour les travaux notés et lexamen sont disponibles sur la page web du cours sur le site de la TÉLUQ. Seuls les étudiants inscrits à la TÉLUQ ont accès aux évaluations. Données Données du cours Les liens suivants vous dirigerons directement vers les données utilisées pour chaque module Module 1 Module 3 Module 4 Module 5 Module 6 Module 7 Module 8 Module 9 Autres sources Cette rubrique répertorie différentes bases de données qui contiennent des données spatiales. Données Québec Données ouvertes du Gouvernement du Canada Répertoire de données spatiales de lUniversité Laval Répertoire de données spatiales de lUniversité Sherbrooke Répertoire de données spatiales de lUniversité du Texas à Austin Données de la Banque Mondiale Données de la Commission Européenne sur lurbanisation de la planète Données de déplacement UBER Vous êtes tombé sur une base de données intéressante qui ne figure pas plus bas? Partagez avec moi votre découverte et je lajouterai à cette liste. Ressources R Vous trouverez ici des liens vers différentes ressources R. Documentation générale R Site officiel de R: CRAN An introduction to R Forum de la communauté RStudio Introduction to R R for Data Science Documentation R-géospatial Geocomputation with R Introduction to R for Geospatial Data Intro to GIS and Spatial Analysis Spatial Data Science with applications in R Spatial Data Science with R Les bibliothèques R Outil de recherche des bibliothèques de CRAN sf raster mapview tmap animation lubridate Documentation R-Markdown Aide-mémoire Syntaxe de base Guide de référence Livre dastuces Syntaxe Pandoc Markdown (en français) Utilisation de R Markdown pour la création de documents : PDF HTML Word Tufte handout (Pdf) R Package Vignette (Html) Utilisation de R Markdown des présentations : Beamer ioslide Slidy Dérivés de R Markdown bookdown blogdown Les couleurs dans R Document pdf des couleurs dans R. Liste des couleurs par leur nom. Les couleurs dans ggplot2 Palettes de couleurs ColorBrewer Palettes de couleurs Viridis Références "],["intro.html", "Module 1 Introduction", " Module 1 Introduction Ce module est une introduction au cours que vous vous apprêter à suivre. Dans la section leçon, nous discuterons de lévolution historique de la visualisation des données spatiales, des premières cartes jusquà lavènement des systèmes dinformation géographique. Nous ferons une revue des outils existants pour visualiser et analyser les données spatiales. Finalement, nous présenterons quelques concepts de base essentiels à létude des données spatiales. À la fin de ce module vous saurez: Décrire les changements dans la représentation géographique au cours de lhistoire. Définir ce quest la géomatique. Décrire les propriétés générales des systèmes dinformation géographique (SIG). Donner des exemples dapplication des SIG. Nommer des outils et logiciels de visualisation et danalyse géospatiale. Décrire les avantages offerts par le logiciel R. Définir les concepts de bases dans létude des données spatiales : léchelle spatiale et léchelle cartographique, la distance, la contiguïté, linteraction spatiale et le voisinage. La section exercice est une brève introduction au logiciel R. Vous apprendrez à installer R et RStudio et vous vous familiariserez avec les notions importantes de lenvironnement de travail R. Vous réviserez également les concepts et les fonctions de base pour utiliser R. Cette section se conclue par un petit exercice pour mettre en pratique les concepts R enseignés. "],["lecon_intro.html", "1.1 Leçon", " 1.1 Leçon 1.1.1 Les données spatiales dhier à aujourdhui Les cartes anciennes La représentation géographique est une description de lemplacement des éléments naturels (cours deaux, montagnes, forêts, etc.) et artificiels (routes, ponts, bâtiments, etc.) au sein dun territoire. Cette représentation peut être détaillée ou abstraite, et décrire un espace restreint tout comme un vaste territoire. La cartographie est utilisée depuis lAntiquité pour répondre à de multiples besoins comme celui dillustrer la distribution spatiale des ressources, de définir les frontières et lappartenance des territoires ou encore de guider les déplacements. La carte de la cité babylonienne de Nippur, datant denviron 1500 av. J.-C., constitue probablement la plus vieille carte connue tracée à léchelle (Figure 1.1). Dessinée sur une tablette dargile, cette carte représente, notamment, un réseau dirrigation destiné à lagriculture. FIGURE 1.1: La carte de Nippur tracée sur une tablette dargile. Source : Mary Harrsch. Les cartes reflètent la compréhension et la perception quont le ou leurs auteurs du territoire. Le géographe et historien grec Hécatée de Milet, qui a vécu au 5ième siècle av. J.-C., aurait conçu une des premières cartes du monde. Cette dernière est circulaire et place la Méditerranée en son centre (Figure 1.2). FIGURE 1.2: Une reconstitution de la carte du monde dHétacée. Source : Arnaud, P. (2009). Les cartes antiques. Larchéotherma. Un regard sur les cartes anciennes du monde est révélateur de lévolution des connaissances en géographie (Figure 1.3 et Figure 1.4). Par le choix des éléments représentés et limportance visuelle accordée à certains éléments plutôt que dautres, les cartes témoignent aussi des valeurs et des croyances qui animaient les sociétés qui les ont produites. FIGURE 1.3: La carte du monde de Claude Ptolémée. Cet astronome, mathématicien et géographe grec du 1er siècle est lauteur du Manuel de géographie. La carte illustrée ci-dessus a été reconstituée par le cartographe Nicolaus Germanus en 1467, qui sest intéressé à moderniser et vulgariser les travaux de Ptolémée. Source: https://archives.fbi.gov/archives/news/stories/2007/november/stolenmaps_110807. FIGURE 1.4: Carte du nouveau monde de Sebastien Münster. Ce cartographe, astronome et mathématicien allemand, connu, entre autres pour son uvre Cosmographia Universalis a produit cette carte en 1552. Source : https://digital.library.yorku.ca/islandora/object/yul:1153586. Pour ceux et celles intéressés aux cartes historiques, la figure 1.5 présente des cartes de Montréal produites à différents moments depuis la colonisation. Ces cartes démontrent lévolution dans lorganisation du territoire de lîle de Montréal et aussi dans le rendu visuel des cartes. FIGURE 1.5: Représentations de Montréal en 1556, 1645, 1758, 1843, 1897, 1920, 1960, et 1982 (dans lordre allant de gauche à droite et de haut en bas). Sources: Archives Montréal. À partir du 19e siècle, on commence à utiliser la représentation géographique afin dexplorer les relations entre loccurrence de certains phénomènes et leur localisation. Cest le début de lanalyse spatiale. Un exemple bien connu est celui de lanalyse réalisée en 1854 par le docteur anglais John Snow pour comprendre la propagation dune épidémie soudaine de choléra dans le quartier Soho de Londres. John Snow doutait de la théorie en vigueur à lépoque voulant que les maladies telles le cholera ou la peste soient transmises par linhalation démanations malsaines (appelées des miasmes  des mauvais airs). Il supportait plutôt lhypothèse que le choléra se développe par lingestion deau impropre. Il cartographia les lieux de résidence des personnes infectées et observa quils se trouvaient à proximité de la pompe à eau de Broad Street (Figure 1.6. Cette dernière puisait son eau dune section polluée de la Tamise. Il sut convaincre les autorités de fermer la pompe, ce qui stoppa lépidémie. John Snow est perçu aujourdhui comme un des pionniers de lépidémiologie moderne. FIGURE 1.6: Reconstitution de la carte de lépidémie de cholera créée par John Snow. Chaque barre rouge représente une personne infectée. Les pompes à eau sont illustrées en vert. Source: Wikipedia. La géomatique Larrivée de linformatique et des données numériques viennent transformer la cartographie traditionnelle et la façon de traiter linformation géographique. Dans les années 1960, le terme « géomatique », qui est une contraction entre les mots géographie et informatique, est proposé pour désigner cette nouvelle discipline. On définit la géomatique comme « lensemble des connaissances et technologies nécessaires à la production et au traitement des données numériques décrivant le territoire, ses ressources ou tout autre objet ou phénomène ayant une position géographique. »2 En effet, les géographes ou autres utilisateurs de données spatiales doivent maintenant composer avec des données numériques diverses acquises par la photographie aérienne et satellitaire, les outils topographiques électroniques ou munis de GPS, la numérisation de documents papiers, etc. De nos jours, la cartographie a laissé place aux systèmes dinformations géographiques (SIG). Un SIG est un système informatique servant à acquérir, gérer, analyser, et visualiser des données géographiques numériques dans le but détudier un phénomène se produisant sur la Terre. Nous pouvons donc utiliser un SIG pour produire des cartes, mais également pour intégrer des données multi-sources (cartes, photos, images, ), pour réaliser des requêtes et visualiser des résultats, ou encore faire des analyses spatiales (Figure 1.7). FIGURE 1.7: Les différents éléments qui composent un SIG. Source: image récupérée le 6 décembre 2021 à https://bookdown.org/tep/gisbooklet/introduction-to-gis.html. Un SIG est composé dun ordinateur, de données numériques, et dun ou plusieurs logiciels spécialisés. De plus, un SIG doit être développé par du personnel qualifié et pouvoir servir à des utilisatrices ou des utilisateurs. Les SIG font maintenant partie de notre vie quotidienne. Pensez par exemple à Google Map, un des SIG les plus utilisés. Ce dernier permet de calculer des itinéraires, de localiser des services près dune adresse, et de visualiser une localisation par loutil « Street View ». Plusieurs services offerts aux individus sont aussi dotés dune interface SIG, comme la plateforme de vélos en libre-service BIXI, ou encore les sites immobiliers pour la vente ou la location de logement (Figure 1.8). FIGURE 1.8: Exemples de SIG dans notre vie quotidienne. Google Map affiche les services autour dune adresse. Lapplication BIXI permet de trouver les bornes et les vélos accessibles. Source: image récupérée le 6 décembre 2021 à https://journaldesvoisins.com/nouvelles-stations-bixi-dans-ahuntsic-cartierville/. Loutil daffichage de DuProprio permet didentifier les résidences à vendre dans un secteur donné. Les SIG sont surtout de puissants outils pour visualiser et diffuser de linformation et sont de plus en plus utilisés pour faciliter la prise de décisions dans divers contextes. Nommons quelques exemples parmi les multiples domaines dapplication des SIG : Logistique des transports : connaître létat du réseau routier, les chantiers de construction, les accidents et le trafic, pour planifier des trajets ou des travaux futurs. FIGURE 1.9: Suivi de létat du réseau routier par Transport Québec. Source: https://www.quebec511.info/fr/Carte/. Études sociodémographiques : cartographier des indices de défavorisation qui servent au gouvernement à répartir de façon équitable les ressources financières dédiées à léducation. FIGURE 1.10: Atlas de défavorisation du Ministère de lÉducation et de lEnseignement supérieur du Québec. Source: https://infogeo.education.gouv.qc.ca/public/Atlas_Defavorisation/. Évaluation des risques : identifier les risques dinondation dun secteur pour déterminer la couverture dassurance requise pour une habitation. FIGURE 1.11: Cartographie interactive des zones inondables développée par le Ministère de lEnvironnement et de la Lutte contre les changements climatiques du Québec. Source: https://geoinondations.gouv.qc.ca/. Gestion des risques : surveiller les risques journaliers dincendies de forêt pour déterminer les mesures préventives à adopter et les ressources nécessaires pour assumer la suppression de feux. FIGURE 1.12: Cartographie des risques dincendies de forêt mise à jour quotidiennement par la Société de protection des forêts contre le feu (https://sopfeu.qc.ca/cartes/). Source : image récupérée de https://www.rcinet.ca/. Gestion des ressources naturelles : cartographier la distribution des peuplements forestiers et leurs caractéristiques (composition essences, âge, sol, etc.) pour déterminer les futures récoltes de bois. FIGURE 1.13: Cartographie des peuplements forestiers et de leurs caractéristiques par le Ministère des Forêts, de la Faune et des Parcs du Québec. Source: https://www.foretouverte.gouv.qc.ca/. Évaluation foncière : représenter les limites géographiques des cadastres et identifier la valeur des terrains et des bâtiments pour projeter les revenus municipaux provenant des taxes municipales ou pour préparer une vente immobilière. FIGURE 1.14: Zonage et évaluation foncière de la municipalité de Mont-Laurier dans la MRC dAntoine-Labelle (http://geo.mrc-antoine-labelle.qc.ca/sigimweb/). Géomarketing : mener une étude de marcher qui évaluera comment la clientèle visée par une entreprise ainsi que les entreprises concurrentes sont distribuées dans le secteur géographique convoité. FIGURE 1.15: Géomarketing pour les études de marché. Source : https://www.geopoint.pt/en/retalho/. La science des données La science des données est un domaine pluridisciplinaire qui regroupe les méthodes scientifiques et linfrastructure permettant dextraire les connaissances densembles de données. La science des données utilisent notamment les approches dintelligence artificielle (tels lapprentissage automatique et lapprentissage profond) ainsi que linfonuagique (p. ex. les serveurs, le stockage de données, et les logiciels disponibles via internet) pour dégager des tendances au sein de données volumineuses ou complexes et ainsi solutionner des problèmes diverses. Les applications de la science des données se sont multipliées devant la disponibilité de données massives et le besoin de les analyser. Ces applications incluent maintenant des secteurs aussi variés que la santé, le commerce et lastrophysique. Depuis les années 2010, nous observons une convergence entre la géomatique et la science des données. En effets, les concepts et les outils développer dans ces domaines traditionnellement distincts sont mis à profit afin de pouvoir gérer, analyser et visualiser un nombre de grandissant de données spatiales. Laugmentation fulgurante des données spatiales est associée à plusieurs avancées en technologie des capteurs et des communications (Lee and Kang 2015). Ces développements ont permis de diversifier les appareils capables dacquérir des données géoréférencées et de produire des appareils accessibles à tous et mobiles (penser à vos téléphones cellulaires!). Ces développements ont également permis de connecter en réseau les capteurs de données, et daccroître la précision des mesures ainsi que leur suivi en temps réel. Ces avancées technologiques ont donc suscité (et continuent de susciter) lémergence de nouvelles applications reposant sur lutilisation de données spatiales. Par exemple, les données de géolocalisation, et même les messages sur les médias sociaux peuvent faciliter le travail des gouvernements lorsquils doivent fournir efficacement une aide appropriée suivant des évènements tels des accidents. Dans le contexte de la pandémie de COVID-19, les données sur la distribution des cas ont servis, entre autres, à prendre des décisions sur les règles de confinement à adopter selon le nombre de cas par régions. FIGURE 1.16: Carte illustrant la distribution des cas au Canada. Ce portail SIG est fourni par la compagnie ESRI Canada et est disponible sur le site suivant : https://ressouces-fr-covid19canada.hub.arcgis.com/. Dans ordre didées similaires, lapplication Alerte COVID du gouvernement canadien, qui a pour objectif de limiter la propagation de la maladie, permet aux abonnés dêtre informés si une tierce personne ayant reçu un résultat positif sest trouvée dans leur proximité dans les 14 derniers jours. En environnement les applications des données spatiales sont nombreuses. Par exemple, les colliers-GPS portés par des mammifères permettent de mieux comprendre le déplacement des individus appartenant à une espèce menacée et ainsi de mieux protéger leur habitat3. FIGURE 1.17: Carte illustrant les migrations printanières et automnales de caribous de la sous-population de la Rivière-aux-Feuilles dans le Nord du Québec. Chaque ligne représente le déplacement dun individu suivi par satellite. Ces données ont été acquises aux cours des années 2009-2011 dans le cadre du projet Caribou Ungava. Source : Caribou Ungava, Photo : Steeve Côté. Images récupérées le 10 décembre 2021 à https://www.canada.ca/fr/environnement-changement-climatique/services/registre-public-especes-peril/evaluations-rapports-situations-cosepac/caribou-certaines-populations-2017.html. Les observations par des professionnels ou même par des citoyens peuvent aussi servir à cartographier la présence danimaux et aider à déterminer leurs aires de répartition. Par exemple, le programme ebird développé par le Cornell Lab of Ornithology et la National Aubudon Society consiste en une immense base de données dobservation doiseaux à travers le monde auxquelles tous peuvent contribuer en identifiant lespèce, la localisation et le nombre dindividus repéré. En date de mai 2021, ebird contenait plus dun milliard dobervations doiseaux soumises par environ 700 mille participants4. FIGURE 1.18: Carte illustrant la distribution du Roitelet à triple-bandeau produite à partir des données dobservation de ebird. Le mauve indique les lieux où lespèce est présente à lannée, le rouge, durant la période de reproduction, le bleu, durant les périodes de non-reproduction, le jaune durant les saisons de pré- et post-reproduction, et le gris les lieux dabsence ou dobservations rares. Source : https://ebird.org/science/status-and-trends/range-maps - Illustration © Hilary Burn/Lynx Edicions. Les services basés sur la géolocalisation aussi sont de plus en plus important dans notre économie. Lindustrie du commerce de détails, de la restauration, du tourisme, et du transport profitent tous dapplications géo-dépendantes. Pensez par exemple à Uber, Dashdoor, Trip Advisor et même les applications de rencontre comme Tinder. De tels services permettent, entre autres, de signaler des offres aux consommateurs en fonction de leur position. De plus, les données spatiales peuvent servir à identifier des intérêts locaux pour certains produits et ainsi permettre aux entreprises daméliorer lefficacité de leur chaîne dapprovisionnement. FIGURE 1.19: Carte illustrant la position des consommateurs et le nombre de ventes dune entreprise commerciale en Espagne. Carte tirée du site web de la compagnie Log-hub offrant des services basés sur lanalyse de données spatiales pour améliorer les chaînes dapprovisionnement. Source : https://log-hub.com/my-maps-platform/. Les utilisateurs des données spatiales se limitaient historiquement aux organismes gouvernementaux. Or, la multiplication des applications dans différents secteurs a augmenté le besoin pour des logiciels de visualisation et danalyse de données spatiales et aussi pour une main duvre qualifiée capable dopérer ces outils. 1.1.2 Les outils et logiciels de visualisation et danalyse géo-spatiale Dans le cadre de ce cours, nous utiliserons le logiciel et langage de programmation R pour réaliser des tâches de visualisation et danalyse de données spatiales. Or, il existe plusieurs autres logiciels et il est important de savoir où R se situe par rapport aux autres options disponibles dans ce paysage géo-spatial5. Les logiciels commerciaux Il existe plusieurs logiciels commerciaux de géomatique. Ces logiciels sont relativement dispendieux et généralement seulement les entreprises qui offrent des services spécialisés en géomatique ou les ministères, certaines villes et les universités peuvent se procurer ces licences. ArcGIS : est la plateforme principale de la compagnie ESRI (Environmental Systems Research Institute). Créée en 1999 sous le nom ArcMap, cette application est maintenant vendue sous le nom ArcGIS Pro. ESRI offre également dautres plateformes dont ArcGIS Online, un logiciel de cartographie web, et ArcGIS Developer pour les développeurs. MapInfo: est la plateforme de la compagnie Precisely (autrefois Pitney Bowes Software et MapInfo Corporation). Créée en 1995, cest une des premières plateformes à avoir vu le jour. Hexagon Geospatial Power Portfolio: est une plateforme qui comprend divers outils géo-spatiaux dont ERDAS reconnu pour la manipulation dimages de télédétection. Manifold: est une plateforme qui se démarque par sa rapidité de par son utilisation de traitements en parallèle et GPU. Les logiciels libres daccès Il existe une offre de plus en plus intéressante de logiciels libres daccès. La Fondation Open Source Geospatial (OSGeo), une organisation non-gouvernementale fondée en 2006, a pour objectif de soutenir et promouvoir le développement de codes et de logiciels libres en géomatique. Elle chapeaute plusieurs projets comme des bibliothèques spécialisées, des applications SIG mobiles ou bureautiques, et des applications pour la gestion de données spatiales. Voici quelques exemples : QGIS: est une application SIG gratuite et de source libre. Elle est écrite en Python mais possède plusieurs interfaces écrite en R, dont RQGIS. GRASS GIS: est un des projets fondateurs de lOSGeo quon appelle communément GRASS (Geographic Resources Analysis Support System). Cette application libre permet la gestion, le traitement, lanalyse et la visualisation de données spatiales, ainsi que le traitement dimages et la modélisation. Elle est utilisée par des entreprises commerciales et dans les milieux universitaires et gouvernementaux. GDAL: pour Geospatial Data Abstraction Library est une bibliothèque qui permet de lire des données spatiales en formats vectoriel et matriciel6. Plusieurs logiciels, libres et commerciaux, utilisent cette bibliothèque dont QGIS, GRASS GIS, ArcGIS, Google Earth et aussi R. PostGIS: est une extension pour les données spatiales de PostgreSQL, un système de source libre pour la gestion de base de données relationnelle et objet. Les services dinfonuagique Les services infonuagiques sont des services de stockage et de traitement de données externalisés sur des serveurs distants auxquels les utilisatrices et les utilisateurs peuvent accéder via internet. Google Earth Engine: est une plateforme de calcul infonuagique de Google qui permet le traitement de données géo-spatiales. Celle-ci donne accès à un large catalogue dimages satellitaires (p. ex. de Landsat et Sentinel-2) et à la puissance de calcul requise pour les analyser. Google Earth Engine permet ainsi dexplorer les changements sur la surface de la Terre à léchelle planétaire. Il a été utilisé pour visualiser lévolution de diverses problématiques environnementales comme la perte de couvert forestier. Google Earth Engine est gratuit pour des utilisations académiques et de recherche et une version payante existe pour les utilisations commerciales. Une interface de programmation existe également pour les développeurs, Earth Engine API. ArcGIS Online: est la plateforme web dArcGIS, le logiciel commercial présenté plus haut. Cette plateforme donne accès à des milliers de cartes. PanGEO: est une plateforme de source libre, et collaborative, pour le développement dapplications pour les analyses géo-spatiales à grande échelle. Sepal: est une plateforme gratuite pour lanalyse dimages satellitaires qui repose sur Google Earth Engine et des logiciels de source libre comme Python, R. Sepal est un multiples outils quoffre OpenForis, un projet conçu par la FAO (Organisation des Nations Unis pour lalimentation et lagriculture) pour permettre aux pays de faire le suivi de leurs ressources naturelles. Kepler: est également une plateforme de source libre pour les analyse géo-spatiales à grande échelle. Elle est supportée par la compagnie Uber. Planet: est une plateforme commerciale pour les analyses géo-spatiales. Les langages de programmation pour lanalyse géospatiale La majorité des logiciels dinformation géographique reposent sur des interfaces graphiques élaborées où les outils et les fonctions sont accessibles par des menus et des boutons. Or, le mode « pointer-cliquer» de ces interfaces nest pas idéal lorsquon veut sassurer que nos analyses soient facilement reproductibles  un aspect crucial de la recherche scientifique est en effet la reproductibilité. Cest pour cette raison que lutilisation de langages de programmation pour réaliser des analyses et des visualisations de données spatiales est bénéfique et de plus en plus populaire. Lutilisation de lignes de commandes plutôt que dinterfaces graphiques permet également dautomatiser des tâches que lon désire répéter plusieurs fois dans une analyse ou encore de réutiliser des blocs de code dans différents projets. De plus, un code se partage facilement et peut être ainsi amélioré par dautres contributeurs ou contributrices. Il existe plusieurs bibliothèques géo-spatiales dans les langages de programmation à usage général comme C++ et Java. Cependant, la courbe dapprentissage est grande pour ces langages et les efforts requis sont disproportionnés pour les usagers qui comptent utiliser leurs fonctionnalités de façon limitée seulement. En revanche, les langages interprétés7, comme R et Python, sont beaucoup plus simples à apprendre et à utiliser. Ces deux langages possèdent maintenant leur propre ensemble de bibliothèques danalyse et de visualisation de données spatiales. Ce site documente les bibliothèques utiles en Python. Dans le cadre de ce cours, nous utiliserons R en combinaison avec RStudio qui est un environnement de développement (en anglais « integrated development environment », IDE). Linterface RStudio facilite et rend convivial lutilisation de R. Elle permet, entre autre, de créer des fichiers de code dextension .R ou .Rmd que vous pouvez réutiliser et modifier. 1.1.3 Les bibliothèques géo-spatiales de R Il existe un nombre important de bibliothèques R (« packages » en anglais) qui se concentrent sur différents aspects de la manipulation, de lanalyse et de la visualisation de données spatiales. Dautres bibliothèques plus générales, comme base R et ggplot2 peuvent aussi être utilisées sur des données spatiales pour accomplir certaines fonctions. La communauté R est très active, de nouvelles bibliothèques sont régulièrement offertes alors les bibliothèques existantes sont mises à jour et améliorer constamment. Ceci est également vrai pour la « communauté R spatiale ». R étant un projet ouvert, tout le monde peut créer des bibliothèques, ou signalez des problèmes afin daméliorer des bibliothèques existantes. Vous aussi! Vous trouverez sur le site de CRAN (The Comprehensive R Archive Network) une page dédiée aux bibliothèques R pour lanalyse géo-spatiale. Voici quelques bibliothèques importantes que nous utiliserons dans ce cours : sf: bibliothèque incontournable offrant de nombreuses fonctions pour lire et manipuler des objets spatiaux vectoriels de différentes classes. sf est relativement récente et est venue remplacer les bibliothèques sp, rgeos et les parties vectorielles de rdgal. raster: bibliothèque offrant de nombreuses fonctions pour lire et manipuler des objets spatiaux matriciels. Notez que la bibliothèque terra remplacera peut-être raster dans les années à venir. spacetime: bibliothèque offrant des fonctions pour manipuler des objets spatiaux-temporels. mapview: bibliothèque offrant des fonctions pour visualiser rapidement et de façon interactives des données spatiales. tmap : bibliothèque offrant des fonctions plus flexibles pour visualiser des données spatiales. Elle utilise un style qui sapparente à ggplot2. 1.1.4 La pensée géographique Nous allons conclure ce module en définissant certains concepts essentiels à létude des phénomènes spatiaux. Échelle spatiale Le terme échelle spatiale réfère à deux concepts : létendue physique dun phénomène spatial (Figure 1.20) et la résolution (Figure 1.21), cest-à-dire la taille de lunité de mesure, ou encore la précision, avec la laquelle on étudie ce phénomène (Dale and Fortin 2014). FIGURE 1.20: Létendue physique dun phénomène spatial. FIGURE 1.21: La résolution à laquelle on observe un phénomène spatial. Échelle cartographique Sur une carte géographique, léchelle représente le rapport entre une distance mesurée sur la carte et cette distance mesurée sur la Terre (Turner and Garder 2015). On exprime généralement léchelle par une fraction. Par exemple, 1/10 000, signifie quun cm sur la carte représente 10 000 cm sur le terrain (ou 10 m). Alors que 1/1 000 000 signifie quun cm sur la carte représente 1 000 000 cm sur le terrain (soit 1 km). Ainsi, plus léchelle cartographique est petite, plus la résolution est grossière. Inversement, plus léchelle cartographique est grande, plus la résolution est fine. Distance La distance est généralement décrite comme la distance à vol doiseau entre deux entités spatiales dintérêt. Dans ce cas, on la calculera par la distance Euclidienne (équation). Cependant, il faut savoir que le concept de distance peut parfois intégrer des facteurs liés à la capacité de se déplacer dun point à lautre (OSullivan and Unwin 2010). Par exemple, la distance entre deux villes, accessibles par voie terrestre, réfère généralement à la distance du trajet parcouru en suivant les routes qui séparent les deux villes. Cette distance sera bien différente de la distance Euclidienne. Lorsque vous utilisez Google Maps pour calculer un itinéraire, vous savez que la distance du trajet dépendra également du moyen de locomotion choisi. De façon similaire, la distance parcourue par un animal dépendra du trajet utilisé pour éviter des obstacles ou des conditions environnementales peu favorables (p. exemple labsence de couvert forestier). Finalement, pour le calcul de grandes distances, il peut être nécessaire de considérer la courbure de la surface terrestre. Dans de telles situations la distance Euclidienne doit être remplacée par une équation plus complexe. Contiguïté La contiguïté, aussi appelée ladjacence, indique la proximité de deux ou plusieurs objets spatiaux. Cest, en quelque sorte, une mesure binaire de distance : lobjet A est près, oui ou non, de lobjet B (OSullivan and Unwin 2010). La contiguïté est donc un concept relatif à la façon dont on détermine si un objet est proche dun autre. Par exemple, deux pays qui partagent une même frontière pourront être qualifiés de contiguës. Dans dautres cas, nous pourrions considérer une distance maximale fixe (p. ex. 50 km) et déterminer que tous les objets (p.ex. des villes) séparés par une distance moindre que la distance fixée sont contiguës. Nous pourrions également déterminer que les cinq (ou un autre nombre fixe) objets les plus proches dun autre sont contiguës peu importe la distance qui les sépare. Interaction Linteraction spatiale entre deux objets repose également sur le concept de distance. Elle exprime la notion intuitive que tous les objets sont en interaction mais ceux qui sont proches ont plus de chance dinteragir que ceux qui sont distants. On réfère à cette notion comme étant la « première loi » de la géographie et on lattribut au géographe Waldo Tobler. En anglais, cette loi sénonce ainsi : « Everything is related to everything, but near things are more related than distant things » (Tobler 1970). Linteraction entre deux objets se mesure généralement par une fonction allant de 0 (aucune interaction) à 1 (interaction maximale). Cette fonction est inversement proportionnelle à la distance séparant les deux objets de sorte que plus la distance est petite plus linteraction est forte (OSullivan and Unwin 2010). Dautres facteurs peuvent influencer la façon dont on mesure linteraction comme la taille des objets. Linteraction est étroitement liée aux concepts de dépendance spatiale et dautocorrélation spatiale (Dale and Fortin 2014). La dépendance spatiale est labsence dindépendance entre des objets rapprochés. Puisque lassomption dindépendance des données est requise pour réaliser de nombreux tests statistiques paramétriques il est important de pouvoir déterminer la présence de dépendance spatiale. Lautocorrélation spatiale réfère à la corrélation spatiale entre les valeurs dune même variable. Par exemple, la température à un emplacement sera corrélée avec la température à des emplacements voisins. Il existe différentes mesures pour déterminer la dépendance et lautocorrélation spatiale. Dans le cadre de ce cours, nous naborderons pas ces mesures plus poussées danalyse spatiale. Voisinage Le voisinage est aussi un concept relatif qui peut se décrire de différentes façons. Un voisinage peut être défini en fonction dun objet spatial particulier. Le voisinage est alors constitué des objets spatiaux qui sont adjacents à lobjet spatial dintérêt. Par exemple, les cadastres limitrophes dune propriété donnée, ou encore les bâtiments dans un rayon de 500 m autour dune borne fontaine. Un voisinage peut aussi prendre un sens qui sapparente à la notion de quartier. Un voisinage est alors défini comme une région qui entoure des objets spatiaux similaires, et qui se distincte dautres régions qui circonscrivent également des objets similaires. Définition donnée par le Département des sciences géomatiques de lUniversité Laval - https://www.scg.ulaval.ca/la-geomatique-cest-quoi, consultée le 11 novembre 2021 Allez jeter un coup dil au projet Voyageur Wolf Project, qui suit le déplacement de loups dans le nord du Minnesota grâce à des colliers GPS. On peut y voir des animations démontrant le déplacement dindividus de différentes meutes. Source: https://ebird.org/news/global-big-day-2021-reaches-new-heights. Le contenu de cette sous-section est adapté du cours Introduction to Geospatial Concepts : The Geospatial Landscape (Wasser et al. (consulté le 1er mars 2020)) de lorganisme Data Carpentry. Data Carpentry développe et offre des formations variées et spécialisées sur le traitement et lanalyse de données. Ses formations sadressent surtout aux chercheuses et chercheurs scientifiques, mais peuvent être consultées par quiconque car leur matériel est libre daccès. Nhésitez donc pas à y jeter un coup dil. Nous verrons les concepts de données vectorielles et matricielles au Module 2 portant sur les Modèles de données spatiales. Un langage de programmation interprété est un langage qui fait linterprétation du code directement au moment de lexécution sans exiger que lutilisateur ou lutilisatrice le compile préalablement. Allez voir cet article de Wikipédia pour en connaître davantage. "],["ex_intro.html", "1.2 Exercices", " 1.2 Exercices Le cours SCI 1031 est dédié à lapprentissage des bibliothèques et des fonctions pour manipuler, visualiser et analyser des données spatiales. Il est donc important de vous assurer de posséder les acquis de base en R pour poursuivre votre apprentissage vers des notions plus complexes. Cette section est divisée en trois parties. Dans la partie Démarrage vous apprendrez à installer R et RStudio et vous vous familiariserez avec les notions importantes de lenvironnement de travail R. Dans la partie Intro à R vous réviserez les concepts et les fonctions de base pour utiliser R. Finalement, dans la partie À vous de jouer!, vous réaliserez un exercice pour mettre en pratique les concepts enseignés. Une grande partie du contenu de cette section est tiré du livre numérique An Introduction to R (Douglas et al. 2022). 1.2.1 Démarrage Installer R Nous possédez déjà R sur votre ordinateur? Nous recommandons tout de même dinstaller la plus récente version afin davoir la version la plus à jour pour être compatible avec les bibliothèques qui seront utilisées dans le cours. Windows Aller sur le site CRAN et cliquer sur le lien Download R for Windows Cliquer maintenant sur install R for the first time Cliquer sur Download R (numéro de la version) for Windows pour télécharger le fichier *.exe Exécuter le fichier *.exe MacOS Aller sur le site CRAN et cliquer sur le lien Download R for macOS Cliquer sur le lien compatible avec votre système dopération pour télécharger le fichier *.pkg Double-cliquer sur le fichier *.pkg Installer RStudio Vous avez déjà RStudio? Assurez-vous davoir la dernière version: Dans la barre horizontale de votre interface RStudio, aller dans le menu déroulant Help Sélectionner loption Check for Updates Si vous navez pas la version la plus à jour, celle-ci vous sera proposée. Vous navez pas RStudio? Aller sur la page de téléchargement de RStudio Télécharger et exécuter le fichier qui correspond à votre système dopération, cest-à-dire *.exe pour Windows et *.dmg pour macOS. Vous utilisez une autre plateforme que RStudio ? Si vous préférez vraiment un autre environnement de développement que RStudio, vous pouvez bien sûr lutiliser. Aucun apprentissage dans ce cours est dépendant de RStudio. Toutefois, si, en cours de route, vous avez des questions liées à lenvironnement que vous avez choisi dutiliser, il nest pas certain que la personne qui vous encadre sera en mesure de vous aider. Apprivoiser RStudio Lorsque vous ouvrez RStudio pour la première fois, vous devriez voir une interface semblable à celle-ci (peut varier selon votre système dexploitation): FIGURE 1.22: Interface RStudio. Source : Douglas et al. (2022) An introduction to R: RStudio orientation. La grande fenête à gauche est la console R. Vous pouvez y écrire des commandes R à éxécuter. La fenêtre supérieure à droite contient les onglets Environment / History / Connections: Environment: contient les objets que vous avez créé ou chargez dans votre session R. History: contient la liste des commandes que vous avez entrées dans la console `R. Cette fenêtre peut être utile pour retrouver des commandes que vous avez précédemment utilisées. Connections: permet de se connecter à dautres sources de données. La fenêtre inférieur droite contient les onglets Files / Plots / Packages / Help / Viewer: Files: contient la liste de tous les fichiers et les répertoires qui sont dans votre répertoire de travail (working directory) sur votre ordinateur. Plots: contient toutes les figures crées au cours de votre session R. Vous pouvez agrandir la figure (Zoom) et la sauvegarder dans le format de votre choix (Export). Packages: contient la liste de toutes les bibliothèques installées sur votre ordinateur. À partir de cet onglet vous pouvez installer des nouvelles bibliothèques ou mettre à jour vos bibliothèques actuelles en cliquant sur les boutons Install et Update respectivement. Help: présente la documentation R pour une fonction recherchée. Viewer: affiche des graphiques web générés par certaines bibliothèques. Vous pouvez personnaliser votre inferface RStudio de multiples façons. Par exemple aller dans le menu déroulant Tool au haut de lécran et sélectionner Global Options/Appearance pour changer les couleurs de lécran et du lettrage. Vous nallez quand même pas garder cet écran blanc et cette écriture monochrome pendant les 15 semaines de cours ?! Créer un fichier R Bien quil soit possible dutiliser R en rédigeant des commandes dans la console, une meilleure habitude de travail consiste à créer un fichier R (c-à-d un fichier dextension *.R) qui contient une série de commandes successives à exécuter. Un fichier R permet de conserver les commandes. Ainsi, vous pourrez répéter les commandes dune session à une autre sans devoir les retaper dans la console. Un tel fichier permet également dajouter des commentaires pour préciser les opérations réalisées. Finalement, un fichier R permet de partager facilement son code avec autrui. Au cours de votre cheminement, si vous avez des questions ou des problèmes avec du code R, joignez un fichier R dans un courriel à la personne qui vous encadre. Il sera ainsi beaucoup plus facile de vous aider. Pour créer un fichier R, aller dans le menu déroulant File au haut de lécran et sélectionner New File/R Script: FIGURE 1.23: Créer un fichier R. Source : Douglas et al. (2022) An introduction to R: RStudio orientation. Remarquer quune nouvelle fenêtre souvre en haut à gauche de lécran (appelée le panneau Source) et que la console se trouve maintenant en bas à gauche. Pour exécuter une ligne de code dans un fichier R, vous navez quà placer votre curseur sur la ligne désirée et cliquer sur le bouton Run. Le résultat apparaitra dans la console. Vous pouvez également utiliser le raccourci ctrl + enter sous Windows ou cmd + enter sous Mac au lieu de cliquer sur Run. Pour exécuter lensemble des commandes contenues dans un fichier, cliquer sur Source. FIGURE 1.24: Utiliser un fichier R. Source : Douglas et al. (2022) An introduction to R: RStudio orientation. Sauvegarder un fichier R en lui donnant un nom qui a du sens. Ce nom doit être sans accent et sans espace Les bibliothèques Une bibliothèque R, appellée package en anglais, est un ensemble de fonctions spécialisées créées par des experts ou des expertes dans un champ danalyse précis. Pour installer une bibliothèque dans R à même la console, il faut utiliser la fonction install.packages(). Par exemple, la ligne de commande suivante installe la bibliothèque mapview: install.packages(&quot;mapview&quot;) Pour charger une bibliothèque dans une session R, il faut utiliser la fonction library(). Par exemple, vous pouvez écrire la commande suivante dans la console ou encore dans un fichier R: library(mapview) Il faut charger une bibliothèque à toute nouvelle session R. Le répertoire de travail Le répertoire de travail (working directory en anglais) est le dossier par défaut dans lequel R cherche les fichiers que vous téléchargerez au cours de votre session et dans lequel R inscrit tout fichier que vous sauvegarderez. Pour choisir un répertoire, aller dans le menu déroulant Session au haut de lécran et sélectionner Set Working Directory/Choose Directory . Pour connaitre le répertoire de travail courrant, entrer la commande getwd() dans la console. Pour choisir un autre répertoire, il sagit dutiliser le commande setwd() en identifiant le chemin (path) vers le répertoire désiré: setwd(&quot;C:/Users/Elise/TELUQ/SCI1031/Module4/Module4_Donnees&quot;) Vous pouvez ainsi écrire cette ligne de commande au début dun fichier R pour préciser à R le répertoire de travail auquel le code contenu dans le fichier se rapporte. Toutefois, ce chemin est absolu. Cest-à-dire quil est propre à votre ordinateur seulement et à la façon dont vous avez structuré vos dossiers. Dans la perspective où vous serez amené à partager des fichiers de code R, il est préférable dutiliser un chemin relatif. Cest-à-dire un chemin qui pointe vers un répertoire commun aux personnes qui utiliseront le même code. Dans le cours, les lignes de code vous invitant à lire des fichiers de données utiliseront toujours un chemin relatif. Par exemple: donnees &lt;- read.table(&quot;/Module4_Donnees/nz_capitales.csv&quot;, header = TRUE, sep = &quot;,&quot;) Ce sera donc à vous de bien régler votre répertoire de travail afin que R trouve le dossier commun (Module4_Donnees pour le présent exemple). 1.2.2 Intro à R La base Lutilisation la plus simple quon peut faire de R est celle dun calculateur. R exécute des opérations arithmétiques et une foule de fonctions mathématiques. Par exemple, # addition 2 + 2 [1] 4 # multiplication 2 * 8 [1] 16 # R suit les conventions pour la priorité des opérations 2 * 8 - 2 [1] 14 2 * (8 - 2) [1] 12 # Le logarithme en base 2 log(2) [1] 0.6931 # Le logarithme en base 10 log10(2) [1] 0.301 # Le carré ou autres puissances 2^2 [1] 4 3^8 [1] 6561 # La racine carrée sqrt(16) [1] 4 # pi pi [1] 3.142 Les objets Un objet en R est nimporte quelle entrée à laquelle on assigne un nom en utilisant lopérateur dassignation &lt;- . Par exemple, mon_objet &lt;- 10 Un objet peut être un chiffre, un vecteur, une chaine de caractères, ou même une structure plus complexe comme un graphique. Tout objet créé au cours dune session R est affiché dans longlet Environment de la fenêtre supérieure droite de linterface RStudio. Un objet est logé dans la mémoire vive et vous pouvez lutiliser pour des opérations futures. obj1 &lt;- &quot;J&#39;aime le cours&quot; obj2 &lt;- &quot;SCI 1031&quot; paste(obj1, obj2) [1] &quot;J&#39;aime le cours SCI 1031&quot; Les catégories de données Dans le cadre de ce cours nous utiliserons quatre principales catégories ou classes de données supportées par R: Numérique (numeric en anglais) est un nombre décimal ou un nombre entier. obj_num &lt;- 10.3 Entier (integer): un nombre entier. Une donnée de catégorie entier ne peux jamais être décimale. Nous devons utiliser la fonction as.integer() pour créer un entier, sans quoi R lui attribuera la catégorie numérique. obj_ent &lt;- as.integer(10) Logique (logical): une donnée qui prend la valeur vrai (TRUE) ou faux (FALSE), ou encore la valeur NA lorsque la valeur dune donnée est manquante. obj_log &lt;- FALSE Caractère (character): une chaine de un ou plusieurs caractères. obj_car &lt;- &quot;Yo!&quot; Nous utiliserons également une catégorie particulière de données de type caractère quon appelle des facteurs (factor). Les facteurs désignent des données catégoriques qui possèdent un ensemble connu de valeurs possibles (niveaux - levels). Nous créons des données de type facteur avec la fonction factor(): obj_fac &lt;- factor(c(&quot;Faible&quot;, &quot;Modéré&quot;, &quot;Élevé&quot;)) obj_fac [1] Faible Modéré Élevé Levels: Élevé Faible Modéré La fonction class() permet de connaitre la catégorie dune données. class(obj_num) [1] &quot;numeric&quot; class(obj_ent) [1] &quot;integer&quot; class(obj_log) [1] &quot;logical&quot; class(obj_car) [1] &quot;character&quot; class(obj_fac) [1] &quot;factor&quot; Les fonctions is.[nom de la catégorie]() retournent la valeur TRUE si lobjet interrogé appartient à la catégorie précisée et FALSE autrement. is.integer(obj_num) [1] FALSE is.integer(obj_ent) [1] TRUE is.character(obj_log) [1] FALSE Il est parfois utile de changer la classe dun objet en utilisant la fonction is.[nom de la catégorie](). # FALSE devient &quot;FALSE&quot; as.character(obj_log) [1] &quot;FALSE&quot; # FALSE devient 0 as.numeric(obj_log) [1] 0 # 10.3 devient 10 as.integer(obj_num) [1] 10 Les structures de données En plus de différentes catégories, il existe différentes structures de données. Les scalaires et les vecteurs Un vecteur est une séquence de données de même catégorie. Nous définissons un vecteur par lexpression c(,) où la virgule sépare les éléments de la séquence. # Un vecteur de catégorie numérique vec_num &lt;- c(9, 11, 4, 5) # Un vecteur de catégorie caractère vec_car &lt;- c(&quot;bleu&quot;, &quot;vert&quot;, &quot;rouge&quot;) Un vecteur ne peut contenir des données de différentes catégories à lexception dune donnée de valeur NA qui est de catégorie logique et qui désigne labsence de données. # R converti les nombres en caractère pour que les éléments # soient de même catégorie vec_mix &lt;- c(9, 2, &quot;bleu&quot;) vec_mix [1] &quot;9&quot; &quot;2&quot; &quot;bleu&quot; # NA conserve la catégorie des autres éléments vec_numNA &lt;- c(9, 2, NA) vec_numNA [1] 9 2 NA vec_carNA &lt;- c(&quot;bleu&quot;, NA, &quot;rouge&quot;) vec_carNA [1] &quot;bleu&quot; NA &quot;rouge&quot; La fonction length() donne le nombre déléments contenu dans un vecteur. length(vec_num) [1] 4 length(vec_car) [1] 3 Une donnée scalaire est un vecteur de longueur 1. sca &lt;- 3833 length(sca) [1] 1 Pour accéder à des éléments particuliers dun vecteur, nous utilisons lexpression []. a &lt;- c( 38, 33, 45, 26) # Le premier élément a[1] [1] 38 # Le troisième élément a[3] [1] 45 # Le premier et le troisième a[c(1,3)] [1] 38 45 FIGURE 1.25: Représentation dun scalaire et dun vecteur. Source : Douglas et al. (2022) An introduction to R: Data structures. Les matrices et les arrays Une matrice est simplement un vecteur de deux dimensions, tandis quun array est une matrice pouvant avoir plus de deux dimensions. Tout comme un vecteur, une matrice et un array sont formés de données dune même classe. FIGURE 1.26: Représentation dune matrice et dun array. Source : Douglas et al. (2022) An introduction to R: Data structures. Nous pouvons créer une matrice avec la fonction matrix(). Dans lexemple ci-dessous les données de 1 à 12 sont structurées dans une matrice de 4 rangées qui est remplie en suivant les rangées. mat_ex1 &lt;- matrix(1:12, nrow = 4, byrow = TRUE) mat_ex1 [,1] [,2] [,3] [1,] 1 2 3 [2,] 4 5 6 [3,] 7 8 9 [4,] 10 11 12 Une matrice de structure différente mais avec les mêmes éléments. mat_ex2 &lt;- matrix(1:12, nrow = 2) mat_ex2 [,1] [,2] [,3] [,4] [,5] [,6] [1,] 1 3 5 7 9 11 [2,] 2 4 6 8 10 12 Remarquer que dans cet exemple, la matrice est remplie suivant les colonnes. Nous pouvons aussi créer une matrice en combinant des vecteurs. vec1 &lt;- 1:6 vec2 &lt;- 7:12 # combinaison le long des colonnes mat_ex3 &lt;- cbind(vec1, vec2) mat_ex3 vec1 vec2 [1,] 1 7 [2,] 2 8 [3,] 3 9 [4,] 4 10 [5,] 5 11 [6,] 6 12 # combinaison le long des rangées mat_ex4 &lt;- rbind(vec1, vec2) mat_ex4 [,1] [,2] [,3] [,4] [,5] [,6] vec1 1 2 3 4 5 6 vec2 7 8 9 10 11 12 Pour créer un array, nous pouvons utiliser la fonction array() et définir ces dimensions avec largument dim. array_ex1 &lt;- array(1:16, dim = c(2,4,2)) array_ex1 , , 1 [,1] [,2] [,3] [,4] [1,] 1 3 5 7 [2,] 2 4 6 8 , , 2 [,1] [,2] [,3] [,4] [1,] 9 11 13 15 [2,] 10 12 14 16 Cet array est constitué de deux matrices, chacune possédant 2 rangées et 4 colonnes. La dimension dune matrice ou dun array se calcule avec la fonction dim(): dim(mat_ex1) [1] 4 3 dim(array_ex1) [1] 2 4 2 Il est parfois utile dattribuer des noms aux colonnes et aux rangées dune matrice ou dun array. Ceci est possible avec les fonctions colnames() et rownames(): colnames(mat_ex1) &lt;- c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;) rownames(mat_ex1) &lt;- c(&quot;alpha&quot;, &quot;beta&quot;, &quot;gamma&quot;, &quot;delta&quot;) mat_ex1 A B C alpha 1 2 3 beta 4 5 6 gamma 7 8 9 delta 10 11 12 Pour accéder à un élément particulier dune matrice ou dun array nous utilisons toujours lexpression [] mais cette fois la position de lélément dans chaque dimension doit être précisée: # élément à la ligne 1, colonne 2 mat_ex1[1,2] [1] 2 # élément à la ligne 2, colonne 1, 2e matrice array_ex1[2,1,2] [1] 10 Les listes Une liste est un objet pouvant héberger des données de différentes classes. En fait, une liste peut également héberger des données de différentes structures. Nous définissons une liste par la fonction list() où chaque objet de la liste est séparé par une virgule. Voici un exemple: list_ex1 &lt;- list( matrix(1:6, nrow = 3), c(&quot;bleu&quot;, &quot;vert&quot;, &quot;rouge&quot;), c(FALSE, TRUE, FALSE, TRUE, FALSE)) list_ex1 [[1]] [,1] [,2] [1,] 1 4 [2,] 2 5 [3,] 3 6 [[2]] [1] &quot;bleu&quot; &quot;vert&quot; &quot;rouge&quot; [[3]] [1] FALSE TRUE FALSE TRUE FALSE Nous pouvons assigner des noms à chaque objet de la liste en utilisant la fonction names(): names(list_ex1) &lt;- c(&quot;quantite&quot;, &quot;couleur&quot;, &quot;resultat&quot;) list_ex1 $quantite [,1] [,2] [1,] 1 4 [2,] 2 5 [3,] 3 6 $couleur [1] &quot;bleu&quot; &quot;vert&quot; &quot;rouge&quot; $resultat [1] FALSE TRUE FALSE TRUE FALSE Ou encore au moment de définir la liste: list_ex2 &lt;- list( frequence = matrix(1:6, nrow = 3), saveur = c(&quot;bleu&quot;, &quot;vert&quot;, &quot;rouge&quot;), verification = c(FALSE, TRUE, FALSE, TRUE, FALSE)) list_ex2 $frequence [,1] [,2] [1,] 1 4 [2,] 2 5 [3,] 3 6 $saveur [1] &quot;bleu&quot; &quot;vert&quot; &quot;rouge&quot; $verification [1] FALSE TRUE FALSE TRUE FALSE Pour accéder à un objet de la liste, nous devons utiliser lexpression [[]], ou encore son nom précédé du symbole $. # Premier objet list_ex1[[1]] [,1] [,2] [1,] 1 4 [2,] 2 5 [3,] 3 6 # objet couleur list_ex1$couleur [1] &quot;bleu&quot; &quot;vert&quot; &quot;rouge&quot; Pour accéder à un élément particulier de la liste, il faut dabord préciser sa position dans la liste, puis sa position dans lobjet. # Element sur la 3e ligne, 2e colonne du premier objet list_ex1[[1]][3,2] [1] 6 # Element 2 de l&#39;objet couleur list_ex1$couleur[2] [1] &quot;vert&quot; Les data frames Un data frame est un tableau de données à deux dimensions, semblable à une matrice, mais pouvant contenir des données de différentes classes. Généralement chaque ligne du tableau correspond à une observation et chaque colonne à une variable mesurée. Les data frames sont similaires à un tableau Excel. Ils peuvent aussi être perçus comme une combinaison de vecteurs de même longueur. Nous pouvons créer un data frame en utisant la fonction data.frame(): tab_ex1 &lt;- data.frame(voiture = 1:5, marque = c(&quot;Hyundai&quot;, &quot;Ford&quot;, &quot;Toyota&quot;, &quot;Hyundai&quot;, &quot;Subaru&quot;), couleur = c(&quot;Gris&quot;, &quot;Rouge&quot;, &quot;Bleu&quot;, &quot;Noir&quot;, &quot;Gris&quot;)) tab_ex1 voiture marque couleur 1 1 Hyundai Gris 2 2 Ford Rouge 3 3 Toyota Bleu 4 4 Hyundai Noir 5 5 Subaru Gris Ou encore: nom &lt;- c(&quot;Price&quot;, &quot;Suzuki&quot;, &quot;Gallagher&quot;, &quot;Caufield&quot;, &quot;Hoffman&quot;, &quot;Dvorak&quot;, &quot;Romanov&quot;) prenom &lt;- c(&quot;Carey&quot;, &quot;Nick&quot;, &quot;Brendan&quot;, &quot;Cole&quot;, &quot;Mike&quot;, &quot;Christian&quot;,&quot;Alexander&quot;) numero &lt;- c(&quot;31&quot;,&quot;14&quot;,&quot;11&quot;,&quot;22&quot;,&quot;68&quot;,&quot;28&quot;,&quot;27&quot;) age &lt;- c(34,22,29,21, 32, 26, 22) position &lt;- factor(c(&quot;Gardien&quot;, &quot;Centre&quot;, &quot;Ailier droit&quot;, &quot;Ailier droit&quot;, &quot;Centre&quot;,&quot;Ailier gauche&quot;, &quot;Défenseur droit&quot; )) buts &lt;- c(NA, 19, 6,22, 11, 10, 3) tab_ex2 &lt;- data.frame(nom, prenom, numero, age, position, buts) tab_ex2 nom prenom numero age position buts 1 Price Carey 31 34 Gardien NA 2 Suzuki Nick 14 22 Centre 19 3 Gallagher Brendan 11 29 Ailier droit 6 4 Caufield Cole 22 21 Ailier droit 22 5 Hoffman Mike 68 32 Centre 11 6 Dvorak Christian 28 26 Ailier gauche 10 7 Romanov Alexander 27 22 Défenseur droit 3 Nous pouvons accéder à une colonne particulière dun data frame en utilisant lexpression [, n] où n est la position de la colonne ou en utilisant le nom de la colonne précédé du symbole $: tab_ex2[,3] [1] &quot;31&quot; &quot;14&quot; &quot;11&quot; &quot;22&quot; &quot;68&quot; &quot;28&quot; &quot;27&quot; tab_ex2$numero [1] &quot;31&quot; &quot;14&quot; &quot;11&quot; &quot;22&quot; &quot;68&quot; &quot;28&quot; &quot;27&quot; Pour accéder à une ligne particulière dun data frame, nous pouvons utiliser lexpression [m, ] où m est la position de la ligne tab_ex2[4,] nom prenom numero age position buts 4 Caufield Cole 22 21 Ailier droit 22 La fonction str() donne un résumé de la structure dun data frame (le nom des variables, la classe des données, et leur valeur): str(tab_ex2) &#39;data.frame&#39;: 7 obs. of 6 variables: $ nom : chr &quot;Price&quot; &quot;Suzuki&quot; &quot;Gallagher&quot; &quot;Caufield&quot; ... $ prenom : chr &quot;Carey&quot; &quot;Nick&quot; &quot;Brendan&quot; &quot;Cole&quot; ... $ numero : chr &quot;31&quot; &quot;14&quot; &quot;11&quot; &quot;22&quot; ... $ age : num 34 22 29 21 32 26 22 $ position: Factor w/ 5 levels &quot;Ailier droit&quot;,..: 5 3 1 1 3 2 4 $ buts : num NA 19 6 22 11 10 3 Parfois les data frame peuvent contenir beaucoup de variables et dobservations. Dans ces situations, il peut être utile dutiliser les fonctions head() ou tail() qui retournent les 5 premières et les 5 dernières lignes du tableau respectivement. head(tab_ex2) nom prenom numero age position buts 1 Price Carey 31 34 Gardien NA 2 Suzuki Nick 14 22 Centre 19 3 Gallagher Brendan 11 29 Ailier droit 6 4 Caufield Cole 22 21 Ailier droit 22 5 Hoffman Mike 68 32 Centre 11 6 Dvorak Christian 28 26 Ailier gauche 10 Importer et exporter des données Importer des données Dans le cadre de ce cours, vous serez amené à importer des fichiers de données en format *.txt ou *.csv. Ces deux formats peuvent être importés en utilisant la fonction read.table(). Tableau &lt;- read.table(file = &quot;NomDuFichier.txt&quot;, header = TRUE, sep = &quot;\\t&quot;, dec = &quot;,&quot;, na.string = &quot;S/O&quot;, stringsAsFactors = TRUE) La fonction read.table() peut comprendre plusieurs arguments. Entre autres: file =, indique le nom du fichier à importer. header = TRUE ou FALSE précise si on importe ou non le nom des colonnes. sep = \"\\t\" ou \",\" ou \"\" précise comment les données sont séparées dans le fichier dorigine (où \\t désigne la touche de tabulation (tab)). dec = \",\" ou \".\" précise comment la décimale est représentée dans le fichier dorgine (p. ex. en français nous utilisons la virgule). na.string = précise le symbole utilisé pour désigner les valeurs NA (p.ex. en français nous utilisons souvent lexpression S/O qui signifie sans objet) stringsAsFactors = TRUE ou FALSE précise si les données de classe caractère sont importées en classe facteur. Dautres fonctions similaires facilitent limportation de fichiers *.csv. Ces fonctions sont des variantes de la fonction read.table() qui incluent certaines combinaisons darguments par défaut. # Importer un fichier csv Tableau &lt;- read.csv(file = &quot;NomDuFichier.csv&quot;) # Importer un fichier csv avec dec = &quot;,&quot; et sep = &quot;;&quot; Tableau &lt;- read.csv2(file = &quot;NomDuFichier.csv&quot;) # Importer un fichier avec sep = &quot;\\t&quot; Tableau &lt;- read.delim(file = &quot;NomDuFichier.txt&quot;) Dans les modules futurs, nous verrons les fonctions R permettant dimporter des fichiers de données spatiales de différents formats. Exporter des données Similairement à la fonction read.table() pour lire les données, R dispose de la fonction write.table() pour exporter des données. Par exemple, nous pouvons exporter le data frame tab_ex2 dans un fichier *.txt: write.table(tab_ex2, file = &quot;JoueursCanadiens.txt&quot;, col.names = TRUE, row.names = FALSE, sep = &quot;\\t&quot;) Ou en format *.csv: write.table(tab_ex2, file = &quot;JoueursCanadiens.csv&quot;, col.names = TRUE, row.names = FALSE, sep = &quot;,&quot;) Nous pouvons également utiliser la fonction write.csv() pour exporter les données en format *csv write.csv(tab_ex1, file = &quot;voitures.csv&quot;, row.names = FALSE) Dans ce cas, il nest pas nécessaire les arguments col.names = TRUE et sep = \",\" sont pris par défaut, et il nest donc pas nécessaire de les préciser. Graphiques de base Diagramme de dispersion Nous utilisons la fonction plot() pour représenter une variable y en fonction dune variable x: x &lt;- 1:10 y &lt;- x^2 plot(x,y) Il est possible dajouter des arguments pour préciser: le nom des axes: xlab et ylab les limites des axes: xlim et ylim le titre: main la façon de lier les points: type lépaisseur du trait: lwd le style du trait: lty le style des points: pch la taille des points: cex la couleur des points: col et autres! FIGURE 1.27: Quelques arguments de la fonction plot() et les valeurs possibles. Source : The R Graph Gallery. Personnalisons le graphique précédent en ajoutant des arguments: plot(x,y, main = &quot;Croissance incroyable de ma plante&quot;, xlab = &quot;Jours&quot;, ylab = &quot;Taille (cm)&quot;, cex.lab = 1.5, xlim = c(0, 12), ylim = c(0, 120), type = &quot;b&quot;, lty = 3, lwd = 1, pch = 16, col = &quot;blue&quot;, cex = 0.9) 1.2.2.0.1 Histogramme Nous utilisons la fonction hist() pour produire un histogramme qui illustre le nombre ou la fréquence dobservation qui ont une certaines valeurs. # générer 20 nombres aléatoires à partir d&#39;une # distribution normale de moyenne 20 et de distribution standard 5 x &lt;- rnorm(100, mean = 20, sd = 5) # histogramme hist(x) Comme pour la fonction plot(), nous pouvons améliorer lapparence de lhistogramme par lajout darguments. hist(x, breaks = 10, main = &quot;&quot;, xlab = &quot;Valeurs&quot;, ylab = &quot;Fréquences&quot;, cex.lab = 1.5, col = &quot;pink&quot;, xlim = c(5, 40), ylim = c(0, 35)) Largument breaks permet de réduire ou daugmenter le nombre de bandes dans le diagramme. Le nombre de bandes ne sera probablement pas la valeur exacte que vous précisez mais respectera lordre de grandeur. Diagramme à boîtes Nous utilisons la fonction boxplot() pour créer un diagramme à boîtes (aussi appelé diagramme à moustaches). Un diagramme à boîtes est une bonne façon de voir comment les données sont distribuées autour de leur valeur médiane. # générer 20 nombres aléatoires à partir d&#39;une # distribution normale de moyenne 20 et de distribution standard 5 x &lt;- rnorm(100, mean = 20, sd = 5) # histogramme boxplot(x) Le trait horizonal foncé au centre correspond à la valeur médiane. La ligne supérieure de la boîte correspond au 75ième percentile (3ième quartile) et la ligne inférieure de la boîte au 25ième percentile (1er quartile) Comme pour les autres types de graphique, nous pouvons personnaliser les diagrammes à boîtes en ajoutant des arguments à la fonction boxplot() boxplot(tab_ex2$age, ylab = &quot;Âge des joueurs&quot;, ylim = c(19, 36), col = &quot;violet&quot;, cex.lab = 1.5 ) 1.2.3 À vous de jouer! Dans cette section, vous allez mettre en pratique les concepts enseignés en utilisant des données sur les municipalités du Québec qui proviennent du répertoire des municipalités du Québec. Bien que la réponse à chaque question soit disponible, il est très important de tenter dy répondre par vous même! Les données Télécharger le dossier Module1_donnees.zip dans votre répertoire de travail pour ce module, et dézippez-le. Le dossier contient le fichier villes_qc.csv. Question 1 a) Utiliser la fonction read.csv pour importer les données dans votre session de travail R. Nommer lobjet importer villes. Réponse villes &lt;- read.csv(&quot;Module1/Module1_donnees/villes_qc.csv&quot;) b) Quelles sont les dimensions du data frame villes et comment se nomment ses attributs (cest-à-dire le nom de ses colonnes)? Réponse Les dimensions sont données par la fonction dim() dim(villes) [1] 1131 4 Le nom des attributs est donné par la fonction names() names(villes) [1] &quot;munnom&quot; &quot;regadm&quot; &quot;mpopul&quot; &quot;msuperf&quot; Ces attributs correspondent: Au nom de la municipalité (munnom). À la région administrative dattache de la municipalité (regadm). À la taille de la population de la municipalité en 2021 (mpopul). À la superficie de la municipalité en km2 (msuperf). c) Utiliser la fonction str() pour produire un résumé du contenu du data frame villes. Déterminer à quelle classe appartient chaque attribut. Réponse str(villes) &#39;data.frame&#39;: 1131 obs. of 4 variables: $ munnom : chr &quot;Abercorn&quot; &quot;Acton Vale&quot; &quot;Adstock&quot; &quot;Aguanish&quot; ... $ regadm : chr &quot;Montérégie (16)&quot; &quot;Montérégie (16)&quot; &quot;Chaudière-Appalaches (12)&quot; &quot;Côte-Nord (09)&quot; ... $ mpopul : int 344 7733 2768 238 678 2232 227 172 30831 1459 ... $ msuperf: num 27 91.1 306.2 680.6 82.3 ... Nous constatons que munnom et regadm sont de classe caractère (char), mpopul de classe nombre entier (int), et msuperf de classe numérique (num). d) Transformer lattribut regadm en facteur et déterminer son nombre de niveaux. Réponse La fonction as.factor() permet de transformer un attribut en classe facteur. villes$regadm &lt;- as.factor(villes$regadm) Le nombre de niveau dun objet de classe facteur est donné par la fonction levels(). levels(villes$regadm) [1] &quot;Abitibi-Témiscamingue (08)&quot; [2] &quot;Bas-Saint-Laurent (01)&quot; [3] &quot;Capitale-Nationale (03)&quot; [4] &quot;Centre-du-Québec (17)&quot; [5] &quot;Chaudière-Appalaches (12)&quot; [6] &quot;Côte-Nord (09)&quot; [7] &quot;Estrie (05)&quot; [8] &quot;Gaspésie--Îles-de-la-Madeleine (11)&quot; [9] &quot;Lanaudière (14)&quot; [10] &quot;Laurentides (15)&quot; [11] &quot;Laval (13)&quot; [12] &quot;Mauricie (04)&quot; [13] &quot;Montérégie (16)&quot; [14] &quot;Montréal (06)&quot; [15] &quot;Nord-du-Québec (10)&quot; [16] &quot;Outaouais (07)&quot; [17] &quot;Saguenay--Lac-Saint-Jean (02)&quot; Nous observons quil y a 17 niveaux correspondants à chacune des régions administratives du Québec. Question 2 a) Créer lobjet Mtl qui contient seulement les entrées du data frame villes pour la municipalité de Montréal. Réponse Nous souhaitons créer un data frame comprenant seulement la ligne de villes pour laquelle lattribut munnon prend la valeur Montréal. Mtl &lt;- villes[villes$munnom==&quot;Montréal&quot;,] Mtl munnom regadm mpopul msuperf 409 Montréal Montréal (06) 1801546 431.7 Remarquer que lexpression villes$munnom==\"Montréal\" est un vecteur logique qui prend la valeur vrai (TRUE) lorsque le nom de municipalité est Montréal, et la valeur faux (FALSE) dans le cas contraire (cest-à-dire pour les 1130 autres municipalités) length(villes$munnom==&quot;Montréal&quot;) [1] 1131 class(villes$munnom==&quot;Montréal&quot;) [1] &quot;logical&quot; b) Créer lobjet villes_Outaouais qui contient les entrées du data frame villes pour toutes les municipalités de la région administrative de lOuatouais. Réponse Nous procédons de façon similaire à la question 2a. Nous sélectionnons toutes les lignes de villes pour lesquelles lattribut regadm prend la valeur Outaouais (07) villes_Outaouais &lt;- villes[villes$regadm==&quot;Outaouais (07)&quot;,] head(villes_Outaouais) munnom regadm mpopul msuperf 8 Alleyn-et-Cawood Outaouais (07) 172 325.9 21 Aumond Outaouais (07) 766 227.6 60 Blue Sea Outaouais (07) 656 87.5 61 Boileau Outaouais (07) 336 140.9 65 Bois-Franc Outaouais (07) 412 74.3 72 Bouchette Outaouais (07) 667 143.2 Question 3 a) Créer un histogramme de la distibution de la population des villes du Québec comprenant une dizaine de bandes. Utiliser la fonction log10() pour représenter la taille des populations. Préciser les axes de votre graphique adéquatement. Réponse Nous utilisons la fonction hist() avec largument breaks = 10 pour produire un histogramme denviron 10 bandes. hist(villes$mpopul, breaks = 10 ) Nous observons que la distribution de la taille des villes suit une loi de puissance. En effet, nous comptons beaucoup de villes avec une petite taille de population (plus de 1000 villes avec une population inférieure à 250 000 habitants) et peu de villes avec une très grande taille de population. Dans cette situation, il est préférable dillustrer le logarithme de la taille de la population. Cette distribution nous donne une meilleure appréciation de la variation dans la taille des villes. hist(log10(villes$mpopul), breaks = 10 ) Identifions correctement les axes. hist(log10(villes$mpopul), breaks = 10, main = &quot;&quot;, xlab = &quot;Nombre d&#39;habitants&quot;, ylab = &quot;Nombre de villes&quot;, col = &quot;darkorange&quot;, xlim = c(0, 7), ylim = c(0, 400), xaxt=&#39;n&#39; # ceci retire le nom des ticks sur l&#39;axe x. ) # Pour aller un peu plus loin ... axis(side =1 , at = 0:7, labels = c(&quot;1&quot;,&quot;10&quot;,&quot;100&quot;,&quot;1000&quot;, expression(10^4) , expression(10^5), expression(10^6), expression(10^7))) b) Créer un diagramme à boîte pour représenter la superficie des villes de la région de lOutaouais. Réponse boxplot(villes_Outaouais$msuperf, main = &quot;Superficie des municipalités de l&#39;Ouatouais&quot;, ylab = expression(paste(&quot;Superficie (km&quot;^&quot;2&quot;,&quot;)&quot;)), col = &quot;deepskyblue&quot; ) "],["base.html", "Module 2 Modèles de données spatiales", " Module 2 Modèles de données spatiales Ce module sintéresse à la façon dont nous représentons les phénomènes spatiaux se déroulant à la surface de la Terre par des données spatiales. Les objectifs principaux sont de connaître les propriétés des deux types de modèle de données spatiales, les données vectorielles et les données matricielles. À la fin de ce module vous saurez: Définir les propriétés principales des données vectorielles. Reconnaître des formats de fichier de données vectorielles. Définir les propriétés principales des données matricielles. Reconnaître des formats de fichier de données matricielles. Comprendre ce quest une structure en couches. À la section Exercices vous suivrez la première partie dune introduction à la bibliothèque rmarkdown. La deuxième partie de cette introduction aura lieu dans la section Exercices du Module 3. R Markdown permet de créer des documents dynamiques de formats variés (dont HTML, PDF et Word) qui intègrent des morceaux de code R. Dans le cadre de ce cours, toutes vos évaluations devront être remises dans un fichier R Markdown. Cette section vous permet ainsi de vous familiarisez avec cette bibliothèque. "],["leçon.html", "2.1 Leçon", " 2.1 Leçon Les phénomènes spatiaux sont généralement perçus comme étant soit des entités discrètes avec des frontières bien définies ou encore comme des phénomènes continus quon observe de partout mais qui ne possèdent pas de frontières naturelles8. Une rivière, une route, un pays, ou une ville sont tous des exemples dentités spatiales discrètes. Dautre part, lélévation, la température ou la qualité de lair sont des exemples de phénomènes continus, appelés aussi des champs spatiaux. FIGURE 2.1: Exemples de données vectorielles et matricielles. Gauche: La carte délimitant les régions administratives du Québec est formée à partir de données vectorielles. Droite: La carte topographique du Québec (source : https://mern.gouv.qc.ca/repertoire-geographique/carte-relief-quebec/)) Les entités spatiales (ou objets) sont habituellement représentés par ce quon appelle des données vectorielles (« vector data », en anglais), alors que les phénomènes continues sont habituellement représentés par des données matricielles (« raster data », en anglais). Ces deux modèles sont des façons bien différentes de percevoir et de représenter les phénomènes spatiaux. Nous les décrivons dans les deux sous-sections suivantes. 2.1.1 Les données vectorielles Définition Les données vectorielles sont utilisées pour représenter des entités spatiales dont les frontières sont explicites et qui possède une localisation précise et unique. Les données vectorielles sont définies par leur localisation géographique, leur géométrie, et un ou plusieurs attributs. La localisation géographique désigne lemplacement de lentité selon un système de coordonnées géographique ou un système de coordonnées projeté. Un système de coordonnées géographique utilise un système en trois dimensions pour donner la position (x,y,z) ou longitude et latitude dune entité spatiale sur la surface sphérique de la Terre. Un système de coordonnées projeté, donne la position dune entité spatiale sur une surface plane à deux dimensions. Nous reviendrons sur les systèmes de coordonnées de référence à la section 2.1.3. La géométrie dune entité spatiale correspond à sa forme (« shape », en anglais). Il existe trois principaux types de géométrie, aussi appelées des classes : les points, les lignes, et les polygones (Tableau 2.2). Ces classes peuvent être combinées pour créer des géométries plus complexes; des multipoints, des multilignes, des multipolygones, etc. FIGURE 2.2: Exemple de données vectorielles de géométrie simple. Remarquez que dans le cas dun polygone, la première et la dernière coordonnées sont les mêmes. Tableau inspiré de Wikipedia (https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry) Les données vectorielles comprennent également des variables additionnelles appelées des attributs. Les attributs sont toutes informations permettant de décrire une entité spatiale autres que sa localisation et sa géométrie. Géométrie et topologie Les points sont les données vectorielles les plus simples. Par exemple, un point pourrait représenter lemplacement dun restaurant dans une ville. Les attributs associés à ce point pourraient inclure les heures douverture, sa spécialité culinaire, léchelle de prix de son menu ou dautres informations. FIGURE 2.3: Lemplacement des stations de vélo en libre partage, Bixi, dans un quartier de Montréal correspond à une géométrie multipoints. Source : https://secure.bixi.com/map/. Il est aussi possible de combiner plusieurs points ensemble dans une structure multipoints définie par un attribut unique (Figure 2.3). Par exemple, lensemble des restaurants de cuisine vietnamienne dans une ville pourrait être considéré comme une géométrie unique. La géométrie des lignes est plus complexe. Le terme ligne en analyse spatiale na pas la même définition que dans le langage usuel. Une ligne désigne un ensemble dune seule ou de plusieurs polylignes (Figure 2.4). Une polyligne, quant à elle, désigne une séquence de segments de droite reliés entre eux. Ainsi, en analyse spatiale, une seule ligne pourrait représenter le fleuve Saint-Laurent et lensemble de ces affluents (rivière des Outaouais, rivière Saint-Maurice, le Fjord du Saguenay, etc.). Dautre part, il serait aussi possible de définir plusieurs lignes  une pour chaque affluent, par exemple. FIGURE 2.4: Le réseau hydrologique du bassin de lAmazone représente un exemple dun ensemble de polylignes. Source : Wang et al. 2020. Une ligne est représentée par un ensemble ordonné de coordonnées. Les segments de droite peuvent être calculés ou dessinés sur une carte en connectant ensemble les points. Ainsi, la représentation dune ligne est semblable à celle dune structure multipoints. La différence notable est que lordre des points est important dans la représentation dune ligne car il est nécessaire de savoir quels points sont connectés entre eux. Un réseau  par exemple un réseau routier ou un réseau hydrographique  est une ligne de géométrie particulière comprenant des informations additionnelles comme le débit, la connectivité ou la distance. Un polygone désigne un ensemble de polylignes fermées. La géométrie dun polygone est très semblable à celle des lignes à lexception que la dernière paire de coordonnées doit coïncider avec la première paire afin de « fermer » le polygone. Une particularité des polygones est quils peuvent comprendre des trous. Cest-à-dire quun polygone peut être entièrement compris à lintérieur dun polygone de plus grande superficie. Ceci est le cas dune île au sein dun lac, par exemple. Le polygone formant un îlot permet déliminer une partie du polygone qui lenglobe. De plus, alors que lauto-intersection est permise pour une ligne (cest-à-dire quelle peut se croiser sur elle-même), cette propriété nest pas valide pour un polygone. Finalement, plusieurs polygones peuvent être considérés comme formant une géométrie unique ((Figure 2.5)). Par exemple, lIndonésie est constituée de plusieurs îles. Chaque île peut être représentée par son propre polygone, ou encore lensemble des îles peut être représenté par un seul polygone (ou multi-polygones) désignant le pays en entier. FIGURE 2.5: Les Antilles peuvent être représentées par plusieurs polygones distincts pour chaque île, ou par un seul multipolygone. Source : https://fr.wikipedia.org/wiki/Antilles Le modèle vectoriel est très efficace pour représenter la topologie. La topologie est une description des relations spatiales quont les entités spatiales entre elles. Par exemple, une analyse de données vectorielles permettra de déterminer précisément si une entité spatiale est adjacente à une autre, si elle y est incluse, ou si elle sintersecte (Figure 2.6). FIGURE 2.6: Exemples de relations spatiales entre deux entités spatiales : a) adjacence, b) inclusion, et c) intersection. Format de données vectorielles Les données vectorielles peuvent être stockées dans une grande variété de formats différents. Ces formats ont évolué et continuent dévoluer en fonction des besoins et des avancées technologiques. Plusieurs formats ont été développés pour être utilisés avec des logiciels commerciaux mais peuvent être lus et parfois édités par dautres logiciels. Peu importe leur format, les données vectorielles sont toujours organisées selon une base de données relationnelle. Un identifiant désigne chaque objet spatial et lassocie à une géométrie et à un ou plusieurs attributs (Tableau 2.7). FIGURE 2.7: Exemple dune base de données relationnelle pour la carte des régions administratives du Québec (Figure 2.1). Chaque objet vectoriel dans la carte correspond à une ligne dans la base de données où figurent les attributs qui lui sont associés Voici une liste non-exhaustive de formats de données vectorielles. SHAPEFILE (.SHP, .DBF, .PRJ, .SHX) Le shapefile est un format propriétaire dESRI créé pour les logiciels ArcView et ArcGIS. En français, on le nomme aussi un fichier de forme. À ce jour, il est le format le plus couramment utilisé pour les données vectorielles. Il est devenu un standard tant pour les plateformes commerciales quopensource. Un shapefile comprend entre quatre types de fichiers qui contiennent des informations différentes et toutes essentielles à sa représentation. .shp : contient les données spatiales .dbf : contient les données dattributs .prj : contient linformation sur la projection des données .shx : fichier dindex Le fichier dindex sert à lier entre elles les informations contenues dans les autres fichiers. Il existe parfois dautres types de fichier dindex (.sbx, .sbn). Pour visualiser un shapefile, il est nécessaire davoir tous les fichiers associés (et pas seulement le fichier .shp). Le fichier .prj peut être absent. En son absence, le shapefile peut être lu mais les données ne seront pas projetées adéquatement. Nous reviendrons sur le concept de projection plus tard dans ce module. GEODATABASE (.GDB) La géodatabase est le nouveau format propriétaire dESRI conçu pour ArcGIS. Il est de plus en plus adopté car il présente de nombreux avantages par rapport au shapefile. Une géodatabase est une façon de rassembler et dorganiser des données propres à un sujet ou à un projet dans une unique base de données. Elle peut contenir des données géographiques dans une large gamme de fichiers et de formats (Figure 2.8). FIGURE 2.8: Illustration dune géodatabase telle que représentée sur le site web dArcGIS. Image récupérée à : https://desktop.arcgis.com/fr/arcmap/10.3/manage-data/geodatabases/a-quick-tour-of-the-geodatabase.htm Par exemple, un projet sur le réseau de transport délectricité au Québec pourrait nécessiter lutilisation de plusieurs shapefiles (position des centrales, position des pylônes, parcours des câbles, etc.) et aussi plusieurs données matricielles (topographie, végétation, etc.). Ainsi, il savère beaucoup plus efficace davoir lensemble de ces données au sein dune même base. De plus, une géodatabase peut être utilisée par de multiples utilisateurs, ce qui est fort utile pour assurer le partage efficace, la mise à jour, et la cohérence des données géographiques au sein de grandes organisations, comme des entreprises ou des ministères. Malheureusement, bien que les géodatabases peuvent être lues avec R, elles peuvent seulement être modifiées dans ArcGIS. GEOGRAPHIC JAVASCRIPT OBJECT NOTATION (.GEOJSON, .JSON) Le format geoJSON est un format standard ouvert très utilisé en cartographie web. geoJSON est une extension du format JSON pour les données géographiques. Un fichier geoJSON contient les coordonnées des données géospatiales ainsi que dautres informations sur les attributs. Un seul fichier est nécessaire pour stocker lensemble de linformation. GOOGLE KEYHOLE MARKUP LANGUAGE (.KML, .KMZ) Ce format est basé sur le langage XML et est optimisé pour les navigateurs de cartographie web comme Google Maps et Google Earth. KMZ est une version compressée dun fichier KML (KML-Zipped). COVERAGE COVERAGE est le format propriétaire dESRI, développé pour le logiciel ArcInfo, qui a précédé le format shapefile. Cest une autre façon de stockée les données vectorielles qui nécessite plusieurs fichiers. Bien que ce format ne soit plus utilisé lorsque de nouvelles données vectorielles sont conçues, vous pourriez être amenés à rencontrer ce format si vous devez travailler avec des données qui précédent 1990. ARCINFO INTERCHANGE FILE (.EOO) Cest le format utilisé pour importer ou exporter des données dArcInfo. Il fonctionne comme un fichier zip et permet de partager facilement en un seul fichier les multiples fichiers et dossiers associés au format Coverage. Il permet aussi de transférer des données matricielles de format GRID. MAPINFO INTERCHANGE FILE (.MID, .MIF) Cest le format propriétaire de MapInfo, le compétiteur dEsri. Le format shapefile a supplanté le format interchange qui est de moins en moins utilisé. Le fichier MIF contient la localisation géographique et la topologie, et le fichier MID contient les attributs. WEB MAP SERVICE (WMS) Nest pas un format de données mais plutôt un protocole de communication qui permet de visualiser des données spatiales qui sont logées sur un serveur. Les organisations gouvernementales ont souvent recours à cette méthode de partage de linformation spatiale car elle permet de sassurer que les données diffusées sont toujours à jour. Lutilisateur peut jouer avec les paramètres de visualisation mais ne peut pas importer et modifier les données. Notez que ce protocole est utilisé à la fois pour les données vectorielles et les données matricielles. 2.1.2 Les données matricielles Définition Les données matricielles représentent la surface terrestre par une grille régulière, communément appelé un raster, formée de rectangles de même forme et de même dimension appelés cellules ou pixels (Figure 2.9). À chaque cellule de la matrice correspond une valeur numérique (ou une valeur manquante) associée à un attribut dintérêt. On appelle couche (« layer » en anglais) linformation recueillie dans la matrice. La valeur dune cellule peut être continue (p. ex. lélévation - voir Figure 2.1b) ou catégorique (p. ex. le zonage attribué à différents secteurs dune ville tel que résidentiel, commercial ou industriel). Normalement, la valeur dune cellule représente la valeur moyenne (ou la valeur prédominante) pour la superficie quelle couvre. Cependant, les valeurs sont parfois estimées pour le centre de la cellule. FIGURE 2.9: Exemple de données matricielles associées à des classes de végétation obtenues à partir dune image satellitaire. Figure inspirée de NEON neonscience.org/resources/series/introduction-working-raster-data-r On peut utiliser une base de données relationnelle pour lier la valeur dun pixel à lattribut quil décrit (Figure 2.10). Contrairement aux données vectorielles où les polygones peuvent être associés à plusieurs attributs, une couche de données matricielles peut représenter un seul attribut. FIGURE 2.10: Exemple de table relationnelle pour les données vectorielles de la Figure 2.9. Une valeur numérique est associée à chaque couleur de limage ainsi quà un attribut, ici le type de végétation. Dans leur format le plus simple, les données matricielles prennent la forme dune image digitale. Cependant, pour associer les données matricielles à une location particulière sur la surface de la Terre, des informations spatiales doivent être ajoutées. Ainsi, un fichier de données matricielles géospatiales débute toujours par une section, appelée le «header» en anglais, qui procure la localisation. La localisation pour des données matricielles est définie par létendue spatiale (« extent » en anglais) couverte par la matrice, la dimension des cellules, le nombre de rangées et de colonnes qui divisent la superficie (respectivement « rows » et « columns » en anglais), et le système de coordonnées géographique ou projeté. La dimension des cellules correspond à la résolution spatiale et peut être calculée à partir de létendue et du nombre de rangées et de colonnes. Résolution et géométrie La résolution définie la précision avec laquelle nous pouvons discerner les objets dans lespace. Une grande résolution correspond à une matrice de données dont les cellules ont une petite taille (Figure 2.11). En conséquence, une telle matrice est plus lente à visualiser et à manipuler, et requière un fichier plus volumineux. En contrepartie, une couche de données matricielles de faible résolution possède des cellules de plus grande taille, se visualise et se manipule plus rapidement, et est contenue dans un fichier moins volumineux. FIGURE 2.11: Exemple du concept de résolution: plus la résolution est grande, plus la taille des cellules est petite. Dans cette figure, la résolution diminue de droite à gauche, et la taille des cellules augmente. Source de données: https://mern.gouv.qc.ca/nos-publications/spatiocarte-quebec/ Contrairement aux données vectorielles, la géométrie des données matricielles nest pas définie explicitement par un ensemble de coordonnées. La géométrie peut être déduite en observant les démarcations se produisant aux limites des ensembles de cellules de même valeur. Cependant ces démarcations ne correspondent pas nécessairement aux frontières des entités sur le terrain (Figure 2.12). FIGURE 2.12: La géométrie des objets spatiaux matriciels. Les frontières dune entité spatiale définie avec des données matricielles (droite) ne correspondent pas nécessairement aux frontières réelles (gauche) Ainsi, lorsque nous représentons des objets spatiaux aux frontières bien définies, lutilisation de données vectorielles plutôt que matricielles savère plus précise et plus efficace. Par ailleurs, la représentation de phénomènes continus avec des données vectorielles, nécessiterait de définir un grand nombre de petit polygones et denregistrer les coordonnées de chacun deux. Dans la majorité des cas, une telle représentation augmenterait dramatiquement le temps de traitement des données. Données matricielles à bande unique et multi-bandes Un raster peut contenir une couche ou plusieurs couches de données. Par exemple, un fichier de données matricielles délévation comprendra une seule couche de données, soit lélévation à chaque cellule. Par exemple la carte topographique du Québec (Figure 2.1b) est un exemple de raster à une seule couche. Un raster à une seule couche peut aussi représenter des images en noir et blanc en utilisant un codage binaire pour exprimer différentes teintes de gris. Un codage sur 1 bit exprimera 21 (2) teintes de gris [0,1], un codage sur 4 bit exprimera 24 (16) teintes de gris [0,1,2,,15], et un codage sur 16 bits exprimera 216 (65536) teintes de gris [0,1,2,, 65535] (Figure 2.13). FIGURE 2.13: Exemple de codage binaire pour les raster à une couche: Images en blanc et noir utilisant différentes teintes de gris : 2 teintes (gauche), 8 teintes (centre) et 256 teintes (droite). Dautres rasters peuvent contenir plusieurs couches, appelées aussi des bandes (ou canaux). Par exemple, les images de couleurs contiennent souvent trois bandes: une bande de rouge, une bande de vert et une bande de bleu. Cest ce quon nomme le format RGB (pour « red », « green », et « blue »). Ces bandes font références à des sections du spectre électromagnétique captées lors de la prise de limage (Figure 2.14). FIGURE 2.14: Raster multibande. Les bandes blues, vertes et rouges correspondent à des sections du spectre électromagnétique. Source: Esri. Image récupérée à https://desktop.arcgis.com/en/arcmap/10.3/manage-data/raster-and-images/raster-bands.htm. En combinant ces bandes, on peut recréer limage (Figure 2.15). Attention : chaque bande doit posséder les mêmes informations spatiales pour être superposée aux autres. FIGURE 2.15: Image satellitaire de région de lEstrie. Le raster multi-bande contient une bande de rouge, une bande de vert et une bande de bleu. Limage couleur sobtient en combinant les trois bandes. Source de données: https://mern.gouv.qc.ca/nos-publications/spatiocarte-quebec/ Format des données matricielles Tout comme les données vectorielles, les données matricielles peuvent être stockées dans une grande variété de formats différents. Les images possèdent des structures matricielles, ainsi les formats bien connus pour la transmission dimages sur le Web, .jpg (Joint Photographic Experts Group), .gif (Graphics Interchange Format), et .png (Portable Network Graphics), sont des exemples de format de données matricielles. Voici une liste non-exhaustive de formats de données matricielles. GRID (.GRD) GRID est le format propriétaire dESRI pour stocker des données matricielles. TIFF AND GEOTIFF (.TIF) Le Tag Image File format (TIFF) est utilisé pour le stockage dimages numériques. Il a la particularité dêtre comme un contenant dans lequel plusieurs informations additionnelles sur les données peuvent être stockées (par ex. les attributs, et autres métadonnées). Le format GeoTIFF est un fichier .tif standard dans lequel on intègre des informations additionnelles sur la localisation spatiale des données (p. ex. la résolution, létendue ou le système de coordonnées). COMMA SEPERATED VALUE FORTMAT (.CSV) Le format .csv contient du texte séparé par des virgules, et correspond à une façon simple et très répandue de représenter des données matricielles. Par exemple, un fichier .csv pourrait être constitué de trois colonnes : la première pour la coordonnée x de la cellule, la deuxième pour sa coordonnée y, et la troisième pour la valeur de lattribut. Une autre façon dutiliser le format .csv est dy stocker la matrice de données sous forme dun tableau de dimension égale à cette dernière. Chaque entrée du tableau donne la valeur dattribut pour la cellule correspondante. Les informations sur la localisation spatiale doivent alors être fournies en en-tête du fichier. BITMAP (.BMP) BITMAP est le format dimages utilisé dans les applications de Microsoft Windows. De plus, comme expliqué plus haut, la géodatabase et Web Map Service sont aussi utilisés pour les données matricielles. Peu importe le type de données spatiales et le format utilisé pour les stocker, les données spatiales sont souvent accompagnées de métadonnées. Les métadonnées sont les données sur les données. Cest-à-dire quelles viennent donner des informations supplémentaires pour faciliter la compréhension et lutilisation des données spatiales (p. ex. lorigine des données, lauteur.e, les détails sur la structure, le lexique, les abréviations, la légende, etc.). Idéalement, tout ensemble de données devrait être accompagné de métadonnées. 2.1.3 Structure en couches Lorsque nous travaillons avec des données spatiales, il est fréquent de devoir combiner des données représentant des phénomènes spatiaux distincts. Nous devons alors utiliser une structure en couches. Une couche de donnée réfère à un thème spécifique (par ex. topographie, végétation, ou réseau routier) et contient un seul modèle de données (matricielles ou vectorielles) (Figure 2.16). FIGURE 2.16: Représentation de données spatiales par la superposition de couches thématiques. Source: Esri. Image récupérée à https://desktop.arcgis.com/fr/arcmap/10.3/guide-books/map-projections/what-are-map-projections.htm La superposition de couches permet de visualiser les relations spatiales entre les données de différentes thématiques (Auda 2018). Il est primordial que chaque couche de données utilise le même système de coordonnées de référence lorsquelles sont superposées. Le module 3 portera spécifiquement sur cette notion. Repris de lintroduction aux données spatiales du site Spatial Data Science. "],["ex_markdown1.html", "2.2 Exercices", " 2.2 Exercices Cette section est une introduction à R Markdown qui passe en revue différents aspects techniques nécessaires à la bonne compréhension et utilisation de la biblothèque rmarkdown. Cette introduction est divisée en deux parties. Vous ferez la première partie maintenant, au module 2, et la deuxième partie dans le section Exercices du module 3. La bibliothèque rmarkdown permet de créer des documents de formats variés (dont HTML, PDF et Word) avec un contenu R dynamique. Cest-à-dire des documents qui intègrent des morceaux de code R et ce quils génèrent (p. ex. des figures et tableaux). Le code source de ce site web est lui-même un exemple dapplication de cette bibliothèque! R Markdown nest pas un outil spécifique à la visualisation de données spatiales. Toutefois, puisquil constitue un outil dédition, de visualisation et de diffusion fort pratique, nous lutiliserons dans ce cours. En particulier, les évaluations devront être remises dans un fichier R Markdown .Rmd. À la fin de cette introduction vous saurez: Décrire en quoi consiste R Markdown; Décrire les liens entre R, Markdown et Pandoc; Utiliser la syntaxe Pandoc Markdown de base; Créer des documents dynamiques avec la bibliothèque rmarkdown. Cette introduction à RMarkdown a été rédigée par Kevin Cazelles, collobateur clé à réalisation de ce cours. Kevin est un chercheur en écologie computationnelle et fervent utilisateur des outils pour la science ouverte. Allez voir ses travaux sur son site https://kevcaz.insileco.io/ et son profil GitHub https://github.com/KevCaz. 2.2.1 Introduction à R Markdown Bénéfices de R Markdown Dans de nombreux milieux professionnels, à des fins de communication diverses, sont produits régulièrement des documents intégrant des analyses de données (tableaux, figures, tests statistiques, etc.). Pour créer de tels documents, il faut être en mesure de manipuler des données, de les analyser et de créer des figures pour les intégrer dans le document final. R est un langage de programmation qui répond à ces besoins avec un grand nombre de bibliothèques qui permettent de manipuler et traiter un spectre très large de données et de les visualiser efficacement. Le langage R offre également la possibilité dintégrer code et les produits du code (résultats de tests, tableaux, figures, etc.) directement dans un document qui est alors qualifié de dynamique. La bibliothèque la plus utilisée pour créer des documents dynamiques est rmarkdown. En effet, elle permet lintégration de R dans un document écrit avec Markdown et qui peut être converti en de nombreux formats de document (dont PDF, Word, HTML). Quest-ce que Markdown? Markdown est un langage de balisage léger. Cest-à-dire un langage dans lequel on peut utiliser des ensembles de caractères spécifiques (des balises) pour délimiter une zone de texte pour laquelle un formatage associé (e.g. text en gras) est appliqué. Markdown est aujourdhui très répandu sur Internet. La syntaxe originale de Markdown est le fruit du travail de John Gruber9, programmeur, bloggeur et baladodiffuseur de Philadelphie en collaboration avec Aaron Swartz10 (lui même connu pour avoir participer à la création de Creative Commons et son tragique destin qui fut lobjet dun film). Sur le site de John Gruber, daringfireball, Markdown est décrit depuis décembre 2004 et on peut même y télécharger la version 1.0.1 (voir http://daringfireball.net/projects/markdown). Lidée de départ est simple et élégante : produire un langage léger qui simplifie les balises HTML utilisé par tous les sites Internet. Lidée nest pas tant de remplacer le HTML mais plutôt den augmenter lefficacité décriture et de fait, il est beaucoup plus rapide décrire en Markdown qui couvre les opérations de formatage les plus courantes (listes, hyperliens, etc.). Notons quil existe dautres langages qui répondent aux mêmes objectifs, par exemple ReStructuredText11. Après la publication de Markdown, John Gruber a cessé de travailler sur Markdown12 et dautres développeurs, sans doute séduits par le langage, ont proposé différentes additions syntaxiques. Il sagissait surtout de lever certaines limitations tout en préservant lesprit dorigine. Ci-dessous, en voici une liste non exhaustive de différentes variantes Markdown: GitHub Flavored Markdown (GFM) Kramdown Markdown Extra Multi Markdow Pandoc Markdown Depuis 2014, CommonMark (https://commonmark.org/) propose une spécification (norme technique) pour Markdown de plus en plus utilisée13. Ceci signifie quen allant dun outil à lautre qui utilise cette spécification, il ny a pas de questions à se poser quant à savoir ce qui marche ou non en terme de syntaxe (un problème parfois frustrant quand on utilise plusieurs outils qui utilisent différentes syntaxes Markdown), il suffit de se reporter à la spécification! Quest-ce que Pandoc? R Markdown (voir http://rmarkdown.rstudio.com)14 utilise la variante Markdown de Pandoc15. Pandoc, comme lindique son site internet (voir http://www.pandoc.org) est un convertisseur de document universel. En une ligne de commande, Pandoc convertit un document dun format donné en un document dun autre format. Par exemple, Pandoc permet de passer dun fichier .tex (LaTeX) à un fichier .docx (Word)! La variante Markdown de Pandoc a été pensé pour rester fidèle à lesprit originel de Markdown tout en incluant davantage déléments communs à différents formats de documents16. Ainsi, un fichier R Markdown pourra être converti dans un grand nombre de formats grâce à lutilisation de Pandoc. Dans cette introduction, nous nous concentrerons sur la création de documents en format Word, PDF et HTML, mais que les possibilités offertes par rmarkdown sont plus vastes (voir la section Ressources du cours dédiée à la documentation R Markdown). 2.2.2 Utiliser un fichier RMarkdown Organisation générale Un fichier R Markdown, dont lextension est .rmd ou .Rmd, un fichier de texte brut qui contient trois types de langage. Un langage de programmation, R. Le fichier peut contentir des blocs de codes R utilisés pour présenter des opérations R, pour les exécuter, et pour afficher leur résultat. Ces blocs commencent et finissent par trois accents graves (backtick ou backquote en anglais): ` et les trois accents graves ouvrant le bloc sont suivis dune accolade qui commence par r ou R, par exemple ```{R name, option1, option2} # code R à exécuter ``` ou encore ```{r option1} # code R à exécuter ``` Ces blocs de code sont intégrés au document grâce aux fonctionnalités de la bibliothèque knitr17. Un langage de balisage pour lécriture du document, la variante syntaxique Pandoc de Markdown. Un langage de sérialisation, YAML, pour personnaliser la mise en page du ou des documents produits. Il sagit dune entête (Front Matter en anglais) placée au début du document dans un bloc de trois tirets ( --- ) qui donne des indications sur les sorties à générer. --- title: &quot;R Notebook&quot; output: html_notebook --- De plus, la variante syntaxique Pandoc de Markdown inclut les symboles mathématiques TeX18 pour facilité lécriture, entre autres, des équations. En un sens cest un quatrième langage que peut contenir un fichier R Markdown! Une fois le fichier R Markdown créé, il sagit dutiliser la fonction R render() pour appeler le fichier. R Markdown générera alors le ou les documents selon le format désiré. Installer R Markdown Commençons par installer la bibliothèque rmarkdown: install.packages(&#39;rmarkdown&#39;) Pour la production de document PDF, vous aurez besoin dinstaller LaTeX. Si vous navez pas déjà LaTeX sur votre ordinateur, installer plutôt la bibliothèque tinytex19: install.packages(&#39;tinytex&#39;) tinytex::install_tinytex() # installer TinyTeX Créer un fichier R Markdown Créer un fichier R Markdown, cest simplement créer un fichier dont lextension est .Rmd ou .rmd, ce qui peut être fait avec nimporte quel éditeur de texte, ou de code, ou même en ligne de commande20. Dans R Studio, cela peut se faire en 2 clics, comme illustré dans la marche à suivre ci-dessous. Lintérêt dutiliser R Studio pour cette opération est que le fichier ainsi créé contient des indications relatives à lutilisation du fichier en question. Première étape : Utilisez licône de création de nouveaux fichiers (symbole + dans un cercle vert), et choissez R Markdown dans le menu vertical Deuxième étape : Choisissez le format de sortie désiré (HTML, PDF ou Word), précisez le titre du document ainsi que votre nom, puis appuyez sur la touche OK. Un fichier contenant différentes instructions et exemples est généré. Sauvegardez le fichier créé en lui attribuant un nom. Spécifier les options YAML Lentête YAML sert à spécifier différentes propriétés des documents à générer à partir du fichier .Rmd (par exemple, le titre, la date, les polices de caractères utilisées, ajout dune table des matières, etc.) grâce à des gabarits (templates en anglais) utilisés par Pandoc. Lorsque vous créez un fichier .Rmd avec R Studio, une entête YAML est créée par défaut avec les champs: titre, autrice ou auteur, date et format de la sortie. --- title: &quot;mondoc&quot; author: &quot;Kevin Cazelles&quot; date: &quot;30/04/2022&quot; output: html_document --- Les champs disponibles dépendent des gabarits utilisés qui sont spécifiques à un format donné, les champs par défaut varient ainsi dun format à lautre. Notez quil est possible de créer ses propres gabarits et donc dajouter autant de champs que désiré. Un champ donné peut contenir une chaîne de caractères, une date, des chiffres ou encore une liste: nomduchamp: [élément1, élément2] ou encore nomduchamp: - élément1 - élément2 On utilise lindentation pour signifier la hiérarchie entre les différents éléments. Les commentaires sont introduits par un #. Pour un aperçu assez complet des options YAML utilisables dans un fichier R Markdown, rendez-vous à la dernière page du guide de référence. Voici quelques exemples de champs valables pour les sorties HTML, PDF et docx: abstract: le texte dun résumé apparaissant au début du document produit. description : la description du contenu du fichier. celle-ci napparaîtra pas sur le document produit. Utiliser les guillemets pour un texte long ou avec des signes de ponctuation. Pour un document HTML, plusieurs champs additionnels sont utiles: theme: le thème Bootstrap21 à utiliser pour lapparence du document HTML. Les thèmes disponibles sont: default, bootstrap, cerulean, cosmo, darkly, flatly, journal, lumen, paper, readable, sandstone, simplex, spacelab, united, et yeti. Consultez la page de la bibliothèque Bootswatch pour voir à quoi ces thèmes ressemblent. highlight: le style de la coloration syntaxique. Les styles disponibles sont: default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, breezedark, et textmate. Vous trouverez ici quelques exemples de ces styles. number_sections: numéroter ou non les sections. toc: inclure ou non une table des matières (table of content en anglais). toc_depth: la profondeur de la table, cest-à-dire, le niveau des titres apparaissant sur la table. toc_float: inclure ou non la table des matières en menu vertical visible à gauche sur le document HTML. Ce champ peut également être spécifié par une liste doptions: collapsed: permettre ou non un menu de type accordéon qui se referme et se déploie. smooth_scroll: colorer ou non le titre dune section dans le menu lors de la navigation sur la page. fig_width: la largeur des figures. fig_height: la hauteur des figures. fig_caption: inclure ou non une légende aux figures. Pour les documents PDF, les champs suivants peuvent être précisés: fontfamily: la police de caractère. fontsize: la taille des caractères. Éditer le contenu du fichier R Markdown Le contenu principal dun fichier R Markdown contient du texte et des blocs de code R. Le texte doit suivre la syntaxe Pandoc Markdown. Nous détaillerons cette syntaxe dans la deuxième partie de cette introduction à R Markdown, à la section Exercices du Module 3. Les blocs de code R sont ce qui distinguent un fichier R Markdown dun fichier Markdown. La façon dont le code R est intégré au document final est déterminé par une suite de paramètres. Ces paramètres contrôlent, par exemple, si le code est affiché, si le résultat est affiché, la position dun graphique produit, etc. Nous détaillerons également ces paramètres dans la deuxième partie de cette introduction à R Markdown. Lorsque vous créer un fichier R Markdown dans RStudio, un exemple est donné par défaut. Cet exemple contient du texte selon la syntaxe Pandoc de Markdown et du code R. Obtenir le document final Pour générer le document final à partir du fichier R Markdown, nous utilisons la fonction render() de la bibliothèque rmarkdown. Il sagit dappeler le fichier *.Rmd en spécifiant le chemin vers son répertoire. render(&quot;chemin/ex_Rmardown.rmd&quot;) Nous pouvons ajouter largument all pour obtenir tous les documents (PDF, HTML, Word) pour lesquels une spécification YAML existe. render(&quot;ex_Rmardown.rmd&quot;, &quot;all&quot;) Avec RStudio, que nous utilisons dans ce cours, générer le document final peut se faire de façon encore plus simple. Il sagit dappuyer sur le bouton Knit en haut à gauche dans le menu horizontal du fichier R Markdown. Vous pouvez aussi choisir le format de la sortie dans le menu déroulant associé au bouton Knit : Knit to PDF, Knit to HTML, ou Knit to Word. 2.2.3 À vous de jouer ! Question 1 Suivez la démarche présentée pour créer un fichier R Markdown en choisissant le format de sortie HTML (rappel). Préciser les champs de lentête YAML selon les indications données. Ne modifier pas le contenu du fichier. Créer le document final. a) --- title: &quot;Bonjour Markdown!&quot; author: &quot;Votre nom&quot; date: &quot;La date&quot; abstract: &quot;Ce document HTML constitue ma première tentative de modifier l&#39;entête YAML d&#39;un document R Markdown&quot; description: &quot;Eh bien, je pensais que ce serait plus difficile!&quot; output: html_document: theme: yeti highlight: breezedark --- Réponse Vous devriez obtenir un document semblable à celui-ci. b) --- title: &quot;Document HTML produit avec le thème darkly&quot; author: &quot;Votre nom&quot; date: &quot;la date&quot; output: html_document: theme: darkly toc: true number_section: true --- Réponse Vous devriez obtenir un document semblable à celui-ci. Question 2 Suivez la démarche présentée pour créer un fichier R Markdown en choisissant le format de sortie PDF (rappel). Préciser les champs de lentête YAML selon les indications données. Ne modifier pas le contenu du fichier. Créer le document final. --- title: &quot;Mon premier document PDF produit avec R Markdown&quot; author: &quot;Votre nom&quot; date: &quot;La date&quot; abstract: &quot;Résumez toute votre vie depuis votre naissance jusqu&#39;au moment où vous vous êtes incrit dans le cours SCI 1031!&quot; output: pdf_document: fig_width: 3 fig_height: 3 toc: true number_section: true --- Réponse Vous devriez obtenir un document semblable à celui-ci. https://en.wikipedia.org/wiki/John_Gruber, consulté le 28 avril 2022. https://fr.wikipedia.org/wiki/Aaron_Swartz, consulté le 28 avril 2022. https://fr.wikipedia.org/wiki/ReStructuredText, consulté le 28 avril 2022. https://blog.codinghorror.com/responsible-open-source-code-parenting/, consulté le le 28 avril 2022. Par example Goldmark, https://github.com/yuin/goldmard, un parser Markdown écrit en Go et utilisé par Hugo (un générateur de site très populaire), est compatible avec Common Mark. La version 1 nutilise pas Pandoc. Pandoc est dailleurs capable de gérer différentes variantes de Markdown. Voir https://pandoc.org/MANUAL.html#pandocs-markdown, consulté le 29 avril 2022. Voir https://yihui.org/knitr/), consulté le 29 avril 2022. Voir https://fr.wikibooks.org/wiki/LaTeX/%C3%89crire_des_math%C3%A9matiques, consulté le 29 avril 2022. Voir https://yihui.org/tinytex/, consulté le 29 avril 2022. Par example, si vous travaillez dans un environnement Linux, vous pouvez simplement entrer cette commande dans un terminal: $ echo \"---\\nauthor: VotreNom \\n---\" &gt; mondoc.Rmd Boostrap est une collection doutils pour le design de page web. Voir: https://fr.wikipedia.org/wiki/Bootstrap_(framework)) "],["SRC.html", "Module 3 Systèmes de coordonnées de référence", " Module 3 Systèmes de coordonnées de référence Ce module porte sur les systèmes de coordonnées de référence (SRC). Nous avons vu dans le module 2 que lintégration de couches de données spatiales différentes nécessite quelles soient définies selon le même système de référence spatiale. Cest-à-dire que le modèle mathématique utilisé pour représenter la position des données sur la surface de la Terre doit être le même pour les deux jeux de données. Dans ce module, nous définissons plusieurs concepts cartographiques pour bien comprendre limportance du SRC dans la visualisation, la manipulation et lanalyse de données spatiales. À la fin de ce module vous saurez: Expliquer la différence entre un ellipsoïde local et un ellipsoïde global. Définir ce quest un datum et nommer des datums courants. Expliquer la différence entre le système de coordonnées géographique et le système de coordonnées projeté. Définir les propriétés permettant de catégoriser les projections Nommer des projections courantes. La section exercices est divisée en deux parties. Dans un premier temps, vous réaliserez une auto-évaluation pour vérifier votre acquisition des connaissances enseignées dans ce module. Dans un second temps, vous continuerez votre apprentissage de R Markdown. "],["leçon-1.html", "3.1 Leçon", " 3.1 Leçon Un système de coordonnées de référence (SCR) est un ensemble dinformations qui accompagne un jeu de données spatiales et qui permet de situer ces données sur la surface de la Terre. Ces informations comprennent le modèle utilisé pour représenter la forme de la Terre, cest-à-dire sa géodésie, et le système de mesure utilisé pour définir des coordonnées qui est soit géographique (système à trois dimensions où les coordonnées sont mesurées à partir du centre de la Terre) ou planimétrique (système à deux dimensions où les coordonnées terrestres sont projetées sur une carte plane) (Esri 2016). 3.1.1 Les systèmes géodésiques La géodésie est létude de la forme et des dimensions de la Terre. Au cours de lhistoire, les penseurs et les scientifiques ont adopté divers modèles pour représenter la forme de la Terre (Figure 3.1). Nous référons couramment à la Terre comme un objet rond et nous la représentons comme telle (le globe terrestre!). En vérité, la Terre nest pas sphérique mais légèrement aplatie aux pôles. FIGURE 3.1: Évolution des modèles de la forme de la Terre : un corps plat, une sphère, une ellipsoïde et un géoïde. La Terre est un corps plastique qui est façonné par un ensemble de forces internes et externes lui donnant une forme irrégulière qui évolue continuellement dans le temps (Figure 3.2). En particulier, le champ gravitationnel agit différemment sur les parties solides, semi-rigides et liquides de la Terre car celles-ci ont des densités différentes22. FIGURE 3.2: Les différentes forces internes et externes agissant continuellement sur la Terre. Source : Ressources naturelles Canada. Le géoïde est un modèle de la Terre qui tient compte de leffet du champ gravitationnel. Cest une surface équipotentielle23 du champ de gravité de la Terre qui coïncide avec le niveau moyen des océans (Figure 3.3). FIGURE 3.3: Le géoïde. a) La forme irrégulière du géoïde avec des bosses et de creux créer par le champ gravitationnel agissant de façon inégale sur la Terre (source : Bezdek et Sebera 2013). b) Le géoïde coïncide avec le niveau moyen des océans et se distingue de lellipsoïde (figure adaptée de USGS). La précision avec laquelle nous pouvons lier un endroit sur Terre à un ensemble de coordonnées dépend du modèle du globe choisi. Le géoïde procure une plus grande précision que lellipsoïde, mais lellipsoïde peut être décrit plus facilement par des équations mathématiques. Nous pouvons distinguer deux types dellipsoïdes utilisés en cartographie. Les ellipsoïdes globaux représentent la Terre à léchelle du globe (Figure 3.4). Les ellipsoïdes locaux représentent une petite région du globe (Figure 3.4). La précision dun ellipsoïde local est meilleure que celle dun ellipsoïde global mais uniquement pour des coordonnées situées dans la région quil représente. FIGURE 3.4: Ellipsoïdes global et local. Un ellipsoïde global épouse mieux la forme globale du géoïde, tandis quun ellipsoïde local épouse mieux la forme du géoïde localement dans la région indiquée par la flèche noire. Figure adaptée de Knippers (2009). Un datum est un système de référence qui détermine la position dun ellipsoïde sur la Terre : cest-à-dire son origine par rapport au centre du globe, ainsi que son orientation. Les datums géocentriques sont associés à des ellipsoïdes globaux. Ce sont des systèmes de référence terrestres globaux dont lorigine correspond au centre de masse de la Terre . Puisque aucun ellipsoïde népouse parfaitement la surface de la Terre, il y a toujours une certaine marge derreur à lutilisation dun datum géocentrique (Figure 3.4). La communauté internationale a adopté différent modèles dellipsoïdes globaux au fil du temps avec lamélioration des techniques spatiales de télémétrie et de positionnement (Thériault 2010). Ces ellipsoïdes diffèrent par les paramètres mathématiques utilisés pour les définir. Les principaux systèmes de référence globaux utilisés présentement à travers de monde sont le Geodetic Reference System 1980 (GRS80), adopté par lUnion Géodésique et Géophysique Internationale et le World Geodetic System 1984 (WGS84), défini par le National Geospatial-Intelligence Agency des États-Unis (Figure 3.5). Le Global Positioning System (le GPS) utilise le WGS 84. FIGURE 3.5: Datums globaux. Lorigine de lellipsoïde WGS84 se trouve au centre de masse de la Terre. Lorigine de lellipsoïde GRS80 se trouve à environ 2 m de lorigine de lellipsoïde WGS84. Lellipsoïde Clarke 1866 se trouve à environ 236 m de celle du WGS84. Le datum local NAD27 qui a précédé le NAD83 (voir plus bas) était basé sur lellipsoïde Clarke 1866. Figure adaptée du National Oceanic and Atmospheric Administration, source : https://vdatum.noaa.gov/docs/datums.html Le Cadre international de référence terrestre (ITRF) est un système de référence créé et maintenu par le Service international de la rotation de la Terre et des Systèmes de référence (IERS), un organisme international « qui étudie lorientation de la Terre et établit un système de coordonnées sur la Terre et par rapport à lespace. »24 LITRF nest pas basé sur un modèle dellipsoïde. Il est constitué dun ensemble de repères terrestres dont les coordonnées \\((x,y,z)\\) à la surface de la Terre sont établies à partir du centre de la Terre (Figure 3.6). On se sert de ces repères pour déterminer les paramètres des ellipsoïdes globaux et locaux. À cause du mouvement des plaques tectoniques, les coordonnées des repères de lITRF doivent être réévaluées périodiquement. FIGURE 3.6: Réseau de repères terrestres en vue détablir le prochain ITRF. Source : NASA Earth Observatory Les datums locaux sont associés à des ellipsoïdes locaux. Ce sont des systèmes de référence dont lorigine de lellipsoïde est décalée par rapport au centre de la Terre. Un datum local fait correspondre un point de la surface de lellipsoïde local à un point de la surface de la Terre. Ce point de référence est fixe et il sert « dancrage » au datum. Cest le point dorigine du système de référence local, et il est souvent basé sur une plaque tectonique. Il existe des centaines de datum local servant de système de référence à différentes régions du globe. Il est possible dutiliser le même ellipsoïde pour définir différents datums. Le système de référence utilisé en Amérique du Nord est le North American Datum of 1983 (NAD83). Il est basé sur lellipsoïde GRS80 et est fixé à la plaque tectonique nord-américaine. Le European Terrestrial Reference System of 1989 (ETRS89) est le système de référence utilisé en Europe. Il est aussi basé sur lellipsoïde GRS80 mais est fixé à la plaque tectonique eurasienne. On peut utiliser un datum local seulement pour la région pour laquelle il a été conçu. Ainsi, il serait erroné dutiliser le ETRS89 pour définir la localisation dun phénomène spatial au Québec. FIGURE 3.7: Réseau de repères terrestres. Gauche : un repère du Réseau de base canadien (RBC) situé en Saskatchewan. Droite : un repère du Réseau géodésique de grande précision (RGP) au Québec. Certains repères du RGP font partie du RBC. (source : www.waymarking.com) Le Système canadien de référence spatiale (SCRS) est un datum local créé par le gouvernement canadien spécifiquement pour ces besoins. La majorité des agences fédérales canadiennes qui ont recours à des données spatiales (Ressources naturelles Canada, Pêches et Océan Canada, Agence spatiale canadienne, etc.) utilise ce système de référence. Le SCRS est un quadrillage tridimensionnel (latitude, longitude et élévation) adapté du système NAD83  il est dailleurs appelé le NAD83 (SCRS). Il a été développé dans les années 1990 pour corriger des distorsions denviron 2 m observées entre le NAD 83 et un réseau de points de contrôle (le Réseau de base canadien, RBC, Figure 3.7 suivi par un système global de navigation par satellite (GNSS) (pour en savoir plus consulter cette description du SCRS donnée par Ressources naturelles Canada) (Figure 3.8). FIGURE 3.8: Comparaison entre le NAD83 et le SCRS. Les points rouges sont la localisation de repères selon le SCRS et les lignes bleues représentent les erreurs (décalages) produites par le NAD83 sur ces localisations. Figure tirée de Craymer (2006). 3.1.2 Les systèmes de coordonnées La localisation géographique se fait à partir dun système de coordonnées. Multiples systèmes de coordonnées peuvent être définis, et les coordonnées dun endroit sur Terre différeront selon le système utilisé. Il existe deux types de système de coordonnées : le système de coordonnées géographiques et le système de coordonnées projetées. Le système de coordonnées géographique représente la Terre comme une sphère et donne des coordonnées en trois dimensions pour se situer sur sa surface. Le système géographique est défini par le datum choisi (qui peut être local ou global), une unité angulaire de mesure et un méridien principal (Esri 2016) (Figure 3.9). FIGURE 3.9: Le système de coordonnées géographique. Les points à la surface de la Terre sont définis par les coordonnées sphériques (\\(\\phi\\),\\(\\lambda\\)) associées à la longitude (ligne mauve) et à la latitude (ligne bleue foncée) respectivement. Le point rouge possède les coordonnées (\\(\\phi\\),\\(\\lambda\\)) = (50\\(^{\\circ}\\) E, 40\\(^{\\circ}\\) N). La ligne jaune représente le méridien principal. Source : Esri, image récupérée à https://desktop.arcgis.com/fr/arcmap/10.3/guide-books/map-projections/geographic-coordinate-system.htm Les coordonnées sphériques (\\(\\phi\\), \\(\\lambda\\)) dun point sur la surface de la Terre correspondent à sa longitude et à sa latitude respectivement (Figure 3.9). On exprime ces coordonnées en degrés (degrés, minutes, secondes (DMS) ou degré décimal (D,D)). Le système géographique forme ce que lon appelle un graticule sur la surface de la Terre (Figure 3.10). Cest une grille composée de lignes horizontales, appelées les parallèles, et de lignes verticales, appelées les méridiens. Le parallèle de latitude zéro constitue léquateur, alors que le méridien de longitude zéro constitue le méridien principal. Dans la plupart des systèmes de coordonnées géographiques, le méridien qui traverse lObservatoire royal de Greenwich en Angleterre correspond au méridien principal. FIGURE 3.10: Graticule. Les parallèles et les méridiens forment un graticule. Source : Esri, image récupérée à https://desktop.arcgis.com/fr/arcmap/10.3/guide-books/map-projections/about-geographic-coordinate-systems.htm Le système de coordonnées projeté, quant à lui, réfère à une transformation mathématique permettant de représenter sous forme de carte plane la réalité tridimensionnelle de la Terre (Figure 3.11). FIGURE 3.11: Le système de coordonnées projeté. Il permet de représenter sur une surface plane bidimensionnelle la surface tridimensionnelle de la carte à laide dune transformation mathématique \\((x,y) = f(\\phi, \\lambda)\\) Les systèmes de coordonnées projetés sont nécessaires pour la création de cartes géographiques. Cependant, puisquil est impossible de représenter parfaitement la surface dun objet tridimensionnel sur une carte plane, les systèmes projetés génèrent certaines distorsions (ou déformations) : forme, distance, direction, etc. Par ailleurs, toutes les projections conservent un élément important de la cartographie : la précision de la localisation géographique. 3.1.3 Les projections On peut catégoriser les systèmes de coordonnées projetés selon la classe de transformations mathématiques utilisées, le type dintersections entre le globe et le plan, lorientation du plan, et le type de distorsions créé sur le plan. Classes de transformations On distingue trois classes principales de transformation pour créer un système de coordonnées projeté (Figure 3.12). Cylindrique : la surface de la Terre est projetée sur un plan enroulé comme un cylindre. Généralement le cylindre coïncide avec le globe le long dun parallèle (p.ex. léquateur). Conique : la surface de la Terre est projetée sur un cône. Le cône et le globe coïncident le long dun ou de deux parallèles. Pour aplanir le cône, il est découpé le long dun méridien, généralement le méridien opposé au méridien principal. Azimutale (ou plane) : la surface de la Terre est projetée directement sur un plan. Celui-ci touche généralement le globe à un seul point (p.ex. le pôle Nord). FIGURE 3.12: Classes de projection: cylindrique (gauche), conique (centre) et azimutale (droite). Toutes les projections illustrées utilisent un plan de projection qui est tangent à la surface de la Terre. Source : Esri. Image adaptée dillustrations récupérées à https://desktop.arcgis.com/en/arcmap/10.3/guide-books/map-projections/projection-types.htm Types dinsersection Il existe deux types dintersection entre un plan et la surface du globe (Figure 3.13). Tangente : le plan touche la surface du globe à un seul point (azimutal) ou le long dune seule ligne (cylindrique et conique). Les transformations illustrées à la Figure classes sont toutes tangentes. Sécante : le plan traverse la surface du globe le long dune seule ligne (azimutal) ou le long de deux lignes (cylindrique et conique). Ces lignes sont appelées les parallèles standards. Les transformations illustrées à la Figure intersection sont toutes sécantes. Notez quil ny a pas de distorsion au point ou à la ligne dintersection car à cet endroit les systèmes de coordonnées géographiques et projetés coïncident parfaitement. FIGURE 3.13: Plans de projection sécants avec le globe. Illustrations pour les classes de projection cylindrique (gauche), conique (centre) et azimutale (droit). Source : Esri. Image adaptée dillustrations récupérées à https://desktop.arcgis.com/en/arcmap/10.3/guide-books/map-projections/projection-types.htm Orientation Le plan de projection peut être positionné selon trois différentes orientations par rapport au globe. Normale : le plan est parallèle par rapport à laxe Nord-Sud du globe. Les transformations illustrées aux Figure classes et intersection sont toutes normales. Transverse : le plan est perpendiculaire à laxe Nord-Sud du globe (Figure 3.14 gauche). Oblique : le plan est ni parallèle ni perpendiculaire à laxe Nord-Sud du globe (Figure 3.14 droite). FIGURE 3.14: Orientations du plan de projection. Orientation transversale (gauche), aussi appelée équatoriale pour la projection azimutale, et orientation oblique (droit). Source : Esri. Image adaptée dillustrations récupérées à https://desktop.arcgis.com/en/arcmap/10.3/guide-books/map-projections/projection-types.htm Distorsion Les projections produisent toutes une certaine forme de distorsion. On caractérise un système de coordonnées projeté selon la propriété quil conserve, c-à-d la propriété quil ne déforme pas. Il y a trois propriétés importantes qui sont ou non conservées (en tenant compte de léchelle de la carte): la forme, la superficie et la distance. Conforme : la projection conserve localement les angles entre les droites. Les cartes de navigation, notamment, sont produites par des projections conformes pour mesurer adéquatement la direction de trajectoires. La conformité implique également la conservation de la forme des régions de petite superficie. Équivalente : la projection conserve localement laire des régions. Les atlas géographiques emplois souvent des cartes produites par des projections équivalentes pour éviter les biais dans la représentation des superficies de différentes régions du monde. Équidistante : la projection conserve les distances sur certaines lignes du globe, généralement les méridiens. Aucune projection ne peut être à la fois conforme et équivalente. Plusieurs projections offrent des compromis entre ces deux propriétés. Il existe plus de deux cent projections distinctes créées au cours de lHistoire par les scientifiques, notamment des astronomes, des géographes, et des navigateurs. La figure 3.15 illustre un petit sous-ensemble de projections. La projection cylindrique équidistante (coin supérieur gauche de la figure 3.15 a été créée par Marinus de Tyr, un astronome dorigine phénicienne, vers lan 100. Plusieurs projections sont identifiées par le nom de la personne qui en a fait la découverte. Par exemple, Gérard Mercator est un mathématicien et géographe flamand du 16e siècle, et Jean-Henri Lambert est un mathématicien, cartographe et astronome dorigine alsacienne du 18e siècle. FIGURE 3.15: Sélection de 12 projections. Lensemble des cartes est tiré du site : https://map-projections.net/ Je vous invite à consulter le site très intéressant de Tobias Jung où un grand nombre de projections est répertorié. Vous pouvez connaître les propriétés des projections et aussi comparer deux projections entre elles. Jetez-y un coup dil! Sur ce site vous pourrez apprendre, par exemple, que les projections de Mollweide, de Bonne, Equal Earth et eumorphique de Boggs sont équivalentes, alors que les projections de Mercator et de Lagrange sont conformes. Les projections de Mercator et cylindrique équidistante, comme son nom lindique, sont équidistantes. Lindicatrice de Tissot permet dillustrer les déformations produites par une projection (Figure 3.16). Cette indicatrice porte le nom du cartographe français, Nicolas Auguste Tissot, qui la créé au 19e siècle. Le niveau de changement de la taille et de la forme des cercles rouges permet de repérer les endroits sur la carte de plus fortes déformations. FIGURE 3.16: Indicatrice de Tissot pour les 12 projections de la figure 3.15. Lensemble des cartes est tiré du site : https://map-projections.net/ 3.1.4 Projections couramment utilisées Projection de Mercator La projection de Mercator (Figure Mercator, Figure projections et Figure tissot coin supérieur droit) est une projection cylindrique conforme. Les méridiens y sont parallèles et équidistants. Les parallèles (les lignes de latitude) sont aussi parallèles. Cependant, elles sécartent les unes des autres au fur et à mesure quelles séloignent de léquateur (Esri 2016). La projection de Mercator fût originalement conçue pour la navigation puisquelle préserve les angles. Elle préserve aussi les formes ce qui la rend très populaire pour la cartographie aux échelles régionales. Par ailleurs, la projection de Mercator ne préserve pas les superficies. Elle génère de grandes distorsions aux pôles (Figure 3.16 coin supérieur droit). Par exemple, la superficie du Groenland apparait être aussi grande que celle de lAfrique sur une projection de Mercator (Figure 3.17, gauche). En vérité, la superficie du Groenland (2 166 086 km\\(^{2}\\), en mauve sur la Figure Mercator, droit) est inférieure à celle de lAlgérie (2 381 741 km\\(^{2}\\), en orange sur la Figure 3.17, droit). Ces distorsions rendent la projection de Mercator peu adéquate pour produire des cartes à léchelle mondiale. FIGURE 3.17: Projection de Mercator. À gauche, on observe que les méridiens sont équidistants tandis que les parallèles sécartent en se dirigeant vers les pôles (source : Tobias Jung, https://map-projections.net/). À droite, on observe que la superficie réelle du Groenland (en mauve) est similaire à celle de lAlgérie (source : https://thetruesize.com/ Les services de cartographie en ligne, comme Google Maps, OpenStreetMap, Bing Maps ou Mapquest, utilise la projection Web de Mercator (avec le datum WGS84). Cette projection est légèrement différente de la projection usuelle de Mercator (elle utilise la transformation sphérique plutôt que ellipsoïdal) produisant des cartes qui ne sont pas tout à fait conformes (PROJ contributors 2020). Projection Transverse universelle de Mercator La projection Transverse universelle de Mercator (en anglais Universal Transverse Mercator, UTM) est une projection cylindrique transverse sécante (Figure 3.18. Le globe est séparé en 60 zones au nord et au sud de léquateur. Chaque zone couvre 6\\(^{\\circ}\\) et est défini en son centre par un méridien central. Les zones sont numérotées de 1 à 60 en suivant la convention selon laquelle la zone 1 couvre la région allant de 180\\(^{\\circ}\\) à 174\\(^{\\circ}\\) ouest (0\\(^{\\circ}\\) correspondant au méridien de Greenwich). Les zones ne couvrent pas les pôles, elles sarrêtent à la latitude de 84\\(^{\\circ}\\) au nord et de 80\\(^{\\circ}\\) au sud. FIGURE 3.18: Projection transverse universelle de Mercator. Gauche : le globe est découpé en tranches de 6\\(^{\\circ}\\), 3\\(^{\\circ}\\) de part et dautre dun méridien central (source : https://www.swisstopo.admin.ch/). Droite : La surface entière de la Terre est représentée par 60 zones (source : https://www.icsm.gov.au/). La projection transverse de Mercator est réalisée sur chacune des zones de façon distincte. Nous obtenons donc 60 projections différentes. Chaque zone présente des distorsions, mais puisque les zones sont petites (6\\(^{\\circ}\\)), les distorsions sont limitées. Les coordonnées dun point dans ce système projeté sont données dabord par le numéro de la zone dans laquelle il se situe, puis par sa position au sein de la zone, cest-à-dire par sa longitude et sa latitude mesurées en mètre. On utilise souvent les appellations anglaises pour désigner les longitudes, eastings, et les latitudes, northings. Par convention, on associe au méridien central la longitude de 500000 m (500 km). Si le point se situe à louest du méridien central, sa longitude est déterminée en soustrayant la valeur 500000 m de la distance à laquelle il se trouve du méridien. À lopposé, si le point se trouve à lest du méridien central, sa longitude sera déterminée en ajoutant 500000 m à la distance qui le sépare du méridien. Les latitudes sont déterminées à partir de léquateur. Dans lhémisphère nord, léquateur correspond à lorigine (0 m) et la latitude dun point est déterminée par la distance qui le sépare de léquateur. Dans lhémisphère sud, léquateur correspond à la valeur 10 000 000 m, et la latitude dun point est déterminée en soustrayant à 10 000 000 m la distance qui le sépare de léquateur (Figure 3.19). Ces conventions sont utilisées de manière à avoir toujours des coordonnées positives dans la zone couverte par la projection. FIGURE 3.19: Longitudes et latitudes à lintérieur dune zone de la projection UTM. Source : http://geokov.com/ Le Canada sétend de la zone 7 à la zone 22, alors que le Québec couvre les zones 17 à 21 (Figure 3.20). Notez que les zones sont aussi appelées des fuseaux. FIGURE 3.20: Projection Universelle Transverse de Mercator au Québec. Source: Lapointe (2005) Pour réduire les problèmes liés aux déformations associées au système UTM, le Québec sest doté de son propre système : la projection modifiée transverse de Mercator (MTM). Le système MTM est identique au système UTM à la différence que chaque zone couvre une longitude de 3\\(^{\\circ}\\). Les zones étant plus petites, les distorsions sont réduites. Les zones sont numérotées de 1 à 8 débutant aux Iles-de-la-Madeleine et se terminant en Abitibi (Figure 3.21). On associe au méridien central des zones MTM la longitude de 304800 m. FIGURE 3.21: Projection Mercator Transverse Modifiée au Québec. Source: Lapointe (2005) Projection conique conforme de Lambert La projection conique conforme de Lambert (LCC) conserve, comme son nom lindique, la forme des régions ainsi que les angles. Cette projection est également sécante : il ny a de distorsion le long des deux parallèles standards (Figure 3.22). La projection LCC est particulièrement utile pour représenter les régions de latitudes moyennes, comme lAmérique du Nord, mais elle est également utilisée en Europe. FIGURE 3.22: Projection conique conforme de Lambert. Source : United States Geological Survey, récupérée sur Wikipedia La position des parallèles standards varie selon la région du globe représentée. Au Canada, elles sont généralement situées à 49 N et 77 N. La carte ci-dessous du Canada (Figure 3.23) utilise une projection LCC pour présenter les résultats des élections fédérales 2019. FIGURE 3.23: Un exemple de projection conique de Lambert. La carte des résultats des élections fédérales canadiennes de 2019. Source : Élections Canada. 3.1.5 Représentation dun SCR Les données spatiales doivent toujours être accompagnées de linformation permettant de connaître le système de coordonnées de référence qui leur est associé. Ces métadonnées peuvent être représenter (ou encoder) de différentes façons. Le Well-known text Le format Well-known text (WKT) est une syntaxe standard utilisée pour représenter les données vectorielles et aussi les SCR des données vectorielles et matricielles. Ce format consiste en une série détiquette de la forme [...] associée à différentes informations relatives au SCR. Par exemple: Reading layer `pistes_cyclables_type&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module4\\Module4_donnees\\Montreal_Velo\\pistes\\pistes_cyclables_type.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 6395 features and 1 field Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: 268000 ymin: 5029000 xmax: 306300 ymax: 5063000 Projected CRS: Transverse_Mercator Coordinate Reference System: User input: Transverse_Mercator wkt: PROJCRS[&quot;Transverse_Mercator&quot;, BASEGEOGCRS[&quot;NAD83&quot;, DATUM[&quot;North American Datum 1983&quot;, ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101, LENGTHUNIT[&quot;metre&quot;,1]], ID[&quot;EPSG&quot;,6269]], PRIMEM[&quot;Greenwich&quot;,0, ANGLEUNIT[&quot;Degree&quot;,0.0174532925199433]]], CONVERSION[&quot;unnamed&quot;, METHOD[&quot;Transverse Mercator&quot;, ID[&quot;EPSG&quot;,9807]], PARAMETER[&quot;Latitude of natural origin&quot;,0, ANGLEUNIT[&quot;Degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8801]], PARAMETER[&quot;Longitude of natural origin&quot;,-73.5, ANGLEUNIT[&quot;Degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8802]], PARAMETER[&quot;Scale factor at natural origin&quot;,0.9999, SCALEUNIT[&quot;unity&quot;,1], ID[&quot;EPSG&quot;,8805]], PARAMETER[&quot;False easting&quot;,304800, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8806]], PARAMETER[&quot;False northing&quot;,0, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8807]]], CS[Cartesian,2], AXIS[&quot;(E)&quot;,east, ORDER[1], LENGTHUNIT[&quot;metre&quot;,1, ID[&quot;EPSG&quot;,9001]]], AXIS[&quot;(N)&quot;,north, ORDER[2], LENGTHUNIT[&quot;metre&quot;,1, ID[&quot;EPSG&quot;,9001]]]] La syntaxe PROJ4 La syntaxe PROJ4 consiste en une liste de paramètres précédés par le symbole +. Elle donne une représentation du CRS de façon beaucoup plus concise. Voici un exemple: [1] &quot;+proj=tmerc +lat_0=0 +lon_0=-73.5 +k=0.9999 +x_0=304800 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; Les paramètres principaux ont la signification suivante: +proj : le nom de la projection +datum : le nom du datum +ellps : le nom de lellipsoïde +zone : le numéro de la zone pour une projection UTM +lat_0 : la latitude de lorigine +lat_1 : la latitude du premier parallèle standard25 +lat_2 : la latitude du deuxième parallèle standard +lon_0 : la longitude du méridien central +x_0 : le faux est (false easting; dans le cas de projection transverse comme UTM) +y_0 : le faux nord (false northing) +units : les unités (mètres, degrés, etc.) +k_0: facteur déchelle Vous pouvez trouver dautres paramètres ici. Les codes EPSG Le Comité de topographie et de positionnement (Surveying and Positionning Comittee) de lAssociation internationale des producteurs de pétrole et de gaz (OGP), autrefois le European Petroleum Survey Group (EPSG), est une organisation scientifique liée à lindustrie pétrolière qui a mis en place une base de données répertoriant tous les systèmes de référence et les systèmes de coordonnées géographiques et projetés existants. Cette base de données, appelée le registre de codes EPSG, associe un code numérique à chaque système pour en faciliter lidentification et précise ses paramètres géodésiques et de projection. Vous pouvez consulter cette base de données ici. Vous pouvez aussi utiliser le site https://epsg.io/ et entrez Quebec dans la fenêtre de recherche pour connaître les codes EPGS utilisés au Québec. Par exemple : NAD83 : 4269 NAD83 (SCRS): 4617 WGS84: 4326 Ou encore: Le fuseau 2 de la projection MTM basé sur le NAD83 : 32182 La projection Web de Mercator : 3857. 3.1.6 Résumé La figure ci-dessous (Figure 3.24) résume les étapes du processus utilisé pour définir un système de coordonnées géographique et un système de coordonnées projeté. FIGURE 3.24: Résumé. Les étapes du processus pour définir un système de coordonnées géographique et un système de coordonnées projeté. Source : la figure utilise des pictogrammes créés par T. Grajecta (Noun Project) Lorsquon représente des données spatiales par un système de coordonnées géographique, il faut toujours préciser le datum qui a été adopté. Lorsquon représente des données spatiales par un système de coordonnées projeté, il faut toujours préciser le datum et la projection. Lorsquon combine des couches de données différentes, on doit sassurer quelles sappuient sur le même datum et la même projection. Si ce nest pas le cas, on peut transformer le système de référence et le système de projection. Nous verrons comment procéder à ces transformations dans le module 7 et le module 8. Source: Le Québec géographique Une surface où le potentiel est constant et qui est en tous points perpendiculaire à la direction dans laquelle sexerce la pesanteur. Une surface équipotentielle est de niveau, c.-à-d. que leau y reste au repos. Définition de Ressources Naturelles Canada Définition selon Wikipédia Souvenez-vous que pour une projection cylindrique ou conique, le plan intersecte le globe le long dun ou de deux parallèles. Voir la leçon 2 "],["ex_markdown2.html", "3.2 Exercices", " 3.2 Exercices Dans cette section nous poursuivons lintroduction à R Markdown entamée dans la section Exercices du module 2. Rappelons les objectifs de cette introduction. Décrire en quoi consiste R Markdown; Décrire les liens entre R, Markdown et Pandoc; Utiliser la syntaxe Pandoc Markdown de base; Créer des documents dynamiques avec la bibliothèque rmarkdown. Cette introduction à RMarkdown a été rédigée par Kevin Cazelles, collobateur clé à réalisation de ce cours. Kevin est un chercheur en écologie computationnelle et fervent utilisateur des outils pour la science ouverte. Allez voir ses travaux sur son site https://kevcaz.insileco.io/ et son profil GitHub https://github.com/KevCaz. 3.2.1 Le variante Pandoc de Markdown Dans cette partie, nous détaillons les éléments de formatage du texte proposés par la syntaxe Pandoc de Markdown26 Informations de départ De façon générale, nous écrivons du texte dans un fichier R Markdown de la même façon que nous le ferions dans un document Word. Nous pouvons, par exemple, écrire des accents français sans problème. Les paragraphes Pour créer des paragraphes, il faut ajouter une ligne (ou plus) vide entre les paragraphes. Ainsi, avec les lignes suivantes : Un datum est un système de référence qui détermine la position dun ellipsoïde sur la Terre : cest-à-dire son origine par rapport au centre du globe, ainsi que son orientation. Les datums géocentriques sont associés à des ellipsoïdes globaux. Ce sont des systèmes de référence terrestres globaux dont lorigine correspond au centre de masse de la Terre. nous obtenons : Un datum est un système de référence qui détermine la position dun ellipsoïde sur la Terre : cest-à-dire son origine par rapport au centre du globe, ainsi que son orientation. Les datums géocentriques sont associés à des ellipsoïdes globaux. Ce sont des systèmes de référence terrestres globaux dont lorigine correspond au centre de masse de la Terre. Notez quavec un simple retour à la ligne, aucun saut de ligne nest inséré. Les paragraphes sont alors affichés bout à bout. Par exemple, ce texte: Un datum est un système de référence qui détermine la position dun ellipsoïde sur la Terre : cest-à-dire son origine par rapport au centre du globe, ainsi que son orientation. Les datums géocentriques sont associés à des ellipsoïdes globaux. Ce sont des systèmes de référence terrestres globaux dont lorigine correspond au centre de masse de la Terre. saffiche comme ceci: Un datum est un système de référence qui détermine la position dun ellipsoïde sur la Terre : cest-à-dire son origine par rapport au centre du globe, ainsi que son orientation. Les datums géocentriques sont associés à des ellipsoïdes globaux. Ce sont des systèmes de référence terrestres globaux dont lorigine correspond au centre de masse de la Terre. Il est cependant possible dajouter un retour à la ligne en utilisant un retour à la ligne et tabulation à la fin du premier paragraphe. Par exemple, ce texte: Un datum est un système de référence qui détermine la position dun ellipsoïde sur la Terre : cest-à-dire son origine par rapport au centre du globe, ainsi que son orientation. Les datums géocentriques sont associés à des ellipsoïdes globaux. Ce sont des systèmes de référence terrestres globaux dont lorigine correspond au centre de masse de la Terre. saffiche comme ceci: Un datum est un système de référence qui détermine la position dun ellipsoïde sur la Terre : cest-à-dire son origine par rapport au centre du globe, ainsi que son orientation. Les datums géocentriques sont associés à des ellipsoïdes globaux. Ce sont des systèmes de référence terrestres globaux dont lorigine correspond au centre de masse de la Terre. La seule différence entre cet exemple et lexemple précédent est lajout dune tabulation après orientation.. Les symboles réservés Certains symboles sont réservés au formatage du texte. Lorsque leur affichage est requis, cest-à-dire lorsque nous désirons les utiliser dans notre texte, nous devons les faire précéder du caractère déchappement qui est, pour Markdown, lantislash : \\. Par exemple, nous devons entrer  : \\\\ \\&amp; \\# \\$ \\[ Pour obtenir : \\ &amp; # $ [ Les commentaires Pour rédiger des commentaires dans le texte qui ne seront pas affichés dans le document final, nous utilisons &lt;!-- devant le commentaire et --&gt; après celui-ci. Décoration du texte Pour écrire du texte en italique, vous avez deux possibilités : *le texte à mettre en italique* _le texte à mettre en italique_ Pour écrire du texte en gras, vous avez aussi deux possibilités : **le texte à mettre en gras** __le texte à mettre en gras__ Pour écrire du texte en gras et italique, utilisez : **le _texte en italique et en gras_** Pour obtenir un texte rayé, entrez : ~~texte rayé~~ Pour écrire un élément en exposant, utilisez : ^texte en exposant^ Pour écrire un élément en indice, tapez : ~texte en indice~ Notez quil ny a pas de balises pour le soulignement du texte. De manière générale, quand un élément de mise en page manque dans la syntaxe, il est toujours possible dutiliser des commandes dun langage. Par exemple, pour souligner dans un document qui sera produit en HTML, je peux utiliser &lt;u&gt;texte souligné&lt;/u&gt; mais cela ne me permettra pas davoir un texte souligné en Word ou en PDF. De même que si jutilise \\underline{texte souligné} le texte sera souligné en PDF, mais pas en HTML ni en Word. Procéder de la sorte nest pas toujours souhaité car le document R Markdown perd en généralité, en ce sens où il ne pourra pas être correctement généré dans tous les formats. Cela nest cependant pas nécessairement un problème, par exemple, si vous souhaiteZ obtenir le document en un seul format, ce fonctionnement devient un atout puisque vous pouvez utiliser toute la gamme de mise en forme offert par le langage en question. Les titres La façon la plus simple de désigner les titres dans un texte se fait par lutilisation du symbole # (ATX heading). Un seul # désigne un titre de premier niveau, et nous utilisons un nombre croissant de # pour descendre dans larborescence des titres: # Un titre d&#39;ordre 1 ## Un titre d&#39;ordre 2 ### Un titre d&#39;ordre 3 Il est aussi possible dutiliser une série de = en dessous des titres de premier niveau et une ligne de - en dessous des titres de niveau 2. Cette option a la qualité de permettre de repérer facilement les titres dans le code source. Un titre d&#39;ordre 1 ================== Un titre d&#39;ordre 2 ------------------ ### Un titre d&#39;ordre 3 Les listes Les listes sont très intuitives en Markdown, alors quelles requièrent des balises un peu lourdes aussi bien en Latex quen HTML. Dans les exemples donnés, il faut toujours séparer le texte principal de la liste par des sauts de ligne. Listes non numérotées Pour obtenir une liste non numérotée, nous pouvons utiliser le symbole *  : * objet 1, * objet 2, * objet 3. ou bien le symbole +  : + objet 1, + objet 2, + objet 3. ou encore le symbole -  : - objet 1, - objet 2, - objet 3. et même  : + objet 1, * objet 2, - objet 3. Dans tous les cas, la liste produite saffiche ainsi : objet 1, objet 2, objet 3. Listes espacées Pour produire une liste plus aérée, nous pouvons ajouter un espace entre les éléments de la liste. Lorsque le document produit est en HTML, ce formatage produit une balise paragraphe (cest-à-dire que &lt;p&gt; &lt;/p&gt; est ajouté). * objet 1, * objet 2, * objet 3. devient: objet 1, objet 2, objet 3. Listes hiérarchisées Pour créer des listes hiérarchisées, il sagit dutiliser une indentation de quatre espaces (ou une tabulation) entre chaque niveau. Par exemple, ceci: - objet 1, + machin 1 - chose 1 - chose 2 + machin 2 - objet 2, - objet 3. produit cette liste: objet 1, machin 1 chose 1 chose 2 machin 2 objet 2, objet 3. Listes avec du texte ou du code Pour alterner des éléments dune liste avec du texte ou du code, il faut utiliser des sauts de lignes avec lindentation adéquate. Ainsi, avec les lignes suivantes : - élément 1&amp;nbsp;: Un petit texte qui pourrait expliciter ce qu&#39;est l&#39;élément 1. - machin 2: for (i in 1:2) print(i) nous obtenons : élément 1 : Un petit texte qui pourrait expliciter ce quest lélément 1. machin 2: for (i in 1:2) print(i) Listes numérotées Pour créer une liste numérotée, il suffit de numéroter chaque élément de la liste. Par exemple: 1. machin 1, 2. machin 2, 3. machin 3. produit ceci: machin 1, machin 2, machin 3. Si les nombres ne sont pas écrits manière ordonnée, cela ne changera pas le résultat. Néanmoins, le premier nombre détermine le numéro de départ de la liste. En écrivant : 3. machin 1, 3. machin 2, 3. machin 3, 5. machin 4. nous obtenons: machin 1, machin 2, machin 3, machin 4. Pour ne pas se soucier des numéros, il existe un style par défaut : #. machin 1, #. machin 2, #. machin 3. Nous retrouvons bien la première liste numérotée : machin 1, machin 2, machin 3. Plusieurs styles de numérotation sont disponibles. Par exemple, en écrivant : #) élément 1 #) élément 2 #) élément 3 (1) truc 1 (2) truc 2 (5) truc 3 i. machin 1 i. machin 2 i. machin 3 nous obtenons : élément 1 élément 2 élément 3 truc 1 truc 2 truc 3 machin 1 machin 2 machin 3 Nous avons aussi la possibilité de mélanger les niveaux numérotés et les niveaux non-numérotés. Par exemple, cette liste 1. machin 1, 1. machin 1.1, 2. machin 1.2, 2. machin 2, - machin 2.1, - machin 2.2, - machin 3, 3. machin 4, 4. machin 5. donne ceci  : machin 1, machin 1.1, machin 1.2, machin 2, machin 2.1, machin 2.2, machin 3, machin 4, machin 5. Enfin, il possible de mettre manuellement fin à une liste en introduisant un commentaire entre les listes à séparer : (1) truc 1 (2) truc 2 (3) truc 2b &lt;!-- end --&gt; (1) truc 3 (2) truc 4 ces lignes sont rendues ainsi : truc 1 truc 2 truc 2b truc 3 truc 4 Blocs de citation Pour utiliser un bloc de citation (la balise blockquote en HTML), il suffit dutiliser &gt; avant la citation. Ainsi les lignes suivantes : &gt; la citation est ajoutée comme ceci, elle nous donne une indentation adéquate pour une mise en page agréable dont le style peut être facilement travailler en HTML grâce au CSS. deviennent : La citation est ajoutée comme ceci, elle nous donne une indentation adéquate pour une mise en page agréable dont le style peut être facilement travailler en HTML grâce au CSS. Pour créer une hiérarchie dans les citations, nous ajoutons des &gt;  : &gt; La citation de départ &gt; &gt;&gt; une hiérarchie dans la citation ce qui donne : La citation de départ une hiérarchie dans la citation Les symboles matématiques Pour utiliser les symboles mathématiques dans le texte, les commandes associées doivent être placées entre deux $. Bien sûr, il faut connaître les combinaisons de caractère associées aux différents symboles. Ce sont les même que celles proposées par Latex et qui seront utilisées par MathJax (par défaut) pour générer les expressions mathématiques dans le fichier html. Voici quelques exemples : Lettres grecques : $\\alpha$, $\\beta$, $\\delta$, $\\lambda$, $\\pi$, $\\phi$, $\\omega$, $\\varpi$, $\\vartheta$ devient : \\(\\alpha\\), \\(\\beta\\), \\(\\delta\\), \\(\\lambda\\), \\(\\pi\\), \\(\\phi\\), \\(\\omega\\), \\(\\varpi\\), \\(\\vartheta\\) Symboles mathématiques : $\\sum$, $\\prod$, $\\int$, $\\infty$, $\\lim$ devient : \\(\\sum\\), \\(\\prod\\), \\(\\int\\), \\(\\infty\\), \\(\\lim\\) Combinaisons de symboles : $\\mu \\in\\mathbb{R}$, $\\lim_{x \\rightarrow 3} f(x)$ devient : \\(\\mu \\in\\mathbb{R}\\), \\(\\lim_{x \\rightarrow 3} f(x)\\) Pour explorer dautres exemples, regarder ce site, ou celui-ci pour des informations plus complètes. Les images Deux options sont offertes pour insérer une image dans un document : Loption dite inline. Dans celle-ci, la légende de limage est donnée entre crochets, précédée dun point dexclamation, et suivie du chemin vers le fichier de limage entre parenthèses. Par exemple, ![Le logo de R](./images/Rlogo.png) Retourne cette image: Le logo de R Loption dite reference. Dans celle-ci, nous assignons dabord un identifiant à limage qui spécifie le chemin vers le fichier de limage. Par exemple: [img2]: ./images/Rlogo.png Nous pouvons alors afficher limage, en référant à son identifiant de la façon suivante: ![Encore le logo R!][img2] Ce qui produit: Encore le logo R! Les tableaux La création facilitée de tableaux est lune des extensions bien utile de Pandoc Markdown. Il existe plusieurs extensions pour faire des tableaux. Pour plus dinformation, nous vous recommandons la page écrite par Jean-Daniel Bonjour sur ce sujet. Donnons lexemple dun tableau produit avec le style pipe table: | Aligné à gauche | Aligné au centre | Par défaut | Aligné à droite | :------- | :-------: | ------ | -------: | truc 1.1 | truc 2.1 | **_truc 3.1_** | truc 4.1 | truc 1.2 | truc 2.2 | ~~truc 3.2~~ | truc 4.2 | truc 1.3 | truc 2.3 | *truc 3.3* | truc 4.1 : La légende associée au tableau. Ce code produira le tableau suivant: La légende associée au tableau. Aligné à gauche Aligné au centre Par défaut Aligné à droite truc 1.1 truc 2.1 truc 3.1 truc 4.1 truc 1.2 truc 2.2 truc 3.2 truc 4.2 truc 1.3 truc 2.3 truc 3.3 truc 4.1 Pour créer un tableau grâce à une interface de type WYSIWYG (What you see is what you get), vous pouvez utiliser ce générateur. Les références Les hyperliens Les liens hypertextes sont utilisés sous la forme [groupe de mots sur lequel cliquer]+(adresse du lien). Pour créer un lien vers la page Markdown de Wikipedia, nous utilisons : [Markdown](https://fr.wikipedia.org/wiki/Markdown) et voilà le lien vers la page Markdown de Wikipedia. Les notes de bas de pages Nous pouvons produire une note de bas de page en plaçant la balise [^id] là où la note doit être insérée. Pour préciser le texte qui y est associé, nous ajoutons [^id]:texte associé à nimporte quel endroit du document. Il faut, par ailleurs, respecter la condition que les notes de bas pages (rassemblées ou non) soient séparées du reste du texte par un saut de ligne. Nous suggérons de rassembler les notes dune section à la fin de la section en question. Par exemple : Un bout de texte avec une note[^note1] et une autre [^note2]. [^note1]: à la fin d&#39;une section par exemple. [^note2]: ou encore, à la fin du document. Ceci produit le texte suivant: Un bout de texte avec une note27 et une autre28. 3.2.2 Intégration de R dans le document Lintérêt du package rmarkdown est détendre la syntaxe Pandoc Markdown avec les fonctionnalités du package knitr pour insérer non seulement du code R mais aussi les sorties associées (sorties console et figures). Nous obtenons ainsi un document dynamique en ce sens que si les données associées et/ou le code R changent, le document évolue aussi. Cela permet, entre autres, de créer des rapports automatisés. Il y existe deux manières dinsérer des sorties R dans le document: directement dans le texte (inline); en utilisant un bloc de code dédié. Pour inclure une sortie texte directement dans un paragraphe, nous utilisons  : `r expression`. Par exemple, il est possible dinsérer lheure et la date en utilisant la fonction R Sys.time(). Ainsi, lutilisation de `r Sys.time()`  dans le texte affichera la sortie de cette fonction R, soit 2023-03-07 10:47:13. Le reste de cette section se concentre sur les blocs de code R (appelés code chunks en anglais). Typiquement, lutilisation dun tel bloc de code ressemble à ceci : ```{r, idbloc, param1 = val1, param2 = val2} ligne de code 1 ligne de code 2 ... ligne de code n ``` idbloc est le nom de lidentifiant que vous pouvez donner au bloc de code. Ceci permet de citer les blocs ou leurs sorties à lintérieur du document. Lidentifiant nest pas obligatoire. En revanche, un identifiant donné ne peut être utilisé quune seule fois. param1 = val1 correspond à un paramètre permettant de préciser comment le code source sera affiché dans le document, ou comment la sortie du code sera affichée. Il existe un grand nombre de paramètres possibles. Ils permettent de mettre de lavant certaines parties du code, et aussi de choisir finement les sorties R (figures, tables, etc.) à ajouter aux documents. Lensemble des paramètres sont disponibles à lURL suivante https://yihui.org/knitr/options/). Les commentaires Les commentaires sont introduits, comme dans R, sous la forme de lignes de code commençant par un #. Débutons avec un exemple simple qui inclut un commentaire et une addition : ```{r, addition} # une addition avec R. 2+3 ``` Notez que le terme addition qui suit r dans laccolade est lidentifiant du morceau de code (la virgule entre les deux premiers éléments est facultative). Ce morceau de code saffiche ainsi: # une addition avec R. 2+3 [1] 5 Nous obtenons donc un code R dans un environnement adéquate (voir la coloration du code) avec la sortie console associée, en loccurrence, le résultat de laddition. Affichage du code source Le paramètre echo Prenons le bloc de code suivant. ```{r} # une addition de variables avec R a &lt;- 2 b &lt;- 3 a + b ``` Celui-ci saffiche comme: # une addition de variables avec R a &lt;- 2 b &lt;- 3 a + b [1] 5 Afin de ne pas afficher le code source dans un document (parce que nous souhaitement uniquement afficher la sortie produite par le code), il suffit dutiliser le paramètre echo = FALSE. Par défaut, nous avons que echo = TRUE. Ainsi, le bloc de code sanscode ```{r sanscode, echo = FALSE} # une addition de variables avec R a &lt;- 2 b &lt;- 3 a + b ``` nous donne uniquement la sortie, sans le code: [1] 5 Le paramètre echo peut aussi être utilisé pour choisir des lignes de code spécifique à montrer. Pour cela, nous utilisons un vecteur indiquant les positions des lignes à montrer. Par exemple, pour montrer uniquement les lignes 1 et 4, nous utilisons: ```{r code14, echo = c(1, 4)} # une addition de variables avec R a &lt;- 2 b &lt;- 3 a + b ``` ce qui donne: # une addition de variables avec R a + b [1] 5 Affichage des sorties Le paramètre results Le paramètre results permet de choisir comment les sorties dun bloc de code R sont traitées. Par défaut, cest le mode markup qui est utilisé: ```{r markup, results = &#39;markup&#39;} # une division avec R cat(&quot;Exemple de division avec R: 1/998.001 = &quot;, 1/998.001) ``` Ceci donne: # une division avec R cat(&quot;Exemple de division avec R: 1/998.001 = &quot;, 1/998.001) Exemple de division avec R: 1/998.001 = 0.001002 Lorsque result = 'asis', les résultats sont affichés comme un paragraphe du document texte principal : ```{r asis, results = &#39;asis&#39;} # une division avec R cat(&quot;Exemple de division avec R: 1/998.001 = &quot;, 1/998.001) ``` # une division avec R cat(&quot;Exemple de division avec R: 1/998.001 = &quot;, 1/998.001) Exemple de division avec R: 1/998.001 = 0.001002 Lorsque result = 'hide', les sorties console ne sont pas ajoutées : ```{r hide, results = &#39;hide&#39;} # une division avec R cat(&quot;Exemple de division avec R: 1/998.001 = &quot;, 1/998.001) ``` donne: # une division avec R cat(&quot;Exemple de division avec R: 1/998.001 = &quot;, 1/998.001) Finalement, results = 'hold' permet dafficher toutes les sorties après le morceau de code. Sans cette option, les sorties sont ajoutées au fur et à mesure de lexécution du code et donc le bloc est interrompu. Par exemple, avec le code suivant : ```{r} a &lt;- 2 print(a) b &lt;- 3 print(b) 2 + 3 ``` on obtient : a &lt;- 2 print(a) [1] 2 b &lt;- 3 print(b) [1] 3 2 + 3 [1] 5 alors quavec results='hold', ```{r hold, results = &#39;hold&#39;} a &lt;- 2 print(a) b &lt;- 3 print(b) 2 + 3 ``` on obtient plutôt : a &lt;- 2 print(a) b &lt;- 3 print(b) 2 + 3 [1] 2 [1] 3 [1] 5 Affichage des messages Il y a trois type de messages retournés par R: les messages : une simple indication (voir la fonction message()); les avertissements qui soulignent que quelque chose est peut-être problématiques, mais le code est exécutable (voir la fonction warning()); les erreurs qui indiquent que quelque chose ne fonctionne pas dans lexécution du code. Considérons le bloc suivant qui inclut un message, un avertissement, une erreur (en commentaire) et une addition. ```{r} message(&quot;Ceci est un message&quot;) warning(&quot;Ceci est un avertissement&quot;) # stop(&quot;Ceci est un problème&quot;) 2 + 3 ``` message(&quot;Ceci est un message&quot;) Ceci est un message warning(&quot;Ceci est un avertissement&quot;) Warning: Ceci est un avertissement # stop(&quot;Ceci est un problème&quot;) 2 + 3 [1] 5 Il est possible de supprimer le message en utilisant message = FALSE. En effet, le code suivant: ```{r sansmessage, message = FALSE} message(&quot;Ceci est un message&quot;) warning(&quot;Ceci est un avertissement&quot;) # stop(&quot;Ceci est un problème&quot;) 2 + 3 ``` naffiche pas le message de sortie: message(&quot;Ceci est un message&quot;) warning(&quot;Ceci est un avertissement&quot;) Warning: Ceci est un avertissement # stop(&quot;Ceci est un problème&quot;) 2 + 3 [1] 5 De la même manière il est possible de supprimer lavertissement avec warning = FALSE. ```{r sansavertissement, warning = FALSE} message(&quot;Ceci est un message&quot;) warning(&quot;Ceci est un avertissement&quot;) # stop(&quot;Ceci est un problème&quot;) 2 + 3 ``` Le code précédent naffiche pas lavertissement généré: message(&quot;Ceci est un message&quot;) Ceci est un message warning(&quot;Ceci est un avertissement&quot;) # stop(&quot;Ceci est un problème&quot;) 2 + 3 [1] 5 Notez que si vous utilisez results = 'hide' les avertissements et les messages seront tout de même retournés. ```{r sansavertissement2, warning = FALSE, message = FALSE, results = &#39;hide&#39;} message(&quot;Ceci est un message&quot;) warning(&quot;Ceci est un avertissement&quot;) # stop(&quot;Ceci est un problème&quot;) 2 + 3 ``` message(&quot;Ceci est un message&quot;) Ceci est un message warning(&quot;Ceci est un avertissement&quot;) # stop(&quot;Ceci est un problème&quot;) 2 + 3 Enfin, par défaut, si une erreur advient dans un code, le document ne sera pas généré. Cest dailleurs la raison pour laquelle la ligne stop(\"Ceci est un problème\") est commentée précédemment. Il est cependant parfois souhaitable de montrer une erreur (à des fins pédagogiques, par exemple). Pour ce faire, il faut utiliser error = TRUE: ```{r erreur, error = TRUE} message(&quot;Ceci est un message&quot;) warning(&quot;Ceci est un avertissement&quot;) stop(&quot;Ceci est un problème&quot;) 2 + 3 ``` message(&quot;Ceci est un message&quot;) Ceci est un message warning(&quot;Ceci est un avertissement&quot;) Warning: Ceci est un avertissement stop(&quot;Ceci est un problème&quot;) Error in eval(expr, envir, enclos): Ceci est un problème 2 + 3 [1] 5 Mode dévaluation du code Par défaut, avec rmarkdown, dans un bloc de code R, le code est exécuté par R et les sorties sont ajoutées dans le document. Ci-dessus, nous avons vu comment modifier ce qui est présenté dans le code source et changer certain aspect de la sortie. Il est également possible de modifier lexécution du code. Le paramètre eval Dans certains cas, il peut savérer utile de montrer le code source sans lexécuter. Pour empêcher lévaluation du code, on utilise eval = FALSE. Ainsi, avec {r eval, eval = FALSE} install.packages(`rmarkdown`) linstallation de la bibliothèque rmarkdown nest pas exécutée mais simplement affichée : install.packages(`rmarkdown`) Le paramètre include Un autre cas relativement commun est de vouloir exécuter un bloc de code de manière silencieuse. En dautres termes, nous ne souhaitons pas présenter le code ni sa sortie, mais nous souhaitons tout de même lexécuter. Dans un rapport dynamique, par exemple, nous sommes souvent amenés à exécuter un script ou charger des fonctions qui serviront éventuellement à créer des sorties qui seront intégrées dans le rapport. Nous ne souhaitons pas que les lectrices ou les lecteurs du rapport lisent ces éléments de code. Nous savons maintenant que lutiliation des options echo = FALSE, results = hide, message = FALSE et warning = FALSE ensemble dans laccolade, permet dobtenir cette exécution silencieuse. Il existe cependant une manière plus rapide darriver à ce résultat en utilisant le paramètre include = FALSE. En guise dexemple, créons une fonction qui fait une addition simple et assignons le résultat à la variable res ```{r include, include = FALSE} mon_addition &lt;- function(a, b) { return(a + b) } res &lt;- mon_addition(2, 3) ``` Lintégration de ce bloc de code dans le document R markdown naffichera ni le code ni sa sortie dans le document final. Toutefois, le code sera bel et bien exécuté. En effet, nous pouvons afficher la variable res qui a été calculée: print(res) [1] 5 Comme prévu, nous obtenons la valeur 5. Nous pouvons également utiliser la fonction mon_addition() : mon_addition(12, 30) [1] 42 Les tableaux La bibliothèque knitr, permet dintégrer dans le document R markdown un tableau créé sous R. Commençons par créer un objet data.frame : var1 &lt;- 20 * runif(12) tab1 &lt;- data.frame( experience = paste0(&quot;traitement_&quot;, rep(1:3, each = 4)), replicat = rep(letters[1:4], 3), var1 = var1, var2 = var1 + rnorm(12) ) La fonction kable() de la bibliothèque knitr nous permet de convertir lobject tab1 en différents formats (dont latex, html, markdown). De plus, la fonction kable() inclut le paramètre caption pour ajouter une légende. Ainsi, le code suivant ```{r table1} library(knitr) kable(tab1, caption = &quot;Tableau créé à partir de *tab1*&quot;) ``` génère le tableau ci-dessous: TABLEAU 3.1: Tableau créé à partir de tab1 experience replicat var1 var2 traitement_1 a 4.029 3.8503 traitement_1 b 4.449 5.2879 traitement_1 c 7.916 6.7942 traitement_1 d 11.336 11.1678 traitement_2 a 1.966 1.1955 traitement_2 b 16.441 16.3194 traitement_2 c 7.293 6.6286 traitement_2 d 9.684 9.4129 traitement_3 a 8.773 9.1629 traitement_3 b 0.065 -0.0304 traitement_3 c 5.904 5.4307 traitement_3 d 10.229 10.1248 La fonction kable() permet dinclure bien dautres paramètres. Par exemple, il est possible de choisir le nombre de chiffres à afficher après la virgule, ou encore dinclure les numéros de lignes. Ainsi, le code suivant ```{r table2} kable(tab1, caption = &quot;Tableau créé à partir de *tab1*&quot;, digits = 3, row.names = TRUE) ``` produit ce tableau: TABLEAU 3.2: Tableau créé à partir de tab1 experience replicat var1 var2 1 traitement_1 a 4.029 3.850 2 traitement_1 b 4.449 5.288 3 traitement_1 c 7.916 6.794 4 traitement_1 d 11.336 11.168 5 traitement_2 a 1.966 1.196 6 traitement_2 b 16.441 16.319 7 traitement_2 c 7.293 6.629 8 traitement_2 d 9.684 9.413 9 traitement_3 a 8.773 9.163 10 traitement_3 b 0.065 -0.030 11 traitement_3 c 5.904 5.431 12 traitement_3 d 10.229 10.125 Pour en apprendre davantage sur les possibilités quoffre kable(), reportez-vous à la documentation de cette fonction. La bibliothèque kableExtra offre de très nombreuses fonctionnalités pour créer des tableaux plus complexes. Jetez-y un coup dil! Les figures Avec la bibliothèque rmarkdown, il est très facile dinsérer les figures produites avec R dans un document. En guise dexemple, considérons simplement la figure produite par la fonction plot(). Prenons les variables var1 et var2 affichées dans le tableau précédent. plot(tab1$var1, tab1$var2) Nous obtenons la figure demandée, avec des dimensions par défaut qui prennent une bonne part de la largeur du document, mais pas son entièreté. Il existe des options pour contrôler, entre autres, la taille, lalignement et la légende de la figure29. Produisons la même figure, mais ajustons maintenant sa taille et son alignement, et ajoutons une légende: ```{r figdim1, fig.height = 4, fig.width = 4, fig.align = &#39;right&#39;, fig.cap = &quot;Ceci est la légende de la figure&quot;} plot(tab1$var1,tab1$var2) ``` Ce bloc de code produit la figure suivante: FIGURE 3.25: Ceci est la légende de la figure Notez que ces options de mise en page sont valides également pour les autres fonctions R produisant des figures comme hist() ou ggplot() ou encore les fonctions que nous verrons ultérieurement pour visualiser des données spatiales. Les dimensions dune figure sont toujours exprimées en pouces. Si vous nêtes pas habitué à manipuler les pouces, il faudra faire des conversations à la main (ou avec R) en gardant en tête que 1 pouce vaut 2.54 cm. Il est également possible de choisir une des deux dimensions et de changer le rapport de forme. Ainsi nous pouvons spécifier vouloir une figure de 9 pouces avec un rapport de forme de 1.5, ce qui revient à demander une hauteur de 6 pouces. ``{r figdim2, fig.cap= &quot;Figure 9x6&quot;, fig.width = 9, fig.aspect = 1.5} plot(tab1$var1,tab1$var2) ``` FIGURE 3.26: Figure 9x6 Il est aussi possible de contrôler la largeur de la sortie en utilisant des pourcentage, pour cela nous utilisons loption out.width: ``{r figdim3, out.width = &quot;100%&quot;} plot(tab1$var1, tab1$var2) ``` plot(tab1$var1, tab1$var2) Pour connaître lensemble des options disponibles pour la mise en page des figures, nous vous invitons à regarder la page 3 du guide de référence RMarkdown. Les graphiques non-générés par R Dans la section traitant des images avec Pandoc Markdown nous avons vu comment insérer une image dans un document. Il est aussi possible de faire une telle inclusion grâce à la fonction include_graphics() de la bibliothèque knitr. Lavantage de cette manière de procéder est quelle permet de traiter le fichier extérieur comme un graphique produit par R. Par exemple pour ajouter le logo de R utiliser plus haut (./images/Rlogo.png), il est possible dutiliser: ```{r iclgraph, fig.align = &#39;center&#39;, out.width = &quot;40%&quot;, echo = FALSE} include_graphics(&quot;./images/Rlogo.png&quot;) ``` Ce qui affiche limage ci-dessous: 3.2.3 À vous de jouer ! Cet exercice vise à mettre en pratique les notions apprises pour la rédaction de documents R Markdown. Bien que la réponse soit disponible, il est très important de tenter dy répondre par vous même! Les données Dans un premier temps, télécharger le dossier Module3_donnees.zip dans votre répertoire de travail pour ce module, et dézippez-le. Le dossier contient trois fichiers: villes_qc.csv. Mod3_resume.jpg. Mod3_exoRMarkdonw.html Le fichier villes_qc.csv correspond aux données sur les municipalités du Québec que vous avez déjà utilisées dans la partie exercice du Module 1. Le fichier Mod3_resume.jpg correspond à la figure résumé 3.24 vue à la fin du présent module. Le fichier Mod3_exoRMarkdown.html est un fichier HTML que vous devrez tenter de reproduire. Dans un deuxième temps, suivez la démarche présentée dans la partie exercice du Module 2 pour créer un fichier R Markdown en choisissant le format de sortie HTML (rappel) et en utilisant lentête YALM suivante: --- title: &quot;Exercice R Markdown, SCI 1031, Module 3&quot; output: html_document: theme: flatly highlight: zenburn --- Vous devez maintenant rédiger le contenu du document R Markdown que vous venez de créer afin de reproduire le document HTML: Mod3_exoRMarkdown.html. Réponse Voici le document Rmd permettant de généré le document HTML donné. Vous pouvez également consulter le site de référence de Pandoc et le résumé à la première page du guide de référence R Markdown. Pour une source en français, le guide Élaboration et conversion de documents avec Markdown et Pandoc (http://enacit1.epfl.ch/markdown-pandoc/) écrit par Jean-Daniel Bonjour fournit un excellent tour dhorizon. Un exemple de note de bas de page. Encore un exemple de note de bas de page. Notez que la taille et lalignement dune figure ne sont pas des options supportées pour la sortie Word. "],["vec.html", "Module 4 Données vectorielles", " Module 4 Données vectorielles Cette leçon est une introduction aux données spatiales vectorielles sous R. Lobjectif principal de ce module est dapprendre à créer, lire, interpréter et visualiser des données vectorielles30. La section 4.1 expliquera comment créer des données vectorielles. Les sections 4.2-4.4 porteront sur des données vectorielles en format shapefile puisque celles-ci sont couramment utilisées. La section 4.5 vous familiarisera avec les données vectorielles en format geodatabase puisque celles-ci sont de plus en plus utilisées au sein de grandes organisations comme des ministères. À la fin de ce module vous saurez: Créer des données vectorielles et comprendre leur structure. Lire un shapefile, explorer ses métadonnées et interpréter sa géométrie. Lire une geodatabase, et explorer ses couches. Visualiser des données vectorielles de type point, ligne et polygone. Visualiser des données vectorielles par attribut. Visualiser plusieurs données vectorielles au sein dune même figure. Transformer le système de coordonnées de référence de données vectorielles. Vous utiliserez les bibliothèques suivantes: sf rgdal mapview leafsync spData Installez ces librairies si vous ne les avez pas: install.packages(c(&#39;sf&#39;, &#39;rgdal&#39;, &#39;mapview&#39;, &#39;leafsync&#39;, &#39;spData&#39;)) Vous apprendrez à utiliser les fonctions suivantes: st_point(), st_multipoint() st_linestring(), st_multilinestring() st_polygon(), st_multipolygon() st_sfc() st_sf() st_as_sf() st_read() st_write() st_geometry_type() st_crs() st_bbox() mapview() st_transform() latticeView() as.factor() levels() class() Vous utiliserez les données suivantes: Dans la section leçon, vous utiliserez deux ensembles de données vectorielles. Le premier ensemble contient des données shapefile relatives au réseau de pistes cyclables de la ville de Montréal et aux accidents routiers impliquant des bicyclettes. Le second ensemble constitue une géodatabase contenant des données du Ministère de lÉducation et de lEnseignement Supérieur du Québec relatives aux établissements denseignement sur le territoire québécois. Dans la section exercice, vous utiliserez les données vectorielles nz disponibles dans la bibliothèque spData. Le matériel pour ce cours est tiré du chapitre sur les données vectorielles du manuel Geocomputation with R (Lovelace, Nowosad, and Muenchow 2021) et du cours Introduction to Geospatial Raster and Vector Data with R (Wasser et al. (consulté le 1er mars 2020)) de lorganisme Data Carpentry. Data Carpentry développe et offre des formations variées et spécialisées sur le traitement et lanalyse de données. Ses formations sadressent surtout aux chercheuses et chercheurs scientifiques, mais peuvent être consultées par quiconque car leur matériel est libre daccès. Nhésitez donc pas à y jeter un coup dil. "],["lecon_vec.html", "4.1 Leçon", " 4.1 Leçon 4.1.1 Télécharger les données Les données Dans les sections 4.1.3 à 4.1.6 du présent module vous apprendrez à lire et visualiser des données déjà existantes. Afin de faciliter le téléchargement de ces multiples données, lensemble des couches dinformations spatiales peuvent être téléchargées en cliquant sur un seul lien: données pour le module 4. Sauvegardez le dossier compressé (zip) dans votre répertoire de travail Module4_donnees pour ce module, et dézippez-le. Le dossier comprend lui même deux dossiers compressés et un fichier csv: Montreal_Velo.zip Donnees_Ouvertes_MEES.gbd.zip nz_capitales.csv Dézipper chacun des deux dossiers. Le premier dossier, Montreal_Velo sera utilisé aux sections 4.1.3-4.1.5. Il contient les données vectorielles relatives au réseau de pistes cyclables de la ville de Montréal et aux accidents routiers impliquant des bicyclettes. Il contient trois sous-dossiers: accidents pistes terre. Le deuxième dossier, Donnees_Ouvertes_MEES.gbd est la geodatabase du Ministère de lÉducation et de lEnseignement Supérieur du Québec (MEES); nous lutiliserons à la section 4.1.6. Le fichier nz_capitales.csv contient les coordonnées géographiques des capitales des régions administratives de la Nouvelle-Zélande; nous lutiliserons à la section exercices à la fin de ce module. 4.1.2 Créer des données vectorielles Pour créer, lire et manipuler des données vectorielles, nous allons utiliser la bibliothèque sf. Notez que la bibliothèque rgdal se charge automatiquement lorsque sf se charge. library(sf) Créer des géométries simples Nous avons appris à la leçon 2 que les données vectorielles peuvent avoir différentes géométries (point, ligne, polygone, etc.). La bibliothèque sf possède des fonctions pour créer ces géométries simples, cest-à-dire pour créer des objects de la classe sfg (pour simple feature geometry). La fonction st_point() permet de transformer un vecteur numérique représentant les coordonnées dun point en un objet de type point. Par exemple, p &lt;- c(3,5) point &lt;- st_point(p) point POINT (3 5) Remarquez que la classe de lobjet formé est sfg: class(point) [1] &quot;XY&quot; &quot;POINT&quot; &quot;sfg&quot; La fonction st_multipoint() permet de créer une géométrie multipoint. Nous devons fournir à cette fonction une matrice où chaque rangée définie les coordonnées dun des points: M &lt;- rbind( c(3,5), c(5,5), c(4,1), c(2,3)) multi_point &lt;- st_multipoint(M) multi_point MULTIPOINT ((3 5), (5 5), (4 1), (2 3)) La fonction st_linestring() permet de créer une ligne. Nous devons également lui fournir une matrice contenant les coordonnées des extrémités de la ligne. ligne &lt;- st_linestring(M) ligne LINESTRING (3 5, 5 5, 4 1, 2 3) Un polygone se crée de façon similaire, cette fois en utilisant la fonction st_polygon(). Les coordonnées des extrémités du polygone doivent toutefois être définies dans une liste, et non une matrice. Il sagit alors dutiliser la fonction list() pour convertir une matrice en liste. L &lt;- list(rbind( c(3,5), c(5,5), c(4,1), c(2,3), c(3,5))) polygone &lt;-st_polygon(L) polygone POLYGON ((3 5, 5 5, 4 1, 2 3, 3 5)) Noter que pour créer un polygone la première extrémité doit être identique à la dernière. Dans un même ordre didées, pour créer des multi-lignes ou des multi-polygones nous devons aussi recourrir à des listes où chaque élément de la liste correspond à une ligne ou à un polygone respectivement. M1 &lt;- rbind( c(3,5), c(5,5), c(4,1), c(2,3)) M2 &lt;- rbind( c(1,2), c(2,2), c(2,1)) L &lt;- list(M1, M2) multi_ligne &lt;- st_multilinestring(L) multi_ligne MULTILINESTRING ((3 5, 5 5, 4 1, 2 3), (1 2, 2 2, 2 1)) L1 &lt;- list(rbind( c(3,5), c(5,5), c(4,1), c(2,3), c(3,5))) L2 &lt;- list(rbind( c(1,2), c(2,2), c(2,1), c(1,2))) L &lt;- list(L1, L2) multi_polygone &lt;- st_multipolygon(L) multi_polygone MULTIPOLYGON (((3 5, 5 5, 4 1, 2 3, 3 5)), ((1 2, 2 2, 2 1, 1 2))) Attribuer un SCR Nous venons dapprendre les fonctions de base de la bibliothèque sf pour créer des géométries simples. Or, les données vectorielles ne sont pas uniquement des géométries, ce sont des géométries géoréférencées. Ceci signifie quon doit attribuer aux géométries un datum et une projection. Pour ce faire, nous devons créer des objets de la classe sfc, cest-à-dire simple feature columns. Un objet sfc est une liste dobjets sfg qui permet, en plus, de contenir linformation relative au système de coordonnées de référence (SRC) utilisé. La fonction st_sfc() permet de transformer un objet de classe sfg en un objet de classe sfc. Par exemple, transformons le point créer plus haut: point_sfc &lt;- st_sfc(point) Alors que lobjet point contenait seulement la géométrie de lobjet: point POINT (3 5) Lobjet point_sfc contient la géométrie de lobjet et il possède la structure pour définir le SCR (CRS en anglais), bien que pour linstant ce dernier ne soit pas défini (valeur de NA): point_sfc Geometry set for 1 feature Geometry type: POINT Dimension: XY Bounding box: xmin: 3 ymin: 5 xmax: 3 ymax: 5 CRS: NA POINT (3 5) La fonction st_sfc() peut être utilisée sur les autres géométries. Elle permet également de combiner des géométries. Par exemple: L1 &lt;- list(rbind( c(3,5), c(5,5), c(4,1), c(2,3), c(3,5))) polygone1 &lt;- st_polygon(L1) L2 &lt;- list(rbind( c(1,2), c(2,2), c(2,1), c(1,2))) polygone2 &lt;- st_polygon(L2) polygone_sfc &lt;- st_sfc(polygone1, polygone2) polygone_sfc Geometry set for 2 features Geometry type: POLYGON Dimension: XY Bounding box: xmin: 1 ymin: 1 xmax: 5 ymax: 5 CRS: NA POLYGON ((3 5, 5 5, 4 1, 2 3, 3 5)) POLYGON ((1 2, 2 2, 2 1, 1 2)) Pour connaître le SCR dun object vectoriel, il sagit dutiliser la fonction st_crs() de la bibliothèque st: st_crs(polygone_sfc) Coordinate Reference System: NA Dans le cas présent, le SCR est indéfini. Il existe plusieurs façons de définir le SCR. La façon la plus simple est dutiliser le code EPSG associé au SCR que lon désire utilisé. Par exemple, utilisons le EPSG 32198 correspondant au système de coordonnées conique conforme de Lambert dans le datum NAD83 pour définir le CRS de polygone_sfc: polygone_sfc &lt;- st_sfc(polygone1, polygone2, crs = 32198) st_crs(polygone_sfc) Coordinate Reference System: User input: EPSG:32198 wkt: PROJCRS[&quot;NAD83 / Quebec Lambert&quot;, BASEGEOGCRS[&quot;NAD83&quot;, DATUM[&quot;North American Datum 1983&quot;, ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101, LENGTHUNIT[&quot;metre&quot;,1]]], PRIMEM[&quot;Greenwich&quot;,0, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ID[&quot;EPSG&quot;,4269]], CONVERSION[&quot;Quebec Lambert Projection&quot;, METHOD[&quot;Lambert Conic Conformal (2SP)&quot;, ID[&quot;EPSG&quot;,9802]], PARAMETER[&quot;Latitude of false origin&quot;,44, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8821]], PARAMETER[&quot;Longitude of false origin&quot;,-68.5, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8822]], PARAMETER[&quot;Latitude of 1st standard parallel&quot;,60, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8823]], PARAMETER[&quot;Latitude of 2nd standard parallel&quot;,46, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8824]], PARAMETER[&quot;Easting at false origin&quot;,0, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8826]], PARAMETER[&quot;Northing at false origin&quot;,0, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8827]]], CS[Cartesian,2], AXIS[&quot;easting (X)&quot;,east, ORDER[1], LENGTHUNIT[&quot;metre&quot;,1]], AXIS[&quot;northing (Y)&quot;,north, ORDER[2], LENGTHUNIT[&quot;metre&quot;,1]], USAGE[ SCOPE[&quot;Topographic mapping (medium and small scale).&quot;], AREA[&quot;Canada - Quebec.&quot;], BBOX[44.99,-79.85,62.62,-57.1]], ID[&quot;EPSG&quot;,32198]] Nous pouvons également utilisé la notation proj4string: st_crs(polygone_sfc)$proj4string [1] &quot;+proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; st_sfc(point, crs = &quot;+proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&quot;) Geometry set for 1 feature Geometry type: POINT Dimension: XY Bounding box: xmin: 3 ymin: 5 xmax: 3 ymax: 5 CRS: +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs POINT (3 5) Ou encore référé au SCR dun autre objet: st_sfc(point, crs = st_crs(polygone_sfc)) Geometry set for 1 feature Geometry type: POINT Dimension: XY Bounding box: xmin: 3 ymin: 5 xmax: 3 ymax: 5 Projected CRS: NAD83 / Quebec Lambert POINT (3 5) Définir des attributs Les attributs sont les variables non-géographiques permettant de décrire les données vectorielles. Les attributs peuvent, par exemple, correspondre au nom de chaque objet ou à dautres caractéristiques qualitatives ou numériques. Les attributs sont répertoriés dans un objet de classe data.frame, qui est en quelque sorte une matrice dont les colonnes peuvent accueillir des données de différents types (numérique, charactère, logique, facteur, etc.). Afin de démontrer comment joindre des attibuts à des géométries géoréférencées, créons dabord un objet sfc constitué de quatre points. # Créer quatre vecteurs numériques p1 &lt;- c(3,5) p2 &lt;- c(5,5) p3 &lt;- c(4,1) p4 &lt;- c(2,3) # Créer des géométries de type point point1 &lt;- st_point(p1) point2 &lt;- st_point(p2) point3 &lt;- st_point(p3) point4 &lt;- st_point(p4) # Créer un simple feature column # et attribuer un SRC points_sfc &lt;- st_sfc(point1,point2,point3,point4, crs = 32198) points_sfc Geometry set for 4 features Geometry type: POINT Dimension: XY Bounding box: xmin: 2 ymin: 1 xmax: 5 ymax: 5 Projected CRS: NAD83 / Quebec Lambert POINT (3 5) POINT (5 5) POINT (4 1) POINT (2 3) Supposons que les points désignent des écoles primaires pouvant être publiques ou privées. Utilisons la fonction data.frame(), une fonction de base de R pour créer une table des attributs. points_attribut &lt;- data.frame( nom = c(&quot;École A&quot;, &quot;École B&quot;, &quot;École C&quot;, &quot;École D&quot;), nombre_eleves = c(403, 357, 280, 296), ecole_publique = as.logical(c(1, 1, 0, 1)) ) points_attribut nom nombre_eleves ecole_publique 1 École A 403 TRUE 2 École B 357 TRUE 3 École C 280 FALSE 4 École D 296 TRUE Remarquer que chaque colonne est associée à un attribut de classe différente, comme le permet la classe data.frame. Pour associer cette table dattributs à lobjet points_sfc, il sagit dutiliser la fonction st_sf() de la bilbiothèque sf: points_sf &lt;- st_sf(points_sfc, points_attribut) points_sf Simple feature collection with 4 features and 3 fields Geometry type: POINT Dimension: XY Bounding box: xmin: 2 ymin: 1 xmax: 5 ymax: 5 Projected CRS: NAD83 / Quebec Lambert nom nombre_eleves ecole_publique points_sfc 1 École A 403 TRUE POINT (3 5) 2 École B 357 TRUE POINT (5 5) 3 École C 280 FALSE POINT (4 1) 4 École D 296 TRUE POINT (2 3) Lobjet points_sf résultant de cette opération contient deux classes: class(points_sf) [1] &quot;sf&quot; &quot;data.frame&quot; La composante de classe sf (pour simple feature) contient les attributs spatiaux des données tandis que la composante de classe data.frame contient les attributs non-spatiaux. Cette dualité est une caractéristique importante des objets de classe sf: ceux-ci sont essentiellement des data.frames avec une extension spatiale et nous pouvons ainsi les manipuler comme des data.frames. Nous reviendrons sur ce concept au Module 7 portant sur la manipulation de données vectorielles. La fonction st_as_sf() La fonction st_as_sf() de la bibliothèque sf permet de créer un objet de classe sf à partir dun objet dune autre classe. En particulier, elle permet de convertir en un objet sf de type points un data.frame qui contient des colonnes donnant les coordonnées de chaque élément. Donnons un exemple. Considérons le tableau suivant: point_df &lt;- data.frame( points = c(&quot;alpha&quot; ,&quot;beta&quot; ,&quot;gamma&quot;, &quot;delta&quot;), x = c(10, 20, 30, 40), y = c(25, 5, 15, 35) ) Utilisons la fonction st_as_sf() avec largument coords. points_sf &lt;- st_as_sf(point_df, coords = c(&quot;x&quot;,&quot;y&quot;)) points_sf Simple feature collection with 4 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: 10 ymin: 5 xmax: 40 ymax: 35 CRS: NA points geometry 1 alpha POINT (10 25) 2 beta POINT (20 5) 3 gamma POINT (30 15) 4 delta POINT (40 35) Nous pouvons également définir un SCR en utilisant largument crs. points_sf &lt;- st_as_sf(point_df, coords = c(&quot;x&quot;,&quot;y&quot;), crs = 32182) points_sf Simple feature collection with 4 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: 10 ymin: 5 xmax: 40 ymax: 35 Projected CRS: NAD83 / MTM zone 2 points geometry 1 alpha POINT (10 25) 2 beta POINT (20 5) 3 gamma POINT (30 15) 4 delta POINT (40 35) 4.1.3 Lire un shapefile et interpréter sa géométrie Lire les données Nous allons lire les trois shapefiles suivants : Des données vectorielles de type polygone représentant la frontière de notre zone détude, ici, lîle de Montréal. Des données vectorielles de type ligne représentant les pistes cyclables sur lîle de Montréal, et Des données vectorielles de type point représentant la position daccidents impliquant des bicyclettes. Dans un premier temps, nous allons ouvrir les données vectorielles de type polygone qui contiennent les limites terrestres de lîle de Montréal. Pour lire ces données nous utiliserons la fonction st_read() de la bibliothèque sf. Pour utiliser st_read() nous devons spécifier le chemin menant au fichier shapefile à lire. limites_terrestres &lt;- st_read(&quot;Module4/Module4_donnees/Montreal_Velo/terre/terre_shp.shp&quot;) Reading layer `terre_shp&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module4\\Module4_donnees\\Montreal_Velo\\terre\\terre_shp.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 72 features and 1 field Geometry type: POLYGON Dimension: XY Bounding box: xmin: 267500 ymin: 5029000 xmax: 306700 ymax: 5063000 Projected CRS: NAD83 / MTM zone 8 La fonction st_read() vous permet dores et déjà dobtenir certaines informations sur la structure des données vectorielles que vous venez de lire: le type de géométrie (Geometry type), la dimension des données (Dimension), létendue spatiale des données (Bounding box), et le système de coordonnées projetées (Projected CRS). Nous explorerons ces propriétés en détails plus bas. Nous allons maintenant lire les données vectorielles de type ligne, en utilisant encore la fonction st_read(). pistes_cyclables &lt;- st_read(&quot;Module4/Module4_donnees/Montreal_Velo/pistes/pistes_cyclables_type.shp&quot;) Reading layer `pistes_cyclables_type&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module4\\Module4_donnees\\Montreal_Velo\\pistes\\pistes_cyclables_type.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 6395 features and 1 field Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: 268000 ymin: 5029000 xmax: 306300 ymax: 5063000 Projected CRS: Transverse_Mercator Finalement, nous allons lire les données vectorielles de type point, en utilisant toujours la fonction st_read(). accidents_velo &lt;- st_read(&quot;Module4/Module4_donnees/Montreal_Velo/accidents/accidents2018_Mtl_velo.shp&quot;) Reading layer `accidents2018_Mtl_velo&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module4\\Module4_donnees\\Montreal_Velo\\accidents\\accidents2018_Mtl_velo.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 796 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: 269500 ymin: 5030000 xmax: 305400 ymax: 5059000 Projected CRS: Transverse_Mercator Remarquez que le type de géométrie (Geometry type) diffère pour les trois classes de données lues comme nous nous y attendions. Explorer les métadonnées dun shapefile Les informations contenues dans un shapefile sont appelées des métadonnées. Nous sommes particulièrement intéressées aux métadonnées géospatiales. Les métadonnées fondamentales dun shapefile sont : Le type de géométrie : le type de classes des données vectorielles téléchargées. La projection : le système de coordonnées de référence utilisé pour représenter les données. Létendue spatiale : la superficie géographique couvrant les données vectorielles. Le type de géométrie Nous pouvons explorer chacune de ces métadonnées en utilisant des fonctions de la librairie sf. Le type de géométrie est obtenu par la fonction st_geometry_type(). Par exemple, pour les limites terrestres de la ville de Montréal, cette fonction nous donne: st_geometry_type(limites_terrestres) [1] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [7] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [13] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [19] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [25] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [31] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [37] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [43] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [49] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [55] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [61] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON [67] POLYGON POLYGON POLYGON POLYGON POLYGON POLYGON 18 Levels: GEOMETRY POINT LINESTRING ... TRIANGLE Nous avons ainsi la confirmation que ces données vectorielles correspondent à des polygones (plus exactement, 72 polygones). Les 18 niveaux donnés en dessous constituent une liste des classes possibles de géométrie. En comparaison, pour les données de type ligne et de type point nous obtenons plutôt : st_geometry_type(pistes_cyclables) [1] MULTILINESTRING MULTILINESTRING MULTILINESTRING [4] MULTILINESTRING MULTILINESTRING MULTILINESTRING [7] MULTILINESTRING MULTILINESTRING MULTILINESTRING [10] MULTILINESTRING MULTILINESTRING MULTILINESTRING [13] MULTILINESTRING MULTILINESTRING MULTILINESTRING [16] MULTILINESTRING MULTILINESTRING MULTILINESTRING [19] MULTILINESTRING MULTILINESTRING MULTILINESTRING [22] MULTILINESTRING MULTILINESTRING MULTILINESTRING [25] MULTILINESTRING MULTILINESTRING MULTILINESTRING [28] MULTILINESTRING MULTILINESTRING MULTILINESTRING [31] MULTILINESTRING MULTILINESTRING MULTILINESTRING [34] MULTILINESTRING MULTILINESTRING MULTILINESTRING [37] MULTILINESTRING MULTILINESTRING MULTILINESTRING [40] MULTILINESTRING MULTILINESTRING MULTILINESTRING [43] MULTILINESTRING MULTILINESTRING MULTILINESTRING [46] MULTILINESTRING MULTILINESTRING MULTILINESTRING [49] MULTILINESTRING MULTILINESTRING MULTILINESTRING [52] MULTILINESTRING MULTILINESTRING MULTILINESTRING [55] MULTILINESTRING MULTILINESTRING MULTILINESTRING [58] MULTILINESTRING MULTILINESTRING MULTILINESTRING [61] MULTILINESTRING MULTILINESTRING MULTILINESTRING [64] MULTILINESTRING MULTILINESTRING MULTILINESTRING [67] MULTILINESTRING MULTILINESTRING MULTILINESTRING [70] MULTILINESTRING MULTILINESTRING MULTILINESTRING [73] MULTILINESTRING MULTILINESTRING MULTILINESTRING [76] MULTILINESTRING MULTILINESTRING MULTILINESTRING [79] MULTILINESTRING MULTILINESTRING MULTILINESTRING [82] MULTILINESTRING MULTILINESTRING MULTILINESTRING [85] MULTILINESTRING MULTILINESTRING MULTILINESTRING [88] MULTILINESTRING MULTILINESTRING MULTILINESTRING [91] MULTILINESTRING MULTILINESTRING MULTILINESTRING [94] MULTILINESTRING MULTILINESTRING MULTILINESTRING [97] MULTILINESTRING MULTILINESTRING MULTILINESTRING [100] MULTILINESTRING MULTILINESTRING MULTILINESTRING [103] MULTILINESTRING MULTILINESTRING MULTILINESTRING [106] MULTILINESTRING MULTILINESTRING MULTILINESTRING [109] MULTILINESTRING MULTILINESTRING MULTILINESTRING [112] MULTILINESTRING MULTILINESTRING MULTILINESTRING [115] MULTILINESTRING MULTILINESTRING MULTILINESTRING [118] MULTILINESTRING MULTILINESTRING MULTILINESTRING [121] MULTILINESTRING MULTILINESTRING MULTILINESTRING [124] MULTILINESTRING MULTILINESTRING MULTILINESTRING [127] MULTILINESTRING MULTILINESTRING MULTILINESTRING [130] MULTILINESTRING MULTILINESTRING MULTILINESTRING [133] MULTILINESTRING MULTILINESTRING MULTILINESTRING [136] MULTILINESTRING MULTILINESTRING MULTILINESTRING [139] MULTILINESTRING MULTILINESTRING MULTILINESTRING [142] MULTILINESTRING MULTILINESTRING MULTILINESTRING [145] MULTILINESTRING MULTILINESTRING MULTILINESTRING [148] MULTILINESTRING MULTILINESTRING MULTILINESTRING [151] MULTILINESTRING MULTILINESTRING MULTILINESTRING [154] MULTILINESTRING MULTILINESTRING MULTILINESTRING [157] MULTILINESTRING MULTILINESTRING MULTILINESTRING [160] MULTILINESTRING MULTILINESTRING MULTILINESTRING [163] MULTILINESTRING MULTILINESTRING MULTILINESTRING [166] MULTILINESTRING MULTILINESTRING MULTILINESTRING [169] MULTILINESTRING MULTILINESTRING MULTILINESTRING [172] MULTILINESTRING MULTILINESTRING MULTILINESTRING [175] MULTILINESTRING MULTILINESTRING MULTILINESTRING [178] MULTILINESTRING MULTILINESTRING MULTILINESTRING [181] MULTILINESTRING MULTILINESTRING MULTILINESTRING [184] MULTILINESTRING MULTILINESTRING MULTILINESTRING [187] MULTILINESTRING MULTILINESTRING MULTILINESTRING [190] MULTILINESTRING MULTILINESTRING MULTILINESTRING [193] MULTILINESTRING MULTILINESTRING MULTILINESTRING [196] MULTILINESTRING MULTILINESTRING MULTILINESTRING [199] MULTILINESTRING MULTILINESTRING MULTILINESTRING [202] MULTILINESTRING MULTILINESTRING MULTILINESTRING [205] MULTILINESTRING MULTILINESTRING MULTILINESTRING [208] MULTILINESTRING MULTILINESTRING MULTILINESTRING [211] MULTILINESTRING MULTILINESTRING MULTILINESTRING [214] MULTILINESTRING MULTILINESTRING MULTILINESTRING [217] MULTILINESTRING MULTILINESTRING MULTILINESTRING [220] MULTILINESTRING MULTILINESTRING MULTILINESTRING [223] MULTILINESTRING MULTILINESTRING MULTILINESTRING [226] MULTILINESTRING MULTILINESTRING MULTILINESTRING [229] MULTILINESTRING MULTILINESTRING MULTILINESTRING [232] MULTILINESTRING MULTILINESTRING MULTILINESTRING [235] MULTILINESTRING MULTILINESTRING MULTILINESTRING [238] MULTILINESTRING MULTILINESTRING MULTILINESTRING [241] MULTILINESTRING MULTILINESTRING MULTILINESTRING [244] MULTILINESTRING MULTILINESTRING MULTILINESTRING [247] MULTILINESTRING MULTILINESTRING MULTILINESTRING [250] MULTILINESTRING MULTILINESTRING MULTILINESTRING [253] MULTILINESTRING MULTILINESTRING MULTILINESTRING [256] MULTILINESTRING MULTILINESTRING MULTILINESTRING [259] MULTILINESTRING MULTILINESTRING MULTILINESTRING [262] MULTILINESTRING MULTILINESTRING MULTILINESTRING [265] MULTILINESTRING MULTILINESTRING MULTILINESTRING [268] MULTILINESTRING MULTILINESTRING MULTILINESTRING [271] MULTILINESTRING MULTILINESTRING MULTILINESTRING [274] MULTILINESTRING MULTILINESTRING MULTILINESTRING [277] MULTILINESTRING MULTILINESTRING MULTILINESTRING [280] MULTILINESTRING MULTILINESTRING MULTILINESTRING [283] MULTILINESTRING MULTILINESTRING MULTILINESTRING [286] MULTILINESTRING MULTILINESTRING MULTILINESTRING [289] MULTILINESTRING MULTILINESTRING MULTILINESTRING [292] MULTILINESTRING MULTILINESTRING MULTILINESTRING [295] MULTILINESTRING MULTILINESTRING MULTILINESTRING [298] MULTILINESTRING MULTILINESTRING MULTILINESTRING [301] MULTILINESTRING MULTILINESTRING MULTILINESTRING [304] MULTILINESTRING MULTILINESTRING MULTILINESTRING [307] MULTILINESTRING MULTILINESTRING MULTILINESTRING [310] MULTILINESTRING MULTILINESTRING MULTILINESTRING [313] MULTILINESTRING MULTILINESTRING MULTILINESTRING [316] MULTILINESTRING MULTILINESTRING MULTILINESTRING [319] MULTILINESTRING MULTILINESTRING MULTILINESTRING [322] MULTILINESTRING MULTILINESTRING MULTILINESTRING [325] MULTILINESTRING MULTILINESTRING MULTILINESTRING [328] MULTILINESTRING MULTILINESTRING MULTILINESTRING [331] MULTILINESTRING MULTILINESTRING MULTILINESTRING [334] MULTILINESTRING MULTILINESTRING MULTILINESTRING [337] MULTILINESTRING MULTILINESTRING MULTILINESTRING [340] MULTILINESTRING MULTILINESTRING MULTILINESTRING [343] MULTILINESTRING MULTILINESTRING MULTILINESTRING [346] MULTILINESTRING MULTILINESTRING MULTILINESTRING [349] MULTILINESTRING MULTILINESTRING MULTILINESTRING [352] MULTILINESTRING MULTILINESTRING MULTILINESTRING [355] MULTILINESTRING MULTILINESTRING MULTILINESTRING [358] MULTILINESTRING MULTILINESTRING MULTILINESTRING [361] MULTILINESTRING MULTILINESTRING MULTILINESTRING [364] MULTILINESTRING MULTILINESTRING MULTILINESTRING [367] MULTILINESTRING MULTILINESTRING MULTILINESTRING [370] MULTILINESTRING MULTILINESTRING MULTILINESTRING [373] MULTILINESTRING MULTILINESTRING MULTILINESTRING [376] MULTILINESTRING MULTILINESTRING MULTILINESTRING [379] MULTILINESTRING MULTILINESTRING MULTILINESTRING [382] MULTILINESTRING MULTILINESTRING MULTILINESTRING [385] MULTILINESTRING MULTILINESTRING MULTILINESTRING [388] MULTILINESTRING MULTILINESTRING MULTILINESTRING [391] MULTILINESTRING MULTILINESTRING MULTILINESTRING [394] MULTILINESTRING MULTILINESTRING MULTILINESTRING [397] MULTILINESTRING MULTILINESTRING MULTILINESTRING [400] MULTILINESTRING MULTILINESTRING MULTILINESTRING [403] MULTILINESTRING MULTILINESTRING MULTILINESTRING [406] MULTILINESTRING MULTILINESTRING MULTILINESTRING [409] MULTILINESTRING MULTILINESTRING MULTILINESTRING [412] MULTILINESTRING MULTILINESTRING MULTILINESTRING [415] MULTILINESTRING MULTILINESTRING MULTILINESTRING [418] MULTILINESTRING MULTILINESTRING MULTILINESTRING [421] MULTILINESTRING MULTILINESTRING MULTILINESTRING [424] MULTILINESTRING MULTILINESTRING MULTILINESTRING [427] MULTILINESTRING MULTILINESTRING MULTILINESTRING [430] MULTILINESTRING MULTILINESTRING MULTILINESTRING [433] MULTILINESTRING MULTILINESTRING MULTILINESTRING [436] MULTILINESTRING MULTILINESTRING MULTILINESTRING [439] MULTILINESTRING MULTILINESTRING MULTILINESTRING [442] MULTILINESTRING MULTILINESTRING MULTILINESTRING [445] MULTILINESTRING MULTILINESTRING MULTILINESTRING [448] MULTILINESTRING MULTILINESTRING MULTILINESTRING [451] MULTILINESTRING MULTILINESTRING MULTILINESTRING [454] MULTILINESTRING MULTILINESTRING MULTILINESTRING [457] MULTILINESTRING MULTILINESTRING MULTILINESTRING [460] MULTILINESTRING MULTILINESTRING MULTILINESTRING [463] MULTILINESTRING MULTILINESTRING MULTILINESTRING [466] MULTILINESTRING MULTILINESTRING MULTILINESTRING [469] MULTILINESTRING MULTILINESTRING MULTILINESTRING [472] MULTILINESTRING MULTILINESTRING MULTILINESTRING [475] MULTILINESTRING MULTILINESTRING MULTILINESTRING [478] MULTILINESTRING MULTILINESTRING MULTILINESTRING [481] MULTILINESTRING MULTILINESTRING MULTILINESTRING [484] MULTILINESTRING MULTILINESTRING MULTILINESTRING [487] MULTILINESTRING MULTILINESTRING MULTILINESTRING [490] MULTILINESTRING MULTILINESTRING MULTILINESTRING [493] MULTILINESTRING MULTILINESTRING MULTILINESTRING [496] MULTILINESTRING MULTILINESTRING MULTILINESTRING [499] MULTILINESTRING MULTILINESTRING MULTILINESTRING [502] MULTILINESTRING MULTILINESTRING MULTILINESTRING [505] MULTILINESTRING MULTILINESTRING MULTILINESTRING [508] MULTILINESTRING MULTILINESTRING MULTILINESTRING [511] MULTILINESTRING MULTILINESTRING MULTILINESTRING [514] MULTILINESTRING MULTILINESTRING MULTILINESTRING [517] MULTILINESTRING MULTILINESTRING MULTILINESTRING [520] MULTILINESTRING MULTILINESTRING MULTILINESTRING [523] MULTILINESTRING MULTILINESTRING MULTILINESTRING [526] MULTILINESTRING MULTILINESTRING MULTILINESTRING [529] MULTILINESTRING MULTILINESTRING MULTILINESTRING [532] MULTILINESTRING MULTILINESTRING MULTILINESTRING [535] MULTILINESTRING MULTILINESTRING MULTILINESTRING [538] MULTILINESTRING MULTILINESTRING MULTILINESTRING [541] MULTILINESTRING MULTILINESTRING MULTILINESTRING [544] MULTILINESTRING MULTILINESTRING MULTILINESTRING [547] MULTILINESTRING MULTILINESTRING MULTILINESTRING [550] MULTILINESTRING MULTILINESTRING MULTILINESTRING [553] MULTILINESTRING MULTILINESTRING MULTILINESTRING [556] MULTILINESTRING MULTILINESTRING MULTILINESTRING [559] MULTILINESTRING MULTILINESTRING MULTILINESTRING [562] MULTILINESTRING MULTILINESTRING MULTILINESTRING [565] MULTILINESTRING MULTILINESTRING MULTILINESTRING [568] MULTILINESTRING MULTILINESTRING MULTILINESTRING [571] MULTILINESTRING MULTILINESTRING MULTILINESTRING [574] MULTILINESTRING MULTILINESTRING MULTILINESTRING [577] MULTILINESTRING MULTILINESTRING MULTILINESTRING [580] MULTILINESTRING MULTILINESTRING MULTILINESTRING [583] MULTILINESTRING MULTILINESTRING MULTILINESTRING [586] MULTILINESTRING MULTILINESTRING MULTILINESTRING [589] MULTILINESTRING MULTILINESTRING MULTILINESTRING [592] MULTILINESTRING MULTILINESTRING MULTILINESTRING [595] MULTILINESTRING MULTILINESTRING MULTILINESTRING [598] MULTILINESTRING MULTILINESTRING MULTILINESTRING [601] MULTILINESTRING MULTILINESTRING MULTILINESTRING [604] MULTILINESTRING MULTILINESTRING MULTILINESTRING [607] MULTILINESTRING MULTILINESTRING MULTILINESTRING [610] MULTILINESTRING MULTILINESTRING MULTILINESTRING [613] MULTILINESTRING MULTILINESTRING MULTILINESTRING [616] MULTILINESTRING MULTILINESTRING MULTILINESTRING [619] MULTILINESTRING MULTILINESTRING MULTILINESTRING [622] MULTILINESTRING MULTILINESTRING MULTILINESTRING [625] MULTILINESTRING MULTILINESTRING MULTILINESTRING [628] MULTILINESTRING MULTILINESTRING MULTILINESTRING [631] MULTILINESTRING MULTILINESTRING MULTILINESTRING [634] MULTILINESTRING MULTILINESTRING MULTILINESTRING [637] MULTILINESTRING MULTILINESTRING MULTILINESTRING [640] MULTILINESTRING MULTILINESTRING MULTILINESTRING [643] MULTILINESTRING MULTILINESTRING MULTILINESTRING [646] MULTILINESTRING MULTILINESTRING MULTILINESTRING [649] MULTILINESTRING MULTILINESTRING MULTILINESTRING [652] MULTILINESTRING MULTILINESTRING MULTILINESTRING [655] MULTILINESTRING MULTILINESTRING MULTILINESTRING [658] MULTILINESTRING MULTILINESTRING MULTILINESTRING [661] MULTILINESTRING MULTILINESTRING MULTILINESTRING [664] MULTILINESTRING MULTILINESTRING MULTILINESTRING [667] MULTILINESTRING MULTILINESTRING MULTILINESTRING [670] MULTILINESTRING MULTILINESTRING MULTILINESTRING [673] MULTILINESTRING MULTILINESTRING MULTILINESTRING [676] MULTILINESTRING MULTILINESTRING MULTILINESTRING [679] MULTILINESTRING MULTILINESTRING MULTILINESTRING [682] MULTILINESTRING MULTILINESTRING MULTILINESTRING [685] MULTILINESTRING MULTILINESTRING MULTILINESTRING [688] MULTILINESTRING MULTILINESTRING MULTILINESTRING [691] MULTILINESTRING MULTILINESTRING MULTILINESTRING [694] MULTILINESTRING MULTILINESTRING MULTILINESTRING [697] MULTILINESTRING MULTILINESTRING MULTILINESTRING [700] MULTILINESTRING MULTILINESTRING MULTILINESTRING [703] MULTILINESTRING MULTILINESTRING MULTILINESTRING [706] MULTILINESTRING MULTILINESTRING MULTILINESTRING [709] MULTILINESTRING MULTILINESTRING MULTILINESTRING [712] MULTILINESTRING MULTILINESTRING MULTILINESTRING [715] MULTILINESTRING MULTILINESTRING MULTILINESTRING [718] MULTILINESTRING MULTILINESTRING MULTILINESTRING [721] MULTILINESTRING MULTILINESTRING MULTILINESTRING [724] MULTILINESTRING MULTILINESTRING MULTILINESTRING [727] MULTILINESTRING MULTILINESTRING MULTILINESTRING [730] MULTILINESTRING MULTILINESTRING MULTILINESTRING [733] MULTILINESTRING MULTILINESTRING MULTILINESTRING [736] MULTILINESTRING MULTILINESTRING MULTILINESTRING [739] MULTILINESTRING MULTILINESTRING MULTILINESTRING [742] MULTILINESTRING MULTILINESTRING MULTILINESTRING [745] MULTILINESTRING MULTILINESTRING MULTILINESTRING [748] MULTILINESTRING MULTILINESTRING MULTILINESTRING [751] MULTILINESTRING MULTILINESTRING MULTILINESTRING [754] MULTILINESTRING MULTILINESTRING MULTILINESTRING [757] MULTILINESTRING MULTILINESTRING MULTILINESTRING [760] MULTILINESTRING MULTILINESTRING MULTILINESTRING [763] MULTILINESTRING MULTILINESTRING MULTILINESTRING [766] MULTILINESTRING MULTILINESTRING MULTILINESTRING [769] MULTILINESTRING MULTILINESTRING MULTILINESTRING [772] MULTILINESTRING MULTILINESTRING MULTILINESTRING [775] MULTILINESTRING MULTILINESTRING MULTILINESTRING [778] MULTILINESTRING MULTILINESTRING MULTILINESTRING [781] MULTILINESTRING MULTILINESTRING MULTILINESTRING [784] MULTILINESTRING MULTILINESTRING MULTILINESTRING [787] MULTILINESTRING MULTILINESTRING MULTILINESTRING [790] MULTILINESTRING MULTILINESTRING MULTILINESTRING [793] MULTILINESTRING MULTILINESTRING MULTILINESTRING [796] MULTILINESTRING MULTILINESTRING MULTILINESTRING [799] MULTILINESTRING MULTILINESTRING MULTILINESTRING [802] MULTILINESTRING MULTILINESTRING MULTILINESTRING [805] MULTILINESTRING MULTILINESTRING MULTILINESTRING [808] MULTILINESTRING MULTILINESTRING MULTILINESTRING [811] MULTILINESTRING MULTILINESTRING MULTILINESTRING [814] MULTILINESTRING MULTILINESTRING MULTILINESTRING [817] MULTILINESTRING MULTILINESTRING MULTILINESTRING [820] MULTILINESTRING MULTILINESTRING MULTILINESTRING [823] MULTILINESTRING MULTILINESTRING MULTILINESTRING [826] MULTILINESTRING MULTILINESTRING MULTILINESTRING [829] MULTILINESTRING MULTILINESTRING MULTILINESTRING [832] MULTILINESTRING MULTILINESTRING MULTILINESTRING [835] MULTILINESTRING MULTILINESTRING MULTILINESTRING [838] MULTILINESTRING MULTILINESTRING MULTILINESTRING [841] MULTILINESTRING MULTILINESTRING MULTILINESTRING [844] MULTILINESTRING MULTILINESTRING MULTILINESTRING [847] MULTILINESTRING MULTILINESTRING MULTILINESTRING [850] MULTILINESTRING MULTILINESTRING MULTILINESTRING [853] MULTILINESTRING MULTILINESTRING MULTILINESTRING [856] MULTILINESTRING MULTILINESTRING MULTILINESTRING [859] MULTILINESTRING MULTILINESTRING MULTILINESTRING [862] MULTILINESTRING MULTILINESTRING MULTILINESTRING [865] MULTILINESTRING MULTILINESTRING MULTILINESTRING [868] MULTILINESTRING MULTILINESTRING MULTILINESTRING [871] MULTILINESTRING MULTILINESTRING MULTILINESTRING [874] MULTILINESTRING MULTILINESTRING MULTILINESTRING [877] MULTILINESTRING MULTILINESTRING MULTILINESTRING [880] MULTILINESTRING MULTILINESTRING MULTILINESTRING [883] MULTILINESTRING MULTILINESTRING MULTILINESTRING [886] MULTILINESTRING MULTILINESTRING MULTILINESTRING [889] MULTILINESTRING MULTILINESTRING MULTILINESTRING [892] MULTILINESTRING MULTILINESTRING MULTILINESTRING [895] MULTILINESTRING MULTILINESTRING MULTILINESTRING [898] MULTILINESTRING MULTILINESTRING MULTILINESTRING [901] MULTILINESTRING MULTILINESTRING MULTILINESTRING [904] MULTILINESTRING MULTILINESTRING MULTILINESTRING [907] MULTILINESTRING MULTILINESTRING MULTILINESTRING [910] MULTILINESTRING MULTILINESTRING MULTILINESTRING [913] MULTILINESTRING MULTILINESTRING MULTILINESTRING [916] MULTILINESTRING MULTILINESTRING MULTILINESTRING [919] MULTILINESTRING MULTILINESTRING MULTILINESTRING [922] MULTILINESTRING MULTILINESTRING MULTILINESTRING [925] MULTILINESTRING MULTILINESTRING MULTILINESTRING [928] MULTILINESTRING MULTILINESTRING MULTILINESTRING [931] MULTILINESTRING MULTILINESTRING MULTILINESTRING [934] MULTILINESTRING MULTILINESTRING MULTILINESTRING [937] MULTILINESTRING MULTILINESTRING MULTILINESTRING [940] MULTILINESTRING MULTILINESTRING MULTILINESTRING [943] MULTILINESTRING MULTILINESTRING MULTILINESTRING [946] MULTILINESTRING MULTILINESTRING MULTILINESTRING [949] MULTILINESTRING MULTILINESTRING MULTILINESTRING [952] MULTILINESTRING MULTILINESTRING MULTILINESTRING [955] MULTILINESTRING MULTILINESTRING MULTILINESTRING [958] MULTILINESTRING MULTILINESTRING MULTILINESTRING [961] MULTILINESTRING MULTILINESTRING MULTILINESTRING [964] MULTILINESTRING MULTILINESTRING MULTILINESTRING [967] MULTILINESTRING MULTILINESTRING MULTILINESTRING [970] MULTILINESTRING MULTILINESTRING MULTILINESTRING [973] MULTILINESTRING MULTILINESTRING MULTILINESTRING [976] MULTILINESTRING MULTILINESTRING MULTILINESTRING [979] MULTILINESTRING MULTILINESTRING MULTILINESTRING [982] MULTILINESTRING MULTILINESTRING MULTILINESTRING [985] MULTILINESTRING MULTILINESTRING MULTILINESTRING [988] MULTILINESTRING MULTILINESTRING MULTILINESTRING [991] MULTILINESTRING MULTILINESTRING MULTILINESTRING [994] MULTILINESTRING MULTILINESTRING MULTILINESTRING [997] MULTILINESTRING MULTILINESTRING MULTILINESTRING [1000] MULTILINESTRING [ reached getOption(&quot;max.print&quot;) -- omitted 5395 entries ] 18 Levels: GEOMETRY POINT LINESTRING ... TRIANGLE st_geometry_type(accidents_velo) [1] POINT POINT POINT POINT POINT POINT POINT POINT [9] POINT POINT POINT POINT POINT POINT POINT POINT [17] POINT POINT POINT POINT POINT POINT POINT POINT [25] POINT POINT POINT POINT POINT POINT POINT POINT [33] POINT POINT POINT POINT POINT POINT POINT POINT [41] POINT POINT POINT POINT POINT POINT POINT POINT [49] POINT POINT POINT POINT POINT POINT POINT POINT [57] POINT POINT POINT POINT POINT POINT POINT POINT [65] POINT POINT POINT POINT POINT POINT POINT POINT [73] POINT POINT POINT POINT POINT POINT POINT POINT [81] POINT POINT POINT POINT POINT POINT POINT POINT [89] POINT POINT POINT POINT POINT POINT POINT POINT [97] POINT POINT POINT POINT POINT POINT POINT POINT [105] POINT POINT POINT POINT POINT POINT POINT POINT [113] POINT POINT POINT POINT POINT POINT POINT POINT [121] POINT POINT POINT POINT POINT POINT POINT POINT [129] POINT POINT POINT POINT POINT POINT POINT POINT [137] POINT POINT POINT POINT POINT POINT POINT POINT [145] POINT POINT POINT POINT POINT POINT POINT POINT [153] POINT POINT POINT POINT POINT POINT POINT POINT [161] POINT POINT POINT POINT POINT POINT POINT POINT [169] POINT POINT POINT POINT POINT POINT POINT POINT [177] POINT POINT POINT POINT POINT POINT POINT POINT [185] POINT POINT POINT POINT POINT POINT POINT POINT [193] POINT POINT POINT POINT POINT POINT POINT POINT [201] POINT POINT POINT POINT POINT POINT POINT POINT [209] POINT POINT POINT POINT POINT POINT POINT POINT [217] POINT POINT POINT POINT POINT POINT POINT POINT [225] POINT POINT POINT POINT POINT POINT POINT POINT [233] POINT POINT POINT POINT POINT POINT POINT POINT [241] POINT POINT POINT POINT POINT POINT POINT POINT [249] POINT POINT POINT POINT POINT POINT POINT POINT [257] POINT POINT POINT POINT POINT POINT POINT POINT [265] POINT POINT POINT POINT POINT POINT POINT POINT [273] POINT POINT POINT POINT POINT POINT POINT POINT [281] POINT POINT POINT POINT POINT POINT POINT POINT [289] POINT POINT POINT POINT POINT POINT POINT POINT [297] POINT POINT POINT POINT POINT POINT POINT POINT [305] POINT POINT POINT POINT POINT POINT POINT POINT [313] POINT POINT POINT POINT POINT POINT POINT POINT [321] POINT POINT POINT POINT POINT POINT POINT POINT [329] POINT POINT POINT POINT POINT POINT POINT POINT [337] POINT POINT POINT POINT POINT POINT POINT POINT [345] POINT POINT POINT POINT POINT POINT POINT POINT [353] POINT POINT POINT POINT POINT POINT POINT POINT [361] POINT POINT POINT POINT POINT POINT POINT POINT [369] POINT POINT POINT POINT POINT POINT POINT POINT [377] POINT POINT POINT POINT POINT POINT POINT POINT [385] POINT POINT POINT POINT POINT POINT POINT POINT [393] POINT POINT POINT POINT POINT POINT POINT POINT [401] POINT POINT POINT POINT POINT POINT POINT POINT [409] POINT POINT POINT POINT POINT POINT POINT POINT [417] POINT POINT POINT POINT POINT POINT POINT POINT [425] POINT POINT POINT POINT POINT POINT POINT POINT [433] POINT POINT POINT POINT POINT POINT POINT POINT [441] POINT POINT POINT POINT POINT POINT POINT POINT [449] POINT POINT POINT POINT POINT POINT POINT POINT [457] POINT POINT POINT POINT POINT POINT POINT POINT [465] POINT POINT POINT POINT POINT POINT POINT POINT [473] POINT POINT POINT POINT POINT POINT POINT POINT [481] POINT POINT POINT POINT POINT POINT POINT POINT [489] POINT POINT POINT POINT POINT POINT POINT POINT [497] POINT POINT POINT POINT POINT POINT POINT POINT [505] POINT POINT POINT POINT POINT POINT POINT POINT [513] POINT POINT POINT POINT POINT POINT POINT POINT [521] POINT POINT POINT POINT POINT POINT POINT POINT [529] POINT POINT POINT POINT POINT POINT POINT POINT [537] POINT POINT POINT POINT POINT POINT POINT POINT [545] POINT POINT POINT POINT POINT POINT POINT POINT [553] POINT POINT POINT POINT POINT POINT POINT POINT [561] POINT POINT POINT POINT POINT POINT POINT POINT [569] POINT POINT POINT POINT POINT POINT POINT POINT [577] POINT POINT POINT POINT POINT POINT POINT POINT [585] POINT POINT POINT POINT POINT POINT POINT POINT [593] POINT POINT POINT POINT POINT POINT POINT POINT [601] POINT POINT POINT POINT POINT POINT POINT POINT [609] POINT POINT POINT POINT POINT POINT POINT POINT [617] POINT POINT POINT POINT POINT POINT POINT POINT [625] POINT POINT POINT POINT POINT POINT POINT POINT [633] POINT POINT POINT POINT POINT POINT POINT POINT [641] POINT POINT POINT POINT POINT POINT POINT POINT [649] POINT POINT POINT POINT POINT POINT POINT POINT [657] POINT POINT POINT POINT POINT POINT POINT POINT [665] POINT POINT POINT POINT POINT POINT POINT POINT [673] POINT POINT POINT POINT POINT POINT POINT POINT [681] POINT POINT POINT POINT POINT POINT POINT POINT [689] POINT POINT POINT POINT POINT POINT POINT POINT [697] POINT POINT POINT POINT POINT POINT POINT POINT [705] POINT POINT POINT POINT POINT POINT POINT POINT [713] POINT POINT POINT POINT POINT POINT POINT POINT [721] POINT POINT POINT POINT POINT POINT POINT POINT [729] POINT POINT POINT POINT POINT POINT POINT POINT [737] POINT POINT POINT POINT POINT POINT POINT POINT [745] POINT POINT POINT POINT POINT POINT POINT POINT [753] POINT POINT POINT POINT POINT POINT POINT POINT [761] POINT POINT POINT POINT POINT POINT POINT POINT [769] POINT POINT POINT POINT POINT POINT POINT POINT [777] POINT POINT POINT POINT POINT POINT POINT POINT [785] POINT POINT POINT POINT POINT POINT POINT POINT [793] POINT POINT POINT POINT 18 Levels: GEOMETRY POINT LINESTRING ... TRIANGLE Vous remarquez alors que les pistes cyclables sont composées de nombreuses multilignes. Une multiligne étant elle-même un ensemble de lignes. Quant aux accidents de vélo, ce sont des points qui désignent la position précise des accidents. On en compte 796 en 2018. La projection Vérifions maintenant la projection des shapefiles en utilisant la fonction st_crs() de la bibliothèque sf. Pour le shapefile limites_terrestres nous obtenons: st_crs(limites_terrestres) Coordinate Reference System: User input: NAD83 / MTM zone 8 wkt: PROJCRS[&quot;NAD83 / MTM zone 8&quot;, BASEGEOGCRS[&quot;NAD83&quot;, DATUM[&quot;North American Datum 1983&quot;, ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101, LENGTHUNIT[&quot;metre&quot;,1]]], PRIMEM[&quot;Greenwich&quot;,0, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ID[&quot;EPSG&quot;,4269]], CONVERSION[&quot;MTM zone 8&quot;, METHOD[&quot;Transverse Mercator&quot;, ID[&quot;EPSG&quot;,9807]], PARAMETER[&quot;Latitude of natural origin&quot;,0, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8801]], PARAMETER[&quot;Longitude of natural origin&quot;,-73.5, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8802]], PARAMETER[&quot;Scale factor at natural origin&quot;,0.9999, SCALEUNIT[&quot;unity&quot;,1], ID[&quot;EPSG&quot;,8805]], PARAMETER[&quot;False easting&quot;,304800, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8806]], PARAMETER[&quot;False northing&quot;,0, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8807]]], CS[Cartesian,2], AXIS[&quot;easting (E(X))&quot;,east, ORDER[1], LENGTHUNIT[&quot;metre&quot;,1]], AXIS[&quot;northing (N(Y))&quot;,north, ORDER[2], LENGTHUNIT[&quot;metre&quot;,1]], USAGE[ SCOPE[&quot;Engineering survey, topographic mapping.&quot;], AREA[&quot;Canada - Quebec between 75Â°W and 72Â°W.; Canada - Ontario - east of 75Â°W.&quot;], BBOX[44.98,-75,62.53,-72]], ID[&quot;EPSG&quot;,32188]] La fonction st_crs() donne beaucoup dinformations. Pour connaitre la projection utilisée, le datum, le code ESPG, ou lunité de mesure de la projection nous pouvons préciser la sortie désirée de la fonction, de la manière suivante: st_crs(limites_terrestres)$Name [1] &quot;NAD83 / MTM zone 8&quot; st_crs(limites_terrestres)$proj4string [1] &quot;+proj=tmerc +lat_0=0 +lon_0=-73.5 +k=0.9999 +x_0=304800 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; st_crs(limites_terrestres)$epsg [1] 32188 st_crs(limites_terrestres)$units [1] &quot;m&quot; Ainsi, la projection du shapefile pistes_cyclables est: st_crs(pistes_cyclables)$proj4string [1] &quot;+proj=tmerc +lat_0=0 +lon_0=-73.5 +k=0.9999 +x_0=304800 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; Et la projection du shapefile accidents_velo est: st_crs(accidents_velo)$proj4string [1] &quot;+proj=tmerc +lat_0=0 +lon_0=-73.5 +k=0.9999 +x_0=304800 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; Les données de tous les shapefiles sont dans la projection de Mercator transverse (+proj=tmerc) et utilisent le Système de référence géodésique nord-américain de 1983 (+datum=NAD83). Létendue spatiale Létendue spatiale dun objet spatial dans R, appelée le Bounding box, représente les limites géographiques des données, ou la localisation des données les plus au sud, nord, est et ouest. Pour connaître létendue spatiale des shapefiles nous utilisons la fonction st_bbox() de la librairie sf : st_bbox(limites_terrestres) xmin ymin xmax ymax 267517 5029232 306669 5062642 st_bbox(pistes_cyclables) xmin ymin xmax ymax 267984 5029291 306349 5062582 st_bbox(accidents_velo) xmin ymin xmax ymax 269489 5029752 305368 5059058 Les attributs Finalement, nous pouvons visualiser toutes les métadonnées et les attributs dun shapefile simplement en écrivant son nom dans la console R: limites_terrestres Simple feature collection with 72 features and 1 field Geometry type: POLYGON Dimension: XY Bounding box: xmin: 267500 ymin: 5029000 xmax: 306700 ymax: 5063000 Projected CRS: NAD83 / MTM zone 8 First 10 features: DefaultAtt geometry 1 &lt;NA&gt; POLYGON ((299608 5038364, 2... 2 &lt;NA&gt; POLYGON ((301350 5036978, 3... 3 &lt;NA&gt; POLYGON ((300403 5038997, 3... 4 &lt;NA&gt; POLYGON ((300744 5039496, 3... 5 &lt;NA&gt; POLYGON ((302032 5043372, 3... 6 &lt;NA&gt; POLYGON ((302299 5043145, 3... 7 &lt;NA&gt; POLYGON ((302508 5040978, 3... 8 &lt;NA&gt; POLYGON ((304719 5062024, 3... 9 &lt;NA&gt; POLYGON ((304927 5062499, 3... 10 &lt;NA&gt; POLYGON ((305396 5062622, 3... pistes_cyclables Simple feature collection with 6395 features and 1 field Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: 268000 ymin: 5029000 xmax: 306300 ymax: 5063000 Projected CRS: Transverse_Mercator First 10 features: TYPE_VOIE 1 Piste cyclable sur rue 2 Piste cyclable en site propre 3 Chaussée désignée 4 Bande cyclable 5 Piste cyclable en site propre 6 Piste cyclable en site propre 7 Piste cyclable en site propre 8 Chaussée désignée 9 Piste cyclable en site propre 10 Piste cyclable en site propre geometry 1 MULTILINESTRING ((297752 50... 2 MULTILINESTRING ((305050 50... 3 MULTILINESTRING ((299076 50... 4 MULTILINESTRING ((287779 50... 5 MULTILINESTRING ((300752 50... 6 MULTILINESTRING ((300953 50... 7 MULTILINESTRING ((299010 50... 8 MULTILINESTRING ((276415 50... 9 MULTILINESTRING ((293077 50... 10 MULTILINESTRING ((304787 50... accidents_velo Simple feature collection with 796 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: 269500 ymin: 5030000 xmax: 305400 ymax: 5059000 Projected CRS: Transverse_Mercator First 10 features: FID geometry 1 0 POINT (279673 5041015) 2 1 POINT (277292 5039169) 3 2 POINT (275581 5036314) 4 3 POINT (274728 5035946) 5 4 POINT (283935 5040875) 6 5 POINT (280442 5039871) 7 6 POINT (279626 5040700) 8 7 POINT (277734 5038853) 9 8 POINT (276487 5038090) 10 9 POINT (278357 5040125) 4.1.4 Visualisation de shapefiles sous R Visualisation avec la librairie Mapview Vous allez maintenant apprendre à visualiser des données shapefile en utilisant la fonction mapview() de la librairie mapview. Cette bibliothèque est une des plus simples à utiliser pour visualiser rapidement des données spatiales. Commençons par charger cette bibliothèque dans la console R: library(mapview) Dans un premier temps, visualisons les limites terrestres de la ville de Montréal. mapview(limites_terrestres, col.regions = &quot;white&quot;) Remarquez que nous avons choisi la couleur blanche pour représenter lintérieur des polygones délimitant la ville de Montréal. La couleur par défaut (c-à-d si on ne précise pas de couleur) est bleue. Passez votre curseur sur la carte ainsi créée et remarquez que vous pouvez cliquer sur chacun des polygones contenus dans cette couche de données. Remarquez aussi la légende dans le coin supérieur gauche de la carte créée et approchez-y votre curseur. Vous pouvez alors sélectionner une ou lautre des arrières-plans disponibles. Loption OpenStreetMap affichera la carte produite par ce gratuitiel de cartographie pour la région entourant le polygone illustré. Loption ESRI.WorldImagery, quant à elle, affichera une image satellitaire de la région. Dans un deuxième temps, visualisons les pistes cyclables. Utilisons toujours la fonction mapview() et demandons que la couleur du trait des lignes soit verte foncée. Pour définir la couleur des lignes, nous utilisons largument color et non largument col.regions. mapview(pistes_cyclables, color = &quot;darkgreen&quot;) Il existe 657 couleurs prédéfinies dans R. Taper la commande colors() dans votre console R pour voir afficher le nom des couleurs. Celles-sont sont listées par ordre alphabétique sauf pour la première couleur, qui est le blanc (white). Ainsi, vous pouvez utiliser une couleur en assignant son nom ou son numéro. Pour produire la figure précédente, color = \"darkgreen\" aurait pu être remplacé par color = colors()[81]. Essayez pour voir. Pour en apprendre davantage sur les couleurs dans R, vous êtes invité à consulter le site Earl Glynn et à conserver dans vos notes son tableau synthèse des couleurs dans R. Nous discuterons plus en détails des couleurs dans le Module 6 portant sur la cartographie. Dans la carte des pistes cyclables, remarquez la légende apparue dans le coin supérieur droit. Celle-ci identifie les différentes catégories de pistes cyclables. Cette information correspond aux différentes valeurs que peut prendre lattribut TYPE_VOIE du shapefile pistes_cyclables. Nous y reviendrons plus bas. Finalement, visualisons les accidents de la route impliquant des bicyclettes. mapview(accidents_velo, color = &quot;red&quot;, col.regions = &quot;red&quot;, cex = 1, legend = NULL) La position des accidents est représentée par des points dont le contour et lintérieur, dénotés par les arguments color et col.regions respectivement, sont de couleur rouge. Largument cex, quant à lui, indique la taille des cercles, la taille par défaut utilisée dans mapview est 2. Ici, nous avons demandé une taille plus petite afin de mieux différencier chacun des points. Visualiser des données vectorielles par attribut Lorsque nous avons affiché les métadonnées du shapefile pistes_cyclables, vous avez peut-être observé que ce dernier comprenait lattribut TYPE_VOIE qui caractérise le type de pistes cyclables de chaque multiligne. Affichons les métadonnées à nouveau: pistes_cyclables Simple feature collection with 6395 features and 1 field Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: 268000 ymin: 5029000 xmax: 306300 ymax: 5063000 Projected CRS: Transverse_Mercator First 10 features: TYPE_VOIE 1 Piste cyclable sur rue 2 Piste cyclable en site propre 3 Chaussée désignée 4 Bande cyclable 5 Piste cyclable en site propre 6 Piste cyclable en site propre 7 Piste cyclable en site propre 8 Chaussée désignée 9 Piste cyclable en site propre 10 Piste cyclable en site propre geometry 1 MULTILINESTRING ((297752 50... 2 MULTILINESTRING ((305050 50... 3 MULTILINESTRING ((299076 50... 4 MULTILINESTRING ((287779 50... 5 MULTILINESTRING ((300752 50... 6 MULTILINESTRING ((300953 50... 7 MULTILINESTRING ((299010 50... 8 MULTILINESTRING ((276415 50... 9 MULTILINESTRING ((293077 50... 10 MULTILINESTRING ((304787 50... Utilisons la fonction factor() pour convertir la classe de lattribut TYPE_VOIE de charactère (chr) à facteur (Factor). Puis, utilisons la fonction levels() pour connaître ces types de voie cyclables. La fonction levels donne les différentes valeurs que peuvent prendre un attribut. pistes_cyclables$TYPE_VOIE &lt;- factor(pistes_cyclables$TYPE_VOIE) levels(pistes_cyclables$TYPE_VOIE) [1] &quot;Bande cyclable&quot; [2] &quot;Chaussée désignée&quot; [3] &quot;Piste cyclable au niveau du trottoir&quot; [4] &quot;Piste cyclable en site propre&quot; [5] &quot;Piste cyclable sur rue&quot; [6] &quot;Sentier polyvalent&quot; Si vous ne connaissez pas la distinction entre ces types daménagement cyclable, consulter ce document sommaire de la Ville de Montréal31 Dans la figure précédente illustrant les pistes cyclables, celles-ci étaient illustrées en vert peu importe leur type. Nous voulons maintenant représenter les six types de voie cyclable par six couleurs différentes. Un des avantages de la fonction mapview() est quelle est capable demblée de distinguer les différentes valeurs que peuvent prendre un attribut. Ainsi, nous pouvons simplement demander: mapview(pistes_cyclables) Le shapefile pistes_cyclables contient un seul attribut, TYPE_VOIE. Si un shapefile contient plus dun attribut, il faut spécifier celui quon veut représenter en argument à la fonction mapview(). Dans le cas présent, nous aurions plutôt demandé: `mapview(pistes_cyclables, z = TYPE_VOIE). Par défaut, la fonction mapview() pour les données vectorielles utilise la palette de couleur viridis. Une palette de couleur est un ensemble de plusieurs couleurs prédéfinies et stocké dans un vecteur. Il existe plusieurs palettes de couleur prédéfinies et nous y reviendrons également au Module 6 portant sur la cartographie. La palette viridis forme un gradient allant du mauve au jaune en passant pas le bleu et le vert (Fig 4.1): FIGURE 4.1: Palette viridis contenant 20 couleurs différentes Un utilisateur de R peut utiliser des palettes prédéfinies, ou encore définir les siennes. Par exemple, si nous trouvons que les couleurs de la palette viridis ne permettent pas de bien différencier les différents types de piste cyclable, nous pouvons nous-même créer une palette contenant six couleurs (car il y a six valeurs possibles pour cet attribut). couleurs_voie &lt;- c(&quot;black&quot;,&quot;goldenrod&quot;, &quot;cornflowerblue&quot;, &quot;darkcyan&quot;, &quot;hotpink&quot;, &quot;mediumpurple&quot;) Nous pouvons ajouter cet argument à la fonction mapview(): mapview(pistes_cyclables, color=couleurs_voie, layer.name = &quot;Types de pistes cyclables&quot;, lwd = 1 ) Remarquez que nous avons changé le titre de la légende en utilisant largument layer.name, et que nous avons réduit lépaisseur des lignes en utilisant largument lwd. Visualiser plusieurs shapefiles Nous allons maintenant représenter les données vectorielles limites terrestres, pistes_cyclables et accidents_velo au sein dune même figure. Il sagit de définir individuellement chacune des cartes comme un objet mapview et de les additionner en utilisant lopérateur +. map_limites_terrestres &lt;- mapview(limites_terrestres, col.regions = &quot;darkgray&quot;, legend = NULL) map_pistes_cyclables &lt;- mapview(pistes_cyclables, color=couleurs_voie, layer.name = &quot;Types de pistes cyclables&quot;, lwd = 1) map_accidents &lt;- mapview(accidents_velo, color = &quot;red&quot;, col.regions = &quot;red&quot;, cex = 1, legend = NULL) map_limites_terrestres + map_pistes_cyclables + map_accidents 4.1.5 Reprojection de données vectorielles sous R Dans cette section vous apprendrez à manipuler le système de coordonnées de référence de données vectorielles. Nous avons vu en début de leçon que les données utilisées sont dans la projection de Mercator transverse (tmerc) et utilisent le Système de référence géodésique nord-américan de 1983 (NAD83). Par exemple, pour connaître la projection des données limites_terrestres, nous avions fait: st_crs(limites_terrestres)$proj4string [1] &quot;+proj=tmerc +lat_0=0 +lon_0=-73.5 +k=0.9999 +x_0=304800 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; Nous allons maintenant transformer le SCR vers la projection de Robinson (robin) et le Système géodésique mondial de 1984 (WGS84). Pour se faire nous utilisons la fonction st_transform() de la bibliothèque st. ##limites_terrestres_rob &lt;- st_transform(limites_terrestres, ## CRS(&quot;+proj=robin +datum=WGS84&quot;)) limites_terrestres_rob &lt;- st_transform(limites_terrestres, CRS(&quot;+proj=robin +lon_0=0 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs&quot; )) Comparons les données transformées avec les données initiales. Pour se faire, nous voulons représenter les deux cartes une à côté de lautre. La bibliothèque leafsync associée à la bibliothèque leaflet permet de créer facilement des figures avec des panneaux multiples. Nous discuterons plus en détails de ces bibliothèques dans le Module 6 portant sur la cartographie. Installez la bibliothèque leafsync si ce nest pas déjà fait, et chargez-là dans votre session de travail. library(leafsync) Représentons mainteant les deux projections différentes en utilisant la fonction latticeView() de la bibliothèque leafsync. Puisque cette fonction existe à la fois dans la bibliothèque leafsync et dans la bibliothèque mapview mais quelle est obsolète dans cette dernière, nous devons préciser que nous voulons la fonction latticeView()de la bibliothèqueleafsyncen utilisant la notation suivante:leafsync::latticeView` map_mercator &lt;- mapview(limites_terrestres, legend = FALSE, col.regions = &quot;red&quot;) map_robinson &lt;- mapview(limites_terrestres_rob, legend = FALSE) Map &lt;- leafsync::latticeView(map_mercator,map_robinson, ncol = 2) Map Nous remarquons que les deux cartes sont identiques (outre la couleur)! Comment cela est-ce possible sachant que nous venons de transformer la projection ? Ceci sexplique par le fait que la fonction mapview() représente par défaut toutes données spatiales dans la projection Pseudo-Mercator (ou Mercator Web), qui est la projection utilisée par lapplication OpenStreetMap. Ainsi, la fonction mapview calcule elle-même le changement de projection avant de représenter des données spatiales. Pour conserver la projection originale il faut utiliser largument native.crs=TRUE. Représentons à nouveau les cartes des limites terrestres de la région de Montréal, cette fois en précisant que nous voulons conserver le CRS dorgine. map_web &lt;- mapview(limites_terrestres, col.regions = &quot;red&quot;, legend = NULL, layer.name = &quot;Mercator Web&quot;) map_mercator &lt;- mapview(limites_terrestres, col.regions = &quot;yellow&quot;, legend = NULL, layer.name = &quot;Mercator&quot;, native.crs=TRUE) map_robinson &lt;- mapview(limites_terrestres_rob, legend = NULL, layer.name = &quot;Robinson&quot;, native.crs=TRUE) Map &lt;- leafsync::latticeView(map_web,map_mercator,map_robinson, ncol = 3) Map Remarquez que nous avons utilisé largument ncol dans la fonction latticeview pour spécifier le nombre de colonnes - c-à-d le nombre de panneaux verticaux quaura cette image. Finalement, pour sauvegarder des données vectorielles, nous utilisons la fonction st_write() de la bibliothèque st, de la même façon que nous avons utilisé la fonction st_read() en début de leçon. Par exemple, sauvons les données limites_terrestres_rob que nous venons de créer. 4.1.6 Lire une géodatabase et explorer ses couches Dans cette section, nous allons explorer les données vectorielles dune géodatabase du Ministère de lÉducation et de lEnseignement supérieur du Québec (MEES). Ces données se trouvent dans le dossier Donnees_Ouvertes_MEES.gbd que vous avez normalement téléchargé au début de la leçon. Lire les données Dans la section portant sur le format des données vectorielles du Module 2, nous avons expliqué quune géodatabase est une façon de rassembler et dorganiser des données propres à un sujet dans une unique base de données. La géodatabase Donnees_Ouvertes_MEES.gdb contient plusieurs couches de données vectorielles (layers) sur les établissements denseignement au Québec. Pour lire et explorer une géodatabase, on continue à utiliser la bibliothèques sf. Chaque couche peut être lue individuellement en utilisant la fonction st_read(): st_read(\"nom_de_la_geodatabase.gdb\", layer = \"nom_de_la_couche\"). Il est donc nécessaire de connaître dabord les noms donnés aux couches composants la géodatabase - information qui nous est, pour linstant, inconnue. Pour connaître les couches dune géodatabase, nous utilisons la fonction st_layers() couches_mees &lt;- st_layers(&quot;Module4/Module4_donnees/Donnees_Ouvertes_MEES.gdb&quot;) couches_mees Driver: OpenFileGDB Available layers: layer_name geometry_type features 1 CS_STA Multi Polygon 3 2 CS_FRA Multi Polygon 60 3 CS_ANG Multi Polygon 9 4 CS_STA_GEN Multi Polygon 3 5 CS_ANG_GEN Multi Polygon 9 6 CS_FRA_GEN Multi Polygon 60 7 CS_FRA_SDA Multi Polygon 60 8 CS_ANG_SDA Multi Polygon 9 9 CS_STA_SDA Multi Polygon 3 10 PPS_Public_SSocial_Org Point 2748 11 PPS_Prive_Installation Point 350 12 PPS_Prive_Etablissement Point 261 13 PPS_Gouvernemental Point 37 14 PPS_Public_SSocial_CS Point 72 15 ES_Universitaire Point 22 16 PPS_Public_Ecole Point 5202 17 PPS_Public_Immeuble Point 4641 18 ES_Collegial Point 311 fields crs_name 1 9 WGS 84 / Pseudo-Mercator 2 9 WGS 84 / Pseudo-Mercator 3 9 WGS 84 / Pseudo-Mercator 4 9 WGS 84 / Pseudo-Mercator 5 9 WGS 84 / Pseudo-Mercator 6 9 WGS 84 / Pseudo-Mercator 7 9 WGS 84 / Pseudo-Mercator 8 9 WGS 84 / Pseudo-Mercator 9 9 WGS 84 / Pseudo-Mercator 10 24 WGS 84 / Pseudo-Mercator 11 24 WGS 84 / Pseudo-Mercator 12 15 WGS 84 / Pseudo-Mercator 13 22 WGS 84 / Pseudo-Mercator 14 16 WGS 84 / Pseudo-Mercator 15 17 WGS 84 / Pseudo-Mercator 16 29 WGS 84 / Pseudo-Mercator 17 22 WGS 84 / Pseudo-Mercator 18 17 WGS 84 / Pseudo-Mercator Nous observons que la géodatabase contient 18 couches différentes. Nous pouvons connaître le nom donné à chaque couche (layer_name), leur géométrie (geometry_type), le nombre dobjets vectoriels quelles contiennent (features), et le nombre dattributs quelles décrivent (fields). Les couches dont le nom commence par CS_ contiennent des données vectorielles relatives aux centres de services scolaires32. Puisque chacun de ces centres couvre un territoire qui leur est propre, ces données sont des multi-polygones. Les couches dont le nom commence par PPS_ et ES_ contiennent des données vectorielles relatives aux établissements denseignement primaire, secondaire et supérieure. Puisque chacun de ces établissements est identifié par une paire de coordonnées, ces données sont des points. Lisons les données vectorielles de la couche PPS_Public_Ecole en utilisant la fonction st_read(). ecoles_pub &lt;- st_read(&quot;Module4/Module4_donnees/Donnees_Ouvertes_MEES.gdb&quot;, layer = &quot;PPS_Public_Ecole&quot;) Reading layer `PPS_Public_Ecole&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module4\\Module4_donnees\\Donnees_Ouvertes_MEES.gdb&#39; using driver `OpenFileGDB&#39; Simple feature collection with 5202 features and 29 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -8849000 ymin: 5623000 xmax: -6360000 ymax: 8958000 Projected CRS: WGS 84 / Pseudo-Mercator Cette couche donne la localisation des 5202 écoles primaires et secondaires publiques de la province ainsi que 28 autres attributs associés à ces établissements. Notez le système de coordonnées de référence: le datum WGS84 et la projection Pseudo-Mercator (ou Mercator Web) sont utilisés. Notez aussi que cette couche de la géodatabase possède la même structure que celle dun shapefile. Nous pouvons visualiser la position des écoles publiques du Québec en utilisant la fonction mapview() de la bibliothèque mapview. mapview(ecoles_pub) Nous remarquons quil est difficile de visualiser la position des écoles dans la région Sud du Québec car il y a énormément de points. Explorer les attributs dune couche Pour explorer les attributs associés à la couche ecoles_pub, commençons dabord par utiliser la fonction names() qui retourne le nom associé à chaque attribut de la couche. names(ecoles_pub) [1] &quot;DT_MAJ_GDUNO&quot; [2] &quot;COMBINE_NUO_NUI&quot; [3] &quot;CD_ORGNS&quot; [4] &quot;NOM_COURT_ORGNS&quot; [5] &quot;NOM_OFFCL_ORGNS&quot; [6] &quot;ADRS_GEO_L1_GDUNO_ORGNS&quot; [7] &quot;ADRS_GEO_L2_GDUNO_ORGNS&quot; [8] &quot;CD_POSTL_GDUNO_ORGNS&quot; [9] &quot;CD_MUNCP_GDUNO_ORGNS&quot; [10] &quot;NOM_MUNCP_GDUNO_ORGNS&quot; [11] &quot;CD_IMM&quot; [12] &quot;NOM_IMM&quot; [13] &quot;ADRS_GEO_L1_GDUNO_IMM&quot; [14] &quot;ADRS_GEO_L2_GDUNO_IMM&quot; [15] &quot;CD_MUNCP_GDUNO_IMM&quot; [16] &quot;NOM_MUNCP_GDUNO_IMM&quot; [17] &quot;CD_POSTL_GDUNO_IMM&quot; [18] &quot;PRESC&quot; [19] &quot;PRIM&quot; [20] &quot;SEC&quot; [21] &quot;FORM_PRO&quot; [22] &quot;ADULTE&quot; [23] &quot;SITE_WEB_ORGNS&quot; [24] &quot;COORD_X_LL84_IMM&quot; [25] &quot;COORD_Y_LL84_IMM&quot; [26] &quot;ORDRE_ENS&quot; [27] &quot;CD_CS&quot; [28] &quot;TYPE_CS&quot; [29] &quot;STYLE_CART&quot; [30] &quot;SHAPE&quot; Notre première réaction à la lecture de ces noms est quils ne sont pas tous intuitifs! Examinons les quatre attributs suivants: NOM_OFFCL_ORGNS, NOM_MUNCP_GDUNO_IMM, TYPE_CS, et SHAPE. Lattribut NOM_OFFCL_ORGNS correspond au nom de chaque école publique. On peut lire les premières entrées de cette liste de noms en utilisant la fonction head(): head(ecoles_pub$NOM_OFFCL_ORGNS) [1] &quot;Centre de formation professionnelle de Mont-Joli-Mitis&quot; [2] &quot;Centre de formation des adultes de Mont-Joli-Mitis&quot; [3] &quot;École des Alizés&quot; [4] &quot;École de l&#39;Écho-des-Montagnes-Lavoie&quot; [5] &quot;École de Mont-Saint-Louis-Saint-Rosaire&quot; [6] &quot;École des Sources&quot; Lattribut NOM_MUNCP_GDUNO_IMM correspond au nom de la municipalité dans laquelle se trouve une école publique. Pour avoir un aperçu des valeurs données, on utilise encore la fonction head: head(ecoles_pub$NOM_MUNCP_GDUNO_IMM) [1] &quot;Mont-Joli&quot; [2] &quot;Mont-Joli&quot; [3] &quot;Mont-Joli&quot; [4] &quot;Saint-Fabien&quot; [5] &quot;Rimouski&quot; [6] &quot;Saint-Anaclet-de-Lessard&quot; Lattribut TYPE_CS identifie les écoles selon leur appartenance à une commision scolaire francophone, anglophone ou à statut linguistique particulier. head(ecoles_pub$TYPE_CS) [1] &quot;Franco&quot; &quot;Franco&quot; &quot;Franco&quot; &quot;Franco&quot; &quot;Franco&quot; [6] &quot;Franco&quot; Il y a trois types de commissions scolaires possibles: Anglo, Franco, et Statut. Il est possible dobtenir cette information en utilisant la fonction levels() précédée de la fonction as.factor(): levels(as.factor(ecoles_pub$TYPE_CS)) [1] &quot;Anglo&quot; &quot;Franco&quot; &quot;Statut&quot; Finalement, lattribut SHAPE donne la position géographique de chaque école publique et les métadonnées spatiales associées à cette couche: head(ecoles_pub$SHAPE) Geometry set for 6 features Geometry type: POINT Dimension: XY Bounding box: xmin: -7666000 ymin: 6156000 xmax: -7590000 ymax: 6205000 Projected CRS: WGS 84 / Pseudo-Mercator First 5 geometries: POINT (-7590676 6204635) POINT (-7590676 6204635) POINT (-7590441 6205128) POINT (-7665998 6156083) POINT (-7648497 6168694) Sélection dun sous-ensemble de données Pour simplifier la visualisation de cette couche, nous allons nous concentrer sur les écoles de la municipalité de Montréal. Pour ce faire, nous créons un nouveau shapefile en sélectionnant les données propres à la municipalité de Montréal: ecoles_pub_Mtl&lt;- ecoles_pub[ecoles_pub$NOM_MUNCP_GDUNO_IMM == &quot;Montréal&quot;,] Interprétons cette ligne de commande: elle utilise lopérateur logique == pour sélectionner les écoles publiques de la municipalité de Montréal, ainsi que tous les autres attributs au sein de la couche ecoles_pub. Visualisons maintenant ce nouveau shapefile en utilisant la fonction mapview(). map_pub_mtl&lt;-mapview(ecoles_pub_Mtl, cex = 2) map_pub_mtl Ici, nous avons utilisé largument cex pour diminuer la taille des points sur la carte (la taille par défaut est 6). En cliquant sur lun ou lautre des points vous obtiendrez lensemble des attributs propres à lécole sélectionnée. Nous pouvons également assigner des couleurs aux données vectorielles en fonction des valeurs dun de ses attributs. Ceci est possible en utilisant largument zcol de la fonction mapview() et en lui assignant de nom de lattribut que nous désirons illustrer. Utilisons, par exemple, lattribut TYPE_CS qui indique la langue de la commission scolaire. mapview(ecoles_pub_Mtl, zcol = &quot;TYPE_CS&quot;, cex = 2, layer.name = &#39;Commissions scolaires&#39;) De façon similaire, nous aurions pu représenter les écoles de lîle de Montréal selon le niveau denseignement quon y dispense. Cette information est donnée par lattribut ORDRE_ENS. mapview(ecoles_pub_Mtl, zcol = &quot;ORDRE_ENS&quot;, cex = 2, layer.name = &#39;Enseignement&#39;) Visualisation de plusieurs couches dune géodatabse Nous voulons visualiser dautres types détablissement denseignement donnés dans la géodatabase du Ministère de lÉducation et de lEnseignement supérieur du Québec. Choisissons les écoles privées, les établissements de niveau collégial (e.g. CÉGEP) et les universités. Pour se faire nous utilisons encore la fonction st_read en spécifiant le nom de la couche (layer) désirée. ecoles_priv &lt;- st_read(&quot;Module4/Module4_donnees/Donnees_Ouvertes_MEES.gdb&quot;, layer = &quot;PPS_Prive_Etablissement&quot;) Reading layer `PPS_Prive_Etablissement&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module4\\Module4_donnees\\Donnees_Ouvertes_MEES.gdb&#39; using driver `OpenFileGDB&#39; Simple feature collection with 261 features and 15 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -8442000 ymin: 5623000 xmax: -7391000 ymax: 6484000 Projected CRS: WGS 84 / Pseudo-Mercator college&lt;- st_read(&quot;Module4/Module4_donnees/Donnees_Ouvertes_MEES.gdb&quot;, layer = &quot;ES_Collegial&quot;) Reading layer `ES_Collegial&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module4\\Module4_donnees\\Donnees_Ouvertes_MEES.gdb&#39; using driver `OpenFileGDB&#39; Simple feature collection with 311 features and 17 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -8795000 ymin: 5661000 xmax: -6892000 ymax: 6486000 Projected CRS: WGS 84 / Pseudo-Mercator univ &lt;- st_read(&quot;Module4/Module4_donnees/Donnees_Ouvertes_MEES.gdb&quot;, layer = &quot;ES_Universitaire&quot;) Reading layer `ES_Universitaire&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module4\\Module4_donnees\\Donnees_Ouvertes_MEES.gdb&#39; using driver `OpenFileGDB&#39; Simple feature collection with 22 features and 17 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -8795000 ymin: 5679000 xmax: -7627000 ymax: 6182000 Projected CRS: WGS 84 / Pseudo-Mercator Toujours dans le but de simplifier la visualisation, sélectionnons au sein des couches ecoles_priv, college et univ les établissements situés à Montréal. Attention, pour ces couches le nom de lattribut associé à la municipalié où se situe les établissements listés est NOM_MUNCP et non NOM_MUNCP_GDUNO_IMM. ecoles_priv_Mtl &lt;- ecoles_priv[ecoles_priv$NOM_MUNCP == &quot;Montréal&quot;,] college_Mtl &lt;- college[college$NOM_MUNCP == &quot;Montréal&quot;,] univ_Mtl &lt;- univ[univ$NOM_MUNCP == &quot;Montréal&quot;,] Nous pouvons visualiser chacun de ces nouveaux shapefile individuellement en utilisant la fonction mapview(), mais plus intéressant encore est de les visualiser ensemble au sein dune même carte. Pour se faire nous créons dabord des cartes individuelles. map_priv_mtl &lt;- mapview(ecoles_priv_Mtl, color = &quot;red&quot;, col.regions = &quot;red&quot;, cex = 2) map_college_mtl &lt;- mapview(college_Mtl, color = &quot;green&quot;, col.regions = &quot;green&quot;, cex = 4) map_univ_mtl &lt;- mapview(univ_Mtl, color = &quot;orange&quot;, col.regions = &quot;orange&quot;, cex = 6) Remarquez que nous utilisons différentes tailles de points et différentes couleurs pour bien différencier le type dinstitution dans la carte qui les combinera. La couleur du contour du point est donnée par largument color et celle de lintérieur du point par largument col.regions. Nous combinons toutes les couches par une simple addition des cartes individuelles map_pub_mtl + map_priv_mtl + map_college_mtl + map_univ_mtl Dans le menu du coin supérieur gauche de la carte, remarquez que vous pouvez sélectionner/désélectionner chaque couche selon linformation que vous désirez explorer. Il serait intéressant de créer une nouvelle géodatabase pour sauvegarder les quatre nouveaux shapefiles des institutions denseignement à Montréal au sein dune même structure. Malheureusement R peut seulement lire des géodatabases mais ne peut pas sauvegarder ce format qui est propriétaire de ESRI. Ainsi, il faudrait utiliser la fonction st_write() pour sauvegarder chacun des shapefiles individuellement. Ville de Montréal. Aménagements cyclables. Repéré le 19 mars 2020 Les centres de services scolaires (qui remplacent les commissions scolaires depuis 2020) ont pour rôle dépauler les établissements denseignement situés sur leur territoire. Pour plus dinformations, consultez le site web du MEES32 "],["ex_vec.html", "4.2 Exercices", " 4.2 Exercices Dans cette section, vous mettrez en pratique certains concepts vus dans la section leçon de ce module. Bien que la réponse à chaque question soit disponible, il est très important de tenter dy répondre par vous même! Question 1 Créer une géométrie simple de type polygone qui a la forme dun carré de 10 unités de long avec un trou en son centre qui a la forme dun carré de 4 unités de long. Réponse Définir deux matrices de coordonnées, une pour le grand et lautre pour le petit carré. Les coordonnées exactes peuvent prendre nimporte quelles valeurs du moment que la taille de chaque carré respecte les dimensions demandées. matrice_carre_grand &lt;- rbind(c(1,1), c(1,11), c(11,11), c(11,1), c(1,1)) matrice_carre_petit &lt;- rbind(c(4,4),c(4,8),c(8,8),c(8,4),c(4,4)) Créer une liste avec ces deux matrices et créer le polygone en utilisant la fonction st_polygon() polygone &lt;- st_polygon(list(matrice_carre_grand, matrice_carre_petit)) polygone POLYGON ((1 1, 1 11, 11 11, 11 1, 1 1), (4 4, 4 8, 8 8, 8 4, 4 4)) Visualiser le polygone pour confirmer votre réponse: mapview(polygone) Question 2 a) Créer 3 géométries simples de type ligne en utilisant les matrices de coordonnées suivantes: matrice_ligne1 &lt;- rbind(c(1,1), c(2,2), c(3,1), c(4,2), c(5,1), c(6,2), c(7,1)) matrice_ligne2 &lt;- rbind(c(1,5), c(3,3), c(7,5), c(3,5), c(4,4)) matrice_ligne3 &lt;- rbind(c(1,3), c(3,7), c(7,8), c(10,10)) Réponse Utiliser la fonction st_lignestring() pour créer les 3 géométries simples de type ligne. ligne1 &lt;- st_linestring(matrice_ligne1) ligne2 &lt;- st_linestring(matrice_ligne2) ligne3 &lt;- st_linestring(matrice_ligne3) b) Définir une couche de données vectorielles comprenant ces 3 lignes, et lui attribuer la projection Web de Mercator. Réponse Créer dabord un objet sfc, cest-à-dire une simple feature column, en utilisant la fonction st_sfc(): lignes &lt;- st_sfc(ligne1, ligne2, ligne3) Ajouter maintenant le SCR demandé. La projection Web de Mercator possède le code EPSG 3857 (revoir le Module 3 pour trouver cette information). lignes &lt;- st_sfc(ligne1, ligne2, ligne3, crs = 3857) lignes Geometry set for 3 features Geometry type: LINESTRING Dimension: XY Bounding box: xmin: 1 ymin: 1 xmax: 10 ymax: 10 Projected CRS: WGS 84 / Pseudo-Mercator LINESTRING (1 1, 2 2, 3 1, 4 2, 5 1, 6 2, 7 1) LINESTRING (1 5, 3 3, 7 5, 3 5, 4 4) LINESTRING (1 3, 3 7, 7 8, 10 10) c) Ajouter deux attributs à cette couche de données. Le premier attribut correspond à un nom de votre choix pour désigner chaque ligne, et le deuxième attribut correspond au nombre dextrémités dans chaque ligne. Réponse Créer une table dattribut en utilisant la fonction data.frame(). lignes_att &lt;- data.frame( nom = c(&quot;Zigzag&quot;, &quot;Tourbillon&quot;, &quot;Tordu&quot;), nombre = c(nrow(matrice_ligne1), nrow(matrice_ligne2), nrow(matrice_ligne3)) ) lignes_att nom nombre 1 Zigzag 7 2 Tourbillon 5 3 Tordu 4 Créer un objet sf, cest-à-dire un simple feature, en utilisant la fonction st_sf() pour unir la table dattributs des lignes à leur composante spatiale. lignes_sf &lt;- st_sf(lignes, lignes_att) lignes_sf Simple feature collection with 3 features and 2 fields Geometry type: LINESTRING Dimension: XY Bounding box: xmin: 1 ymin: 1 xmax: 10 ymax: 10 Projected CRS: WGS 84 / Pseudo-Mercator nom nombre lignes 1 Zigzag 7 LINESTRING (1 1, 2 2, 3 1, ... 2 Tourbillon 5 LINESTRING (1 5, 3 3, 7 5, ... 3 Tordu 4 LINESTRING (1 3, 3 7, 7 8, ... d) Visualiser cette couche de données vectorielles. Assurez-vous davoir une légende identifiant chaque ligne par son nom. Réponse Utiliser la fonction mapview() et spécifier que largument z correspond à lattribut nom de lobjet lignes_sf. mapview(lignes_sf, z=&quot;nom&quot;, layer.name = &quot;Nom des lignes&quot;) Question 3 Pour cette question, vous utiliserez les données vectorielles décrivant les régions administratives de la Nouvelle-Zélande. Ces données se nomment nz et sont disponibles dans la bibliothèque spData. library(spData) data(nz) a) Combien déléments spatiaux contient la couche nz et de quel type de géométrie sont ces éléments ? Réponse Pour répondre à cette question, nous pouvons simplement repérer linformation demandée dans laffichage général de lobjet nz nz Simple feature collection with 16 features and 6 fields Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin: 1090000 ymin: 4749000 xmax: 2090000 ymax: 6192000 Projected CRS: NZGD2000 / New Zealand Transverse Mercator 2000 First 10 features: Name Island Land_area Population 1 Northland North 12501 175500 2 Auckland North 4942 1657200 3 Waikato North 23900 460100 4 Bay of Plenty North 12071 299900 5 Gisborne North 8386 48500 6 Hawke&#39;s Bay North 14138 164000 7 Taranaki North 7254 118000 8 Manawatu-Wanganui North 22221 234500 9 Wellington North 8049 513900 10 West Coast South 23245 32400 Median_income Sex_ratio 1 23400 0.9425 2 29600 0.9443 3 27900 0.9521 4 26200 0.9280 5 24400 0.9350 6 26100 0.9238 7 29100 0.9569 8 25000 0.9388 9 32700 0.9336 10 26900 1.0139 geom 1 MULTIPOLYGON (((1745493 600... 2 MULTIPOLYGON (((1803822 590... 3 MULTIPOLYGON (((1860345 585... 4 MULTIPOLYGON (((2049387 583... 5 MULTIPOLYGON (((2024489 567... 6 MULTIPOLYGON (((2024489 567... 7 MULTIPOLYGON (((1740438 571... 8 MULTIPOLYGON (((1866732 566... 9 MULTIPOLYGON (((1881590 548... 10 MULTIPOLYGON (((1557042 531... Nous pouvons y lire quil y a 16 éléments (features) et que la géométrie est de type multipolygone. Nous pouvons également trouver les réponses en utilisant les deux fonctions spécifiques suivantes: nrow(nz) [1] 16 Effectivement, nz étant un data.frame, nous pouvons utilisé les manipulations usuelles pour cette classe dobjet. Chaque élément dans un data.frame occupe une rangée. st_geometry_type(nz) [1] MULTIPOLYGON MULTIPOLYGON MULTIPOLYGON [4] MULTIPOLYGON MULTIPOLYGON MULTIPOLYGON [7] MULTIPOLYGON MULTIPOLYGON MULTIPOLYGON [10] MULTIPOLYGON MULTIPOLYGON MULTIPOLYGON [13] MULTIPOLYGON MULTIPOLYGON MULTIPOLYGON [16] MULTIPOLYGON 18 Levels: GEOMETRY POINT LINESTRING ... TRIANGLE Cette commande nous confirme que la couche nz contient bien des multipolygones. b) Trouver le nombre dattributs de nz et leur nom. Réponse Pour trouver le nombre dattributs, nous pouvons nous référer à laffichage général de nz (voir plus haut) qui nous informe que lobjet contient 6 attributs (ou champs, fields en anglais). Nous pouvons également utiliser la fonction ncol() qui donne le nombre de colonnes dans le data.frame. ncol(nz) [1] 7 Lobjet nz contient bel et bien 7 colonnes. Cependant, la dernière colonne correspond à la géométrie de chaque élément de nz (qui est en fait, un attribut spatial). Ainsi, le nombre dattribut est 6. Pour trouver le nom des attributs, nous pouvons encore sappuyer sur le fait que nz est un data.frame et utiliser la fonction names(): names(nz) [1] &quot;Name&quot; &quot;Island&quot; &quot;Land_area&quot; [4] &quot;Population&quot; &quot;Median_income&quot; &quot;Sex_ratio&quot; [7] &quot;geom&quot; c) Trouver le code EPSG, le nom et lunité de mesure de la projection utilisée. Réponse Ces trois informations se trouvent en utilisant les fonctions suivantes: st_crs(nz)$epsg [1] 2193 st_crs(nz)$Name [1] &quot;NZGD2000 / New Zealand Transverse Mercator 2000&quot; st_crs(nz)$units [1] &quot;m&quot; La projection utilisée est le New Zealand Transverse Mercator 2000. NZGD 2000 réfère au datum utilisé, appelé le New Zealand Geodetic Datum. d) Transformer la projection de nz pour la projection conique conforme de Lambert (LCC). Réponse La projection conique conforme de Lambert est donnée par le code EPSG 32198. nz_lcc &lt;- st_transform(nz, crs = 32198) Vérifions que notre transformation est correcte. st_crs(nz_lcc)$proj4string [1] &quot;+proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; e) Chaque polygone de la couche nz correspond à une région. Visualiser la couche nz en illustrant chaque région avec une couleur différente. Réponse mapview(nz, zcol = &quot;Name&quot;, layer.name = &quot;Régions&quot;) f) Importer le fichier nz_capitales.cvs contenu dans le dossier Module4_donnees. Ce fichier donne le nom et la localisation des capitales de chaque région de la Nouvelle-Zélande. Créer une carte illustrant les frontières des régions ainsi que la position de leur capitale respective. Réponse Tout dabord, vous devez importer le fichier nz_capitales.cvs dans votre session de travail R. Utiliser la fonction de base read.table() afin de stocker les coordonnées des capitales dans un object de classe data.frame. nz_capitales &lt;- read.table(&quot;Module4/Module4_donnees/nz_capitales.csv&quot;, header = TRUE, sep = &quot;,&quot;) nz_capitales Capitales Longitude Latitude 1 Auckland 174.8 -36.85 2 Wellington 174.8 -41.29 3 Christchurch 172.6 -43.53 4 Hamilton 175.3 -37.78 5 Dunedin 170.5 -45.87 6 Palmerston North 175.6 -40.35 7 Napier 176.9 -39.48 8 Whangarei 174.3 -35.73 9 Invercargill 168.4 -46.43 10 Nelson 173.2 -41.29 11 Gisborne 178.0 -38.66 12 Blenheim 173.9 -41.52 13 Richmond 173.2 -41.33 14 Whakatane 177.0 -37.96 15 Greymouth 171.2 -42.47 16 Stratford 174.3 -39.34 Nous observons que les coordonnées sont en format longitude/latitude. Utiliser la fonction st_as_sf() pour transformer cette table de coordonnées en données vectorielles de type points. Puisque les coordonnées sont en format longitude/latitude, nous ne pouvons pas assigner un système de coordonnées projecté cartésien. Utilisons simplement le datum WGS 84 pour définir le SCR. Ce dernier est associé au code EPSG 4326. nz_capitales_points &lt;- st_as_sf(x = nz_capitales, coords = c(&quot;Longitude&quot;, &quot;Latitude&quot;), crs = 4126) Utiliser la fonction mapview() pour visualiser les polygones des régions et les points correspondants aux capitales de ces régions. mapview(nz, col.regions = &quot;blue&quot;, legend = FALSE) + mapview(nz_capitales_points) Notez que nous navons pas besoin de nous assurer que les deux couches soient dans le même SCR puisque la fonction mapview() représente par défaut toutes données spatiales dans la projection Mercator Web. "],["mat.html", "Module 5 Données matricielles", " Module 5 Données matricielles Cette leçon est une introduction aux données spatiales matricielles sous R. Son objectif principal est dapprendre à lire, interpréter et visualiser des données matricielles. Notez que la section 2.3 Raster data du livre Geocomputation with R des auteurs Robin Lovelace, Jakub Nowosad, et Jannes Muenchow (Lovelace, Nowosad, and Muenchow 2021) est un bon accompagnement à ce module. À la fin de ce module vous saurez: Créer et lire un raster. Interpréter la géométrie dun raster. Comprendre la structure dun raster. Obtenir des statistiques simples sur les données contenues dans un raster. Visualiser un raster. Transformer le système de coordonnées de référence dun raster. Transformer la résolution dun raster. Lire et visualiser un raster multi-bande. Vous utiliserez les bibliothèques suivantes: raster mapview leafsync FedData Vous apprendrez à utiliser les fonctions suivantes: raster() getValues() maxValue() cellStats() ncell() res() extent() crs() aggregate() projectRaster() writeRaster() brick() stack() viewRGB() mapview() et latticeView(), que vous connaissez déjà. ratify() Vous utiliserez les données suivantes: Vous utiliserez aussi les fonctions suivantes, qui ne sont pas spécifiques aux données spatiales: dim() class() levels() factor(), as.factor() plot(), hist(), boxplot() as.data.frame() head() max(), min(), median(), median() which.max(), which.min() summary() names() Dans la section leçon, vous utiliserez deux ensembles de données matricielles. Le premier ensemble contient des données spatiales relatives aux îlots de chaleur urbain dans la région de la ville de Québec. Le second ensemble contient des données spatiales satellites captées par Landsat près de la ville de La Tuque en Mauricie. Dans la section exercices, vous utiliserez des données de couverture terrestre dune région du Colorado aux États-Unis. "],["lecon_mat.html", "5.1 Leçon", " 5.1 Leçon 5.1.1 Télécharger les données Les données Dans les sections 5.1.5 à 5.1.10 ainsi que dans la section exercices du présent module, vous apprendrez à lire et visualiser des données déjà existantes. Afin de faciliter le téléchargement de ces multiples données, lensemble des couches dinformations spatiales peuvent être téléchargées en cliquant sur un seul lien: données pour le module 5. Sauvegardez le dossier compressé (zip) dans votre répertoire de travail Module5_donnees pour ce module, et dézippez-le. Le dossier comprend quatre fichiers tif: Temp_vdq.tif Landsat_LaTuque.tif Couvert_2001.tif Couvert_2016.tif Les données matricielles Temp_vdq.tif présentent la température de surface sur le territoire de la ville de Québec. Le fichier Landsat_LaTuque.tif contient des données captées par le satellite Landsat sur une section du territoire de la Haute Mauricie, près de la ville de La Tuque. Les données Couvert_2001.tif et Couvert_2016.tif correspondent à la couverture terrestre (p. ex. forêt, champ, eau, etc.) dune petite région du Colorado aux années 2001 et 2016. Ces données sont utilisées dans la section exercices. 5.1.2 Créer des données matricielles Les données matricielles représentent la surface terrestre par une grille régulière, communément appelé un raster. Dans cette leçon, nous utiliserons les expressions «raster» et «données matricielles» de façon interchangeable. Pour créer, lire et manipuler des données matricielles, nous allons utiliser la bibliothèque raster. Commençons par charger la bibliothèque raster dans notre session de travail R. # Installez la bibliothèque si ce n&#39;est pas déjà fait # install.packages(&quot;raster&quot;) # Chargez la bibliothèque library(raster) Créer un raster simple et le visualiser Au module 2, nous avons expliqué quun raster est formé de rectangles de même forme et de même dimension appelés cellules ou pixels. À chaque cellule de cette matrice correspond une valeur numérique (ou une valeur manquante) associée à un attribut dintérêt. On appelle couche (« layer » en anglais) linformation recueillie dans la matrice. La fonction raster() de la bibliothèque raster permet de créer un raster. Par exemple: M &lt;- raster(nrows=8, ncols=8, xmn = 1, xmx = 5, ymn = 1, ymx = 5, vals = 1:64) Où nrows et ncols correspondent respectivement au nombre de lignes et au nombre de colonnes du raster M, xmn et xmx correspondent respectivement aux coordonnées-x minimale et maximale du raster, ymn et ymx aux coordonnées-y minimale et maximale, et vals est un vecteur comprenant la valeur de chaque pixel du raster. Dans le cas présent, le raster M contient 64 pixels. Le premier pixel a la valeur 1, le deuxième pixel a la valeur 2 et ainsi de suite. Voyons les informations données, lorsque nous appelons le raster M que nous venons de créer: M class : RasterLayer dimensions : 8, 8, 64 (nrow, ncol, ncell) resolution : 0.5, 0.5 (x, y) extent : 1, 5, 1, 5 (xmin, xmax, ymin, ymax) crs : +proj=longlat +datum=WGS84 +no_defs source : memory names : layer values : 1, 64 (min, max) Nous remarquons que des informations additionnelles apparaissent: ncell correspond au nombre de cellules (ou de pixels) dans le raster, resolution correspond à la résolution des pixels, extent correspond à létendue du raster définie par ses coordonnées maximales et minimales, et crs correspond aux paramètres du système de coordonnées de référence utilisé. Si le SCR dun raster nest pas défini au moment de sa création, comme dans le cas présent, alors le SCR WGS84 sera attribué par défaut. Remarquez que la classe (class) de lobjet M est défini comme étant un RasterLayer. Nous verrons dans la dernière section de cette leçon quil existe dautres classes de raster, soit les RasterBrick et les RasterStack. Remarquez aussi que la résolution dun pixel est de 0.5 x 0.5, car les 64 pixels du raster occupent le carré daire 16 délimité par les quatre points (1,1), (1,5), (5,1) et (5,5). Ainsi, une façon équivalente de créer le raster M est: M &lt;- raster(res = 0.5, xmn = 1, xmx = 5, ymn = 1, ymx = 5, vals = 1:64) M class : RasterLayer dimensions : 8, 8, 64 (nrow, ncol, ncell) resolution : 0.5, 0.5 (x, y) extent : 1, 5, 1, 5 (xmin, xmax, ymin, ymax) crs : +proj=longlat +datum=WGS84 +no_defs source : memory names : layer values : 1, 64 (min, max) Dans cette notation, nous avons spécifié la résolution et non la dimension du raster. Nous pouvons également connaître les paramètres dun raster en utilisant les fonctions correspondantes. dim(M) [1] 8 8 1 ncell(M) [1] 64 nrow(M) [1] 8 ncol(M) [1] 8 res(M) [1] 0.5 0.5 extent(M) class : Extent xmin : 1 xmax : 5 ymin : 1 ymax : 5 crs(M) Coordinate Reference System: Deprecated Proj.4 representation: +proj=longlat +datum=WGS84 +no_defs WKT2 2019 representation: GEOGCRS[&quot;unknown&quot;, DATUM[&quot;World Geodetic System 1984&quot;, ELLIPSOID[&quot;WGS 84&quot;,6378137,298.257223563, LENGTHUNIT[&quot;metre&quot;,1]], ID[&quot;EPSG&quot;,6326]], PRIMEM[&quot;Greenwich&quot;,0, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8901]], CS[ellipsoidal,2], AXIS[&quot;longitude&quot;,east, ORDER[1], ANGLEUNIT[&quot;degree&quot;,0.0174532925199433, ID[&quot;EPSG&quot;,9122]]], AXIS[&quot;latitude&quot;,north, ORDER[2], ANGLEUNIT[&quot;degree&quot;,0.0174532925199433, ID[&quot;EPSG&quot;,9122]]]] Il existe plusieurs fonctions permettant de visualiser les rasters. Nous pouvons simplement utiliser la fonction plot(). plot(M) FIGURE 5.1: Visualisation du raster M avec la fonction plot() Nous pouvons aussi utiliser la fonction mapview() de la bibliothèque mapview: library(mapview) library(leaflet) mapview(M) FIGURE 5.2: Visualisation du raster M avec la fonction mapview() Nous avons une certaine préférence pour lesthétique quoffre mapview(), nest-ce pas? Peu importe la fonction choisie, celle-ci transforme la valeur de chaque cellule en couleur. Différentes pallettes de couleur peuvent être utilisées, mais pour linstant, limitons-nous à la palette de couleur par défaut, qui est inferno de la bibliothèque viridis, inclue automatiquement dans la bibliothèque mapview. Remarquez que le premier pixel, qui porte la valeur 1 dans le cas présent, se trouve en haut à gauche. Le dernier pixel, quant à lui, se trouve dans le coin inférieur droit. Lidentité des pixels suit donc les lignes dun raster. Raster de différents types de données Les rasters peuvent prendre des valeurs de type discrètes (integer) et des nombres réelles (numeric). Ils peuvent également prendre des valeurs logiques (logical). Par exemple, remplaçons les valeurs discrètes du raster M défini plus haut par des valeurs logiques. z &lt;- 1:64 class(z) #la fonction class() renvoie le type de données de l&#39;objet z [1] &quot;integer&quot; # Créons un nombre logique qui est vrai lorsque z est un multiple de trois, et faux autrement z_mult3 &lt;- z %% 3 == 0 # La fonction modulo, s&#39;exprime par le symbole %%, # L&#39;expression x %% y vaut 0 si y est un multiple de x, # L&#39;expression x %% y vaut r si y n&#39;est pas un multiple de x. # r correspond alors au reste de la division x/y z_mult3 [1] FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE [9] TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE [17] FALSE TRUE FALSE FALSE TRUE FALSE FALSE TRUE [25] FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE [33] TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE [41] FALSE TRUE FALSE FALSE TRUE FALSE FALSE TRUE [49] FALSE FALSE TRUE FALSE FALSE TRUE FALSE FALSE [57] TRUE FALSE FALSE TRUE FALSE FALSE TRUE FALSE class(z_mult3) #vérifions que les valeurs sont bien de type logique [1] &quot;logical&quot; # utilisons le vecteur logique z_mult3 pour créer un raster logique M_logique &lt;- raster(nrows = 8, ncols = 8, xmn = 1, xmx = 5, ymn = 1, ymx = 5, vals = z_mult3) M_logique class : RasterLayer dimensions : 8, 8, 64 (nrow, ncol, ncell) resolution : 0.5, 0.5 (x, y) extent : 1, 5, 1, 5 (xmin, xmax, ymin, ymax) crs : +proj=longlat +datum=WGS84 +no_defs source : memory names : layer values : 0, 1 (min, max) Visualisons maintenant ce raster de type logique: FIGURE 5.3: Raster dont les valeurs sont de type logique Les rasters ne peuvent pas prendre des valeurs de type caractères (character) mais ils peuvent tout de même prendre des valeurs catégoriques. Petit rappel, avec R, les données catégoriques sont représentées par des données de type facteurs (factor). Plus précisément, les données catégoriques sont emmagasinées comme étant des nombres entiers auxquels sont associés des étiquettes - des identifiants uniques. Nous référons à ces identifiants comme étant des niveaux (levels). Par exemple: # Définissons un vecteur de caractères mois_hiver &lt;- c(&quot;décembre&quot;, &quot;janvier&quot;, &quot;février&quot;, &quot;mars&quot;) # Ce vecteur est bel et bien de type caractère class(mois_hiver) [1] &quot;character&quot; # Maintenant transformons ce vecteur en vecteur de type facteur mois_hiver_facteur &lt;- factor(mois_hiver) # Ce vecteur transformé est bien de type facteur class(mois_hiver_facteur) [1] &quot;factor&quot; # Ce nouveau vecteur possède 4 niveaux différents mois_hiver_facteur [1] décembre janvier février mars Levels: décembre février janvier mars # ou encore levels(mois_hiver_facteur) [1] &quot;décembre&quot; &quot;février&quot; &quot;janvier&quot; &quot;mars&quot; Revenons maintenant aux rasters. Reprenons lexemple du raster des multiples de 3. Nous allons le transformer en raster de type facteur. # Nous transformons d&#39;abord le vecteur z de nombres entiers de 1 à 64, # en vecteur de type caractère z_char &lt;- z z_char[z%%3 == 0] &lt;- &quot;Multiple de 3&quot; z_char[z%%3 != 0] &lt;- &quot;Autre&quot; class(z_char) [1] &quot;character&quot; # Transformons le vecteur z_char en vecteur de type facteur z_fact &lt;- factor(z_char) class(z_fact) [1] &quot;factor&quot; # Obtenons maintenant un raster de type facteur M_factor &lt;- raster(nrows = 8, ncols = 8, xmn = 1, xmx = 5, ymn = 1, ymx = 5, vals = z_fact) M_factor class : RasterLayer dimensions : 8, 8, 64 (nrow, ncol, ncell) resolution : 0.5, 0.5 (x, y) extent : 1, 5, 1, 5 (xmin, xmax, ymin, ymax) crs : +proj=longlat +datum=WGS84 +no_defs source : memory names : layer values : 1, 2 (min, max) attributes : ID VALUE 1 Autre 2 Multiple de 3 Visualisons maintenant ce raster de type facteur: mapview(M_factor) FIGURE 5.4: Raster dont les valeurs sont de type facteur 5.1.3 Comprendre la structure dun raster Les objets de type raster disposent dune structure dobjet particulière. Si lon veut accéder aux valeurs stockées, on doit procéder dune certaine manière. La valeur dune cellule peut être obtenue en référant à lidentifiant (indice) de son pixel; cest-à-dire un numéro entre 1 et le nombre total de cellules, ncell, dans le raster. La valeur dune cellule peut aussi être obtenue en référant à sa position (ligne, colonne) dans sa structure matricielle. Par exemple, considérons le raster G suivant, de dimensions 5 par 5, former de nombres aléatoires entre 0 et 1. class : RasterLayer dimensions : 5, 5, 25 (nrow, ncol, ncell) resolution : 0.5, 0.5 (x, y) extent : 1, 3.5, 1, 3.5 (xmin, xmax, ymin, ymax) crs : +proj=longlat +datum=WGS84 +no_defs source : memory names : layer values : 0.1, 1 (min, max) La figure suivante illustre comment les cellules sont indexées et positionnées dans un raster. La cellule supérieure gauche, de position [1,1] est toujours celle portant lindice 1. FIGURE 5.5: Structure dun raster: indice, position et valeur des pixels Ainsi, pour accéder à des valeurs spécifiques du raster, on procède de la façon suivante: # Accéder à la première valeur G[1] [1] 0.2 # Accéder à la valeur de la cellule à la position (3,2) G[3, 2] [1] NA # Accéder aux valeurs de 5 à 10 G[5:10] [1] 0.4 0.3 0.6 0.4 0.6 0.4 # Accéder à des valeurs spécifiques G[c(7, 13, 17:20)] [1] 0.6 1.0 0.6 0.4 NA 0.2 Il est souvent plus simple dutiliser lindice lorsque nous voulons accéder aux valeurs de plusieurs cellules. Par ailleurs, lutilisation de la position, est souvent plus intuitive. Notons toutefois quil peut être dangereux dextraire des valeurs en utilisant les indices des cellules. En effet, nous perdons une information précieuse: la localisation de la cellule dans lespace; cest-à-dire ses coordonnées X et Y. Cest pourquoi, il est souvent privilégié de convertir le raster en data.frame. La fonction as.data.frame(..., xy = TRUE), appliquée à un objet de classe raster, présente lavantage de retourner les coordonnées associées à lindice. G_df &lt;- as.data.frame(G, xy = TRUE) head(G_df) x y layer 1 1.25 3.25 0.2 2 1.75 3.25 0.3 3 2.25 3.25 NA 4 2.75 3.25 NA 5 3.25 3.25 0.4 6 1.25 2.75 0.3 Ainsi, en référant à lindice dune cellule, nous pouvons connaître non seulement sa valeur mais aussi sa localisation dans lespace. G_df[13, ] x y layer 13 2.25 2.25 1 Notez que par défaut, la coordonnée renvoyée par la fonction as.data.frame() correspond au coin inférieur gauche de chaque pixel. Il est cependant possible de renvoyer le centroid du pixel en utilisant largument as.data.frame(..., xy = TRUE, centroids = TRUE). FIGURE 5.6: (A) Coordonnées renvoyées par défaut par la fonction as.data.frame; (B) Coordonnées des centroïdes des pixels renvoyées lorsque largument centroids = TRUE est utilisé dans la fonction as.data.frame 5.1.4 Statistiques de base sur un raster Voyons maintenant comment calculer des statistiques de base sur les valeurs contenues dans un raster. Tout dabord, pour connaître lensemble des valeurs dun raster, nous pouvons utiliser la fonction getValues(). getValues(G) [1] 0.2 0.3 NA NA 0.4 0.3 0.6 0.4 0.6 0.4 1.0 NA [13] 1.0 0.1 0.3 0.4 0.6 0.4 NA 0.2 0.1 1.0 0.1 0.3 [25] 0.5 Cette fonction est équivalente à G[] [1] 0.2 0.3 NA NA 0.4 0.3 0.6 0.4 0.6 0.4 1.0 NA [13] 1.0 0.1 0.3 0.4 0.6 0.4 NA 0.2 0.1 1.0 0.1 0.3 [25] 0.5 Nous pouvons alors calculer des statistiques élémentaires sur ces valeurs. Par exemple, quelle est la valeur maximale du raster G? max(getValues(G), na.rm = TRUE) [1] 1 Noter que nous devons préciser que les valeurs NA ne soient pas prises en considération lors du calcul de statistiques. En effet, na.rm = TRUE signifie que les valeurs NA sont retirées (remove en anglais, abrégé par rm). Plus simplement, nous pouvons utiliser la fonction équivalente maxValue exclusive aux données de classe raster. maxValue(G) [1] 1 De la même façon, nous pouvons obtenir dautres statistiques élémentaires: minValue(G) [1] 0.1 min(getValues(G), na.rm = TRUE) [1] 0.1 mean(getValues(G), na.rm = TRUE) [1] 0.4381 median(getValues(G), na.rm = TRUE) [1] 0.4 quantile(getValues(G), na.rm = TRUE) 0% 25% 50% 75% 100% 0.1 0.3 0.4 0.6 1.0 La fonction summary() permet dobtenir plusieurs statistiques: summary(G) layer Min. 0.1 1st Qu. 0.3 Median 0.4 3rd Qu. 0.6 Max. 1.0 NA&#39;s 4.0 En plus du minimum, du maximum, et de la médiane, la fonction summary() retourne le premier et le troisième quantile, ainsi que le nombre de cellules de valeur NA contenu dans le raster. La fonction cellStats permet également dobtenir des statistiques sur les rasters. La statistique désirée doit être précisée dans les options de la fonction cellStats. Par exemple: cellStats(G, mean, na.rm = TRUE) [1] 0.4381 cellStats(G, sd, na.rm = TRUE) #la déviation standard [1] 0.2801 cellStats(G, max, na.rm = TRUE) [1] 1 cellStats(G, min, na.rm = TRUE) [1] 0.1 cellStats(G, median, na.rm = TRUE) [1] 0.4 cellStats(G, quantile, na.rm = TRUE) 0% 25% 50% 75% 100% 0.1 0.3 0.4 0.6 1.0 cellStats(G, range, na.rm = TRUE) #le minimum et le maximum [1] 0.1 1.0 cellStats(G, sum, na.rm = TRUE) [1] 9.2 Nous pouvons également visualiser la distribution des valeurs contenues dans un raster en utilisant les fonctions R usuelles telles que hist() ou boxplot. Par exemple, hist(G, main = &quot;&quot;, xlab = &quot;Valeurs&quot;, ylab = &quot;Fréquence&quot;, col = &quot;darkorange&quot;) FIGURE 5.7: Histogramme de la distribution des valeurs dans le raster G Ou encore, boxplot(G, main = &quot;&quot;, ylab = &quot;Valeurs&quot;, col = &quot;darkorange&quot;) FIGURE 5.8: Valeur moyenne et intervalle de confiance du raster G 5.1.5 Lire un raster et explorer son contenu Dans les sections précédentes, nous avons créé et manipulé des rasters très simples et peu volumineux. Dans cette section, nous manipulerons un raster plus substantiel, constitué de données réelles sur les îlots de chaleur urbains. Les îlots de chaleur urbains (ICU) sont des zones urbaines où les températures sont plus chaudes que dans la région rurale voisine (Santé Canada 2020). Les ICU amplifient les effets négatifs sur la santé humaine pendant les vagues de chaleur. Les ICU se produisent surtout dans les zones où les humains ont fortement altéré le couvert du sol, par exemple pour y aménager des infrastructures en béton (bâtiments, stationnement, route, etc.). Labsence de végétation, la présence de surfaces imperméables et non-réfléchissantes contribuent à la formation dICU (Santé Canada 2020). La température de surface mesurée sur les territoires urbains permet didentifier la présence dîlots de chaleur33. Les données sur les ICU pour lensemble du territoire québécois sont disponibles sur le site gouvernemental Données Québec en format GeoTIFF. Puisque cette base de données spatiales est particulièrement volumineuse, nous allons travailler seulement avec les données matricielles relatives à la région de la ville de Québec. Lire les données Nous allons maintenant lire les données matricielles en utilisant la fonction raster() de la bibliothèque raster. T_vdq &lt;- raster(&quot;Module5/Module5_donnees/Temp_vdq.tif&quot;) Nous pouvons demblée reconnaître les informations relatives à la dimension, la résolution, létendue, le CRS, et aux valeurs minimale et maximale du raster T_vdq. Nous pouvons également utiliser les fonctions dim(), ncell(), res(), extent(), crs(), et cellStats(, range) pour retrouver ces informations: dim(T_vdq) [1] 857 860 1 ncell(T_vdq) [1] 737020 res(T_vdq) [1] 40 40 extent(T_vdq) class : Extent xmin : -230083 xmax : -195683 ymin : 300611 ymax : 334891 cellStats(T_vdq, range) [1] 1 9 crs(T_vdq) Coordinate Reference System: Deprecated Proj.4 representation: +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=46 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs WKT2 2019 representation: PROJCRS[&quot;unknown&quot;, BASEGEOGCRS[&quot;unknown&quot;, DATUM[&quot;North American Datum 1983&quot;, ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101, LENGTHUNIT[&quot;metre&quot;,1]], ID[&quot;EPSG&quot;,6269]], PRIMEM[&quot;Greenwich&quot;,0, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8901]]], CONVERSION[&quot;unknown&quot;, METHOD[&quot;Lambert Conic Conformal (2SP)&quot;, ID[&quot;EPSG&quot;,9802]], PARAMETER[&quot;Latitude of false origin&quot;,44, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8821]], PARAMETER[&quot;Longitude of false origin&quot;,-68.5, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8822]], PARAMETER[&quot;Latitude of 1st standard parallel&quot;,46, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8823]], PARAMETER[&quot;Latitude of 2nd standard parallel&quot;,60, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8824]], PARAMETER[&quot;Easting at false origin&quot;,0, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8826]], PARAMETER[&quot;Northing at false origin&quot;,0, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8827]]], CS[Cartesian,2], AXIS[&quot;(E)&quot;,east, ORDER[1], LENGTHUNIT[&quot;metre&quot;,1, ID[&quot;EPSG&quot;,9001]]], AXIS[&quot;(N)&quot;,north, ORDER[2], LENGTHUNIT[&quot;metre&quot;,1, ID[&quot;EPSG&quot;,9001]]]] Le nom de la couche de données matricielles contenue dans ce raster, cest-à-dire son attribut, est obtenu en utilisant la fonction names(). names(T_vdq) [1] &quot;Temp_vdq&quot; Nous pouvons changer ce nom pour un nouveau: names(T_vdq) &lt;- &quot;ICU&quot; T_vdq class : RasterLayer dimensions : 857, 860, 737020 (nrow, ncol, ncell) resolution : 40, 40 (x, y) extent : -230083, -195683, 300611, 334891 (xmin, xmax, ymin, ymax) crs : +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=46 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs source : Temp_vdq.tif names : ICU values : 1, 9 (min, max) Explorer les statistiques de base Utilisons la fonction summary() pour déterminer les statistiques de base du raster T_vdq: summary(T_vdq) Warning in .local(object, ...): summary is an estimate based on a sample of 1e+05 cells (13.57% of all cells) ICU Min. 1.00 1st Qu. 2.00 Median 3.75 3rd Qu. 6.25 Max. 9.00 NA&#39;s 310116.00 Remarquez le message retourné par R: summary is an estimate based on a sample of 1e+05 cells (3.39% of all cells). Ce message nous prévient que, par défaut, les calculs de la fonction summary() sont réalisés sur un échantillon de 100 000 cellules choisies aléatoirement. Dans le cas présent, puisque le raster T_vdq contient ncells(T_vdq) = 2946366 cellules, un échantillon de 100 000 cellules correspond donc seulement à 3.39% de toutes les cellules. La limite par défaut du nombre de cellules sélectionnées pour calculer les statistiques dans la fonction summary() est très utile pour obtenir des résultats rapides, surtout lorsque raster est volumineux. Cependant, dans certains cas, cet échantillonnage limité pourrait mener à un estimé trompeur. Ainsi, il est toujours possible de spécifier la taille désirée de léchantillon en utilisant loption maxsamp. Par exemple, summary(T_vdq, maxsamp = ncell(T_vdq)) ICU Min. 1.00 1st Qu. 2.00 Median 3.75 3rd Qu. 6.25 Max. 9.00 NA&#39;s 311157.00 Vous remarquerez que lexécution de la fonction summary() peut prendre plus de temps lorsque le nombre de cellules échantillonnées est plus grand. Dans le cas présent du raster T_vdq, les statistiques demeurent inchangées mais le nombre de valeurs NA a été corrigées. Nous pouvons également visualiser lhistogramme des valeurs de température de surface. hist(getValues(T_vdq), breaks = 10, main = &quot;&quot;, xlab = &quot;Valeurs&quot;, ylab = &quot;Fréquence&quot;, col = &quot;darkorange&quot;) FIGURE 5.9: Distribution des températures de surface dans la ville de Québec Remarquez que nous avons spécifié que la distribution soit calculée sur lensemble des valeurs contenues dans le raster T_vdq en utilisant la fonction getValues(). Autrement, la fonction hist() appliquée à un raster utilise un échantillonnage aléatoire de 100 000 cellules, similairement à la fonction summary(). 5.1.6 Visualiser les données matricielles avec mapview() Nous allons visualiser la carte des températures de surface de la région de la ville de Québec en utilisant la fonction mapview(). Afin de situer plus facilement la région illustrée sur le territoire du Québec, nous allons demander dajouter la carte dOpenStreetMap34 comme carte de fonds. mapview(T_vdq, map.types = &quot;OpenStreetMap&quot;, legend = TRUE, layer.name = &#39;ICU&#39;) FIGURE 5.10: Carte de la température de surface dans la ville de Québec Léchelle de la légende indique des niveaux de température. Le niveau 1 correspond aux températures les plus fraîches, et le niveau 9 aux température les plus chaudes. Vous remarquerez que la résolution de cette carte nest pas parfaite. En effet, par défaut, la fonction mapview() appliquée à un raster utilise 500 000 pixels. Pour que lensemble des pixels soient pris en compte, nous devons le préciser en définissant loption maxpixels. mapview(T_vdq, maxpixels = ncell(T_vdq), map.types = &quot;OpenStreetMap&quot;, legend = TRUE, layer.name = &#39;ICU&#39;) FIGURE 5.11: Carte de la température de surface dans la ville de Québec (visualisation de tous les pixels) Naturellement, le temps nécessaire pour générer la carte est alors plus long. Visualiser une section dun raster Nous voulons maintenant nous concentrer sur une petite section de la carte de la région de la ville de Québec. Nous pouvons le faire en spécifiant les lignes et les colonnes qui nous intéressent dans le raster. Par exemple, choisissons une région carrée de 100 x 100 cellules dans le quartier Sainte-Foy. T_sec &lt;- T_vdq[351:450, 351:450, drop = FALSE] mapview(T_sec, map.types = &quot;OpenStreetMap&quot;) FIGURE 5.12: Carte de la température de surface dans le secteur de Sainte-Foy Notez que loption drop = FALSE est importante car elle permet au nouvel objet T de demeurer un raster comme T_vdq. Autrement, T deviendrait un simple vecteur. Nous observons sur la carte que les températures les plus chaudes (pixels de couleur jaune) sont situées sur les grandes infrastructures bétonnées comme les axes routiers ainsi que les bâtiments et les stationnements (par exemple ceux de la Place Laurier et Sainte-Foy). Dautre part, les températures les plus fraîches (pixels de couleur mauve foncé) sont situés sur des zones boisées comme celles sur le campus de lUniversité Laval. 5.1.7 Changer la résolution dun raster Il est possible daugmenter la résolution dun raster. Cela peut savérer utile lorsque la résolution de ce dernier est trop petite (cest-à-dire que la résolution est fine) pour exécuter rapidement des calculs sur celui-ci. Aussi, cela peut savérer utile lorsque nous devons travailler avec des rasters de résolution différente, il peut alors être nécessaire que tous les rasters aient la même résolution. Pour augmenter la résolution dun raster nous utilisons la fonction aggregate(). Nous devons alors spécifier le facteur, fact, par lequel nous voulons augmenter la résolution. Par exemple, fact = 4 augmentera la résolution par un facteur de \\(4 * 4\\). Cest-à-dire quune cellule de taille \\(x * y\\) aura, dans le nouveau raster, une taille \\(4x * 4y\\). Elle aura donc une taille 16 fois plus grande que dans le raster initial. Quelle valeur prendra alors une cellule de plus grande résolution? Par défaut, la cellule aura comme valeur la moyenne des valeurs des cellules groupées par lagrégation. Par ailleurs, il est aussi possible de specifier dautres fonctions pour calculer la valeur des cellules de plus grande résolution en utilisant loption fun. Par exemple, nous pourrions choisir que la valeur agrégée corresponde à la valeur maximum des valeurs des cellules groupées. T_fact4_moy &lt;- aggregate(T_sec, fact = 4) T_fact4_max &lt;- aggregate(T_sec, fact = 4, fun = &#39;max&#39;) T_fact8_moy &lt;- aggregate(T_sec, fact = 8) T_fact8_max &lt;- aggregate(T_sec, fact = 8, fun = &#39;max&#39;) mapviewOptions(basemaps = &quot;OpenStreetMap&quot;) map_fact4_moy &lt;- mapview(T_fact4_moy, legend = FALSE, homebutton = FALSE) map_fact4_max &lt;- mapview(T_fact4_max, legend = FALSE, homebutton = FALSE) map_fact8_moy &lt;- mapview(T_fact8_moy, legend = FALSE, homebutton = FALSE) map_fact8_max &lt;- mapview(T_fact8_max, legend = FALSE, homebutton = FALSE) leafsync::latticeView(map_fact4_moy, map_fact4_max, map_fact8_moy, map_fact8_max, ncol = 2) Remarquez que nous avons utilisé la fonction latticeView() pour visualiser ces quatre cartes sur deux colonnes. 5.1.8 Changer la projection dun raster Comme pour les données vectorielles, il est possible de manipuler le système de coordonnées de référence de données matricielles. Rappelons que pour connaître le SCR dun raster il sagit dutiliser la fonction crs() de la bibliothèque raster. crs(T_vdq) Coordinate Reference System: Deprecated Proj.4 representation: +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=46 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs WKT2 2019 representation: PROJCRS[&quot;unknown&quot;, BASEGEOGCRS[&quot;unknown&quot;, DATUM[&quot;North American Datum 1983&quot;, ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101, LENGTHUNIT[&quot;metre&quot;,1]], ID[&quot;EPSG&quot;,6269]], PRIMEM[&quot;Greenwich&quot;,0, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8901]]], CONVERSION[&quot;unknown&quot;, METHOD[&quot;Lambert Conic Conformal (2SP)&quot;, ID[&quot;EPSG&quot;,9802]], PARAMETER[&quot;Latitude of false origin&quot;,44, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8821]], PARAMETER[&quot;Longitude of false origin&quot;,-68.5, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8822]], PARAMETER[&quot;Latitude of 1st standard parallel&quot;,46, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8823]], PARAMETER[&quot;Latitude of 2nd standard parallel&quot;,60, ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ID[&quot;EPSG&quot;,8824]], PARAMETER[&quot;Easting at false origin&quot;,0, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8826]], PARAMETER[&quot;Northing at false origin&quot;,0, LENGTHUNIT[&quot;metre&quot;,1], ID[&quot;EPSG&quot;,8827]]], CS[Cartesian,2], AXIS[&quot;(E)&quot;,east, ORDER[1], LENGTHUNIT[&quot;metre&quot;,1, ID[&quot;EPSG&quot;,9001]]], AXIS[&quot;(N)&quot;,north, ORDER[2], LENGTHUNIT[&quot;metre&quot;,1, ID[&quot;EPSG&quot;,9001]]]] Nous pouvons également utiliser la fonction st_crs() de la bibliothèque sf sur un raster. Cela nous permet dobtenir, entre autres, le SCR selon la syntaxe PROJ4. library(sf) st_crs(T_vdq)$proj4string [1] &quot;+proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=46 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; Rappelons que les arguments de la notation PROJ4 ont la signification suivante: +proj : le nom de la projection +lat_0 : la latitude de lorigine +lon_0 : la longitude du méridien central +lat_1 : la latitude du premier parallèle standard35 +lat_2 : la latitude du deuxième parallèle standard +x_0 : le faux est (false easting; dans le cas de projection transverse comme UTM) +y_0 : le faux nord (false northing) +datum : le nom du datum +units : les unités (mètres, pieds, etc.) Nous remarquons que les données matricielles sur les îlots de chaleur de la ville de Québec sont dans la projection conique conforme de Lambert (+proj=lcc). Cette dernière est appropriée pour représenter des données à léchelle de la province. Celle-ci est basée sur le datum NAD83 qui être très proche du datum WGS84. Retournez voir le Module 2 pour un rappel des systèmes de coordonnées de référence! Nous voulons maintenant transformer le système de coordonnées de référence du raster T_vdq vers le système MTM, cest-à-dire la projection Mercator transverse modifiée. Celle-ci est basée aussi sur le datum NAD83. Dans le système MTM, la ville de Québec ce situe dans le fuseau 7. Pour savoir comment définir cette projection, cest-à-dire quels paramètres utilisés, vous pouvez vous rendre sur le site web spatialreference.org. Dans la fenêtre de recherche Search tapez MTM zone 7. Une liste de de code EPSG apparaîtra. Sélectionnez le code EPSG:2949: NAD83(CSRS) / MTM zone 7. Le carré gris qui apparaît propose différents formats possibles pour définir une projection. Choisissez Proj4. La liste des paramètres qui définissent la projection MTM pour le fuseau 7 est alors donnée. Vous pouvez donc copier cette définition, et lutiliser pour définir la nouvelle projection. proj_mtm7 &lt;- &quot;+proj=tmerc +lat_0=0 +lon_0=-70.5 +k=0.9999 +x_0=304800 +y_0=0 +ellps=GRS80 +units=m +no_defs&quot; Pour transformer la projection dun raster, nous devons utiliser la fonction projectRaster() de la bibliothèque Raster. T_mtm7 &lt;- projectRaster(T_vdq, crs = proj_mtm7) Comparons les deux cartes utilisant des projections différentes: par(mfrow = c(1,2)) plot(T_vdq, main = &quot;Québec Lambert&quot;, legend = FALSE) plot(T_mtm7, main = &quot;MTM fuseau 7&quot;) FIGURE 5.13: Rasters de projections Québec Lambert et MTM Il est difficile de percevoir une différence, car celle-ci est légère. Pour sen convaincre, visualisons une plus petite section de la carte de la ville de Québec: FIGURE 5.14: Section des rasters de projections Québec Lambert et MTM Remarquez que la carte de droite, utilisant la projection MTM, est, en effet, inclinée par rapport à la carte utilisant la projection Québec Lambert. Remarquez aussi que les coordonnées des axes x et y sont différentes. De plus, vous aurez sans doute remarqué que nous avons utilisé la fonction plot() et non mapview() pour afficher ces cartes. En effet, au moment décrire ces lignes, la fonction mapview() ne permet pas dafficher des données matricielles dans leur CRS dorigine. Les données matricielles sont automatiquement transformées selon la projection Web de Mercator au moment de la visualisation, si bien quil est impossible de percevoir les différences provenant de projections différentes. Ce problème nexiste pas pour les données vectorielles pour lesquelles nous pouvons utiliser loption crs.native = TRUE. Pour sélectionner une région précise dans un raster, nous avons utilisé la fonction crop(). Nous reviendrons en détails sur cette fonction dans le module 8 qui traite de la manipulation de données matricielles. 5.1.9 Sauvegarder un raster Finalement, pour sauvegarder des données matricielles, nous utilisons la fonction writeRaster() de la bibliothèque raster. Par exemple, sauvons les données matricielles T_vdq que nous avons transformées dans le système de projection MTM. nom_du_fichier&lt;- &quot;Module5/Module5_donnees/ICU_vdq_MTM7.tif&quot; writeRaster(T_mtm7,nom_du_fichier) 5.1.10 Lire et visualiser des données matricielles multi-bande Les données matricielles peuvent contenir plusieurs couches, appelées aussi des bandes ou des canaux. Cest le cas des images de couleurs qui contiennent souvent trois bandes: une bande de rouge, une bande de vert et une bande de bleu. Dans cette section, nous apprendrons à lire et visualiser ce type de raster en utilisant des données satellitaires. Le gouvernement québécois abrite sur son site Données Québec les données satellites, captées par Sentinel-2 et Landsat, couvrant lensemble de la province. Nous parlons alors dune mosaïque dimages. Sentinel-2 est une mission dobservation de la Terre de lAgence spatiale européenne, tandis que Landsat est une mission développée par lAgence spatiale américaine. Pour en apprendre davantage sur ces programmes dobservation et sur les satellites utilisés, consultez les sites de Sentinel-2 et de Landsat ou encore les sites respectifs de Wikipédia (Sentinel-2 et Landsat). La résolution des images captées par Sentinel-2 est de 10 m par 10 m, et celle de Landsat est de 30 m par 30 m. Ces images permettent ainsi didentifier la couverture du sol avec beaucoup de précisions. On les utilise alors pour décrire comment les milieux forestiers, agricoles, humides et anthropisés sont distribués sur le territoire et comment ils évoluent dans le temps. Ces images sont utilisées lors de la planification et laménagement du territoire et de ses ressources. Lire des données multi-bande Nous allons maintenant lire le fichier Landsat_LaTuque.tif qui correspond aux données satellitaires captées par Landsat sur une section du territoire de la Haute Mauricie, près de la ville de La Tuque. Pour ce faire, nous utilisons la fonction raster() de la bibliothèque `raster: S &lt;- raster(&quot;Module5/Module5_donnees/Landsat_LaTuque.tif&quot;) S class : RasterLayer band : 1 (of 3 bands) dimensions : 251, 251, 63001 (nrow, ncol, ncell) resolution : 60, 60 (x, y) extent : -483210, -468150, 462630, 477690 (xmin, xmax, ymin, ymax) crs : +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs source : Landsat_LaTuque.tif names : layer values : 0, 254.8 (min, max) Nous remarquons quune information supplémentaire est apparue dans le description du raster. Il sagit de band : 1 (of 3 bands). Cette information nous précise que nous venons de lire une seule bande alors que ces données matricielles en contiennent trois. Lorsque nous rencontrons un raster de plusieurs bandes, il faut plutôt utiliser la fonction brick() ou la fonction stack() de la bibliothèque raster pour lire lensemble des bandes. S_mult &lt;- brick(&quot;Module5/Module5_donnees/Landsat_LaTuque.tif&quot;) Remarquez que la classe de lobjet S_mult est RasterBrick et non pas simplement Raster comme lobjet S précédent. De plus, dimensions spécifie maintenant que S_mult contient trois couches (nlayers). Le nom de chaque couche est également donné: Landsat_LaTuque.1, Landsat_LaTuque.2 et Landsat_LaTuque.3. Finalement, les valeurs minimum (0) et maximum (255) sont données pour chacune des trois couches. Nous pouvons sélectionner chacune des bandes à partir du raster multi-bande de la façon suivante: SR &lt;- S_mult$Landsat_LaTuque_1 SG &lt;- S_mult$Landsat_LaTuque_2 SB &lt;- S_mult$Landsat_LaTuque_3 Par ailleurs, nous pouvons également lire chacune des bandes individuellement avec la fonction raster(): nom_fichier &lt;- &quot;Module5/Module5_donnees/Landsat_LaTuque.tif&quot; SR &lt;- raster(nom_fichier, band = 1) #lecture de la bande rouge SG &lt;- raster(nom_fichier, band = 2) #lecture de la bande verte (green) SB &lt;- raster(nom_fichier, band = 3) #lecture de la bande bleu SR class : RasterLayer band : 1 (of 3 bands) dimensions : 251, 251, 63001 (nrow, ncol, ncell) resolution : 60, 60 (x, y) extent : -483210, -468150, 462630, 477690 (xmin, xmax, ymin, ymax) crs : +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs source : Landsat_LaTuque.tif names : layer values : 0, 254.8 (min, max) SG class : RasterLayer band : 2 (of 3 bands) dimensions : 251, 251, 63001 (nrow, ncol, ncell) resolution : 60, 60 (x, y) extent : -483210, -468150, 462630, 477690 (xmin, xmax, ymin, ymax) crs : +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs source : Landsat_LaTuque.tif names : layer values : 2, 255 (min, max) SB class : RasterLayer band : 3 (of 3 bands) dimensions : 251, 251, 63001 (nrow, ncol, ncell) resolution : 60, 60 (x, y) extent : -483210, -468150, 462630, 477690 (xmin, xmax, ymin, ymax) crs : +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs source : Landsat_LaTuque.tif names : layer values : 0, 254.8 (min, max) Ainsi, SR correspond à la première bande (la rouge), SG à la deuxième bande (la verte), et SB à la troisième bande (la bleu). Chaque raster comprend des valeurs entre 0 et 255. Ces valeurs correspondent au format RGB, et ensemble ces trois couches permettent de visualiser des images couleurs. RasterBrick et RasterStack Un RasterBrick correspond généralement a différentes bandes spectrales stockées dans un seul objet ou un seul fichier dans la mémoire de votre ordinateur. Dautre part, un RasterStack quon obtient par lutilisation de la fonction stack() permet de combiner des couches provenant de fichiers différents ou dobjets logés à différents endroits de la mémoire de votre ordinateur. Une condition essentielle pour combiner des couches dans un RasterStack est que celles-ci possèdent la même étendue, la même résolution, et le même SCR. Démontrons en quoi consiste unRasterStack par un exemple. Définissons deux couches provenant dobjets différents que nous combinerons par lutilisation de la fonction stack(). Dabord, utilisons la fonction raster() pour créer un raster qui possède la même géométrie que les couches du raster S_mult. raster_1 &lt;- raster(res = res(SR), ext = extent(SR), crs = crs(SR)) Attribuons des values aux pixels de raster_1. Par exemple, values(raster_1) = 1:ncell(SR) Ici, chaque pixel a comme valeur le numéro de son indice dans la matrice. Ensuite, définissons un deuxième couche correspondant à une bande du raster S_mult: raster_2 &lt;- SR Remarquez que la source de chaque couche ainsi créée diffère: raster_1 class : RasterLayer dimensions : 251, 251, 63001 (nrow, ncol, ncell) resolution : 60, 60 (x, y) extent : -483210, -468150, 462630, 477690 (xmin, xmax, ymin, ymax) crs : +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs source : memory names : layer values : 1, 63001 (min, max) raster_2 class : RasterLayer band : 1 (of 3 bands) dimensions : 251, 251, 63001 (nrow, ncol, ncell) resolution : 60, 60 (x, y) extent : -483210, -468150, 462630, 477690 (xmin, xmax, ymin, ymax) crs : +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs source : Landsat_LaTuque.tif names : layer values : 0, 254.8 (min, max) Maintenant, combinons ces deux couches pour former un RasterStack en utilisant la fonction stack(): R_stack &lt;- stack(raster_1, raster_2) R_stack class : RasterStack dimensions : 251, 251, 63001, 2 (nrow, ncol, ncell, nlayers) resolution : 60, 60 (x, y) extent : -483210, -468150, 462630, 477690 (xmin, xmax, ymin, ymax) crs : +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +ellps=GRS80 +units=m +no_defs names : layer.1, layer.2 min values : 1, 0 max values : 63001.0, 254.8 Nous avons ainsi créé un raster de classe RasterStack. Visualiser un raster multi-bande Visualisons individuellement les bandes dun raster multi-bande en utilisant la fonction mapview() de la bibliothèque mapview. # Définissons une palette de gris de 256 tons différents mapviewOptions(raster.palette = gray.colors(256)) # Créons une carte pour chaque bande Map_SR &lt;- mapview(SR, homebutton = FALSE) Map_SG &lt;- mapview(SG, homebutton = FALSE) Map_SB &lt;- mapview(SB, homebutton = FALSE) # Visualisons les trois cartes côte à côte leafsync::latticeView(Map_SR, Map_SG, Map_SB, ncol = 3) Nous pouvons également visualiser les trois bandes ensemble en utilisant la fonction viewRGB() de la librarie mapview. Cette fonction sapplique au raster multibande, et demande quon spécifie quelle couche du raster est associée à chacune des couleurs rouge, vert et bleu. viewRGB(S_mult, r = 1, g = 2, b = 3) Les diverses teintes observées sur limage Landsat peuvent être interprétées pour déduire le type de végétation ou dutilisation du sol présents. Par exemple, les teintes de vert varient selon lâge dun peuplement forestier, sa densité, et sil est composé de feuillus ou de conifères. Les teintes roses, brunes ou bourgognes sont associées à des perturbations, comme des épidémies dinsecte ou des feux de forêt. Ici, les pixels roses signalent la présence de coupes forestières36. Finalement, pour sauvegarder un raster multi-bande, nous pouvons encore utiliser la fonction writeRaster() de la bibliothèque raster. writeRaster(S_mult, &quot;Module5/Module5_donnees/LaTuque-copie.tif&quot;) Si vous désirez comprendre la méthodologie utilisée pour déterminer la température de surface à partir dimages satellitaires, consulter cette note technique produite par le Centre denseignement et de recherche en foresterie de Sainte-Foy inc. OpenStreetMap est un outil collaboratif et libre daccès de cartographie en ligne. Souvenez-vous que pour une projection cylindrique ou conique, le plan intersecte le globe le long dun ou de deux parallèles. Voir la leçon 2 Pour plus dinformations sur linterprétation des images Landsat, consultez ce guide produit par le Ministère des Forêts, de la Faune et des Parcs du Québec (Direction des inventaires forestiers 2015). "],["ex_mat.html", "5.2 Exercices", " 5.2 Exercices Dans cette section, vous mettrez en pratique certains concepts vus dans la section leçon de ce module et apprendrez à manipuler des données matricielles catégoriques. Bien que la réponse à chaque question soit disponible, il est très important de tenter dy répondre par vous même! Les questions qui suivent se rapportent à des données matricielles de couvertures terrestres dune petite région du Colorado aux États-Unis. Ce sont les données utilisées dans le tutoriel de Nikki Inglis et qui proviennent du National Land Cover Database des États-Unis37. Nous allons également utiliser la bibliothèque FedData qui permet dextraire certaines données en provenance de sources fédérales américaines. Installer cette bibliothèque avant de débuter les questions: install.packages(&quot;FedData&quot;) Question 1 a) Lire les rasters Couvert_2001.tif et Couvert_2016.tif correspondant aux couvertures terrestres lors des années 2001 et 2016 respectivement. Réponse library(raster) C2001 &lt;- raster(&quot;Module5/Module5_donnees/Couvert_2001.tif&quot;) C2016 &lt;- raster(&quot;Module5/Module5_donnees/Couvert_2016.tif&quot;) b) Trouver létendue, les dimensions, et la résolution du raster associé à lannée 2001. Réponse extent(C2001) class : Extent xmin : 304442 xmax : 355642 ymin : 4449594 ymax : 4515069 dim(C2001) [1] 2212 1701 1 res(C2001) [1] 30.1 29.6 c) En utilisant la fonction st_crs() de la library sf, déterminer le code EPSG du système de coordonnées utilisé ainsi que lunité de mesure de la projection du raster de la couverture terrestre de 2001. Réponse library(sf) st_crs(C2001)$epsg st_crs(C2001)$units [1] NA [1] &quot;m&quot; d) Confirmer que létendue, la résolution et le système de coordonnées sont les mêmes pour les rasters des années 2001 et 2016. Réponse extent(C2001) == extent(C2016) [1] TRUE res(C2001) == res(C2016) [1] TRUE TRUE st_crs(C2001) == st_crs(C2016) [1] TRUE Question 2 a) Créer deux rasters, R2001 et R2016, en sélectionnant une région carrée de 500 x 500 cellules à lintérieure des deux rasters de couverture terrestre initiaux. Réponse Rappelons que les dimensions des rasters initiaux, C2001 et C2016, sont 2212 par 1701 cellules. Sélectionnons une région carrée qui soit relativement centrale pour éviter les bordures. R2001 &lt;- C2001[1000:1499, 700:1199, drop=FALSE] R2016 &lt;- C2016[1000:1499, 700:1199, drop=FALSE] b) Utiliser la fonction getValues() pour trouver les valeurs comprises dans le raster R2001, et déterminer la classe de ces valeurs. Réponse val &lt;- getValues(R2001) class(val) [1] &quot;numeric&quot; c) Puisque les rasters R2001 et R0016 représentent une couverture terrestre, les valeurs ne devraient pas être numériques mais plutôt catégoriques. Transformer les rasters en facteur en utilisant la fonction as.factor(). Réponse R2001f &lt;- as.factor(R2001) R2016f &lt;- as.factor(R2016) d) Déterminer lidentifiant des catégories de couverture terrestre. Combien de catégories différentes exitent-ils? Réponse Les niveaux sont donnés par la fonction levels() levels(R2001f) [[1]] ID 1 11 2 21 3 22 4 23 5 24 6 41 7 42 8 43 9 52 10 71 11 81 12 82 13 90 14 95 Leur nombre est de: dim(levels(R2001f)[[1]])[1] [1] 14 Question 3 Pour connaître à quel type de couverts ces catégories correspondent, allons charger la légende disponible dans la bibliothèque FedData, en utilisant la fonction pal_nlcd(). library(FedData) legende &lt;- pal_nlcd() legende # A tibble: 20 x 4 ID Class Color Description &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; 1 11 Open Water #547~ Areas of o~ 2 12 Perennial Ice/Snow #FFF~ Areas char~ 3 21 Developed, Open Space #E8D~ Areas with~ 4 22 Developed, Low Intensity #E29~ Areas with~ 5 23 Developed, Medium Intensity #ff0~ Areas with~ 6 24 Developed High Intensity #B50~ Highly dev~ 7 31 Barren Land (Rock/Sand/Clay) #D2C~ Areas of b~ 8 41 Deciduous Forest #85C~ Areas domi~ 9 42 Evergreen Forest #388~ Areas domi~ 10 43 Mixed Forest #D4E~ Areas domi~ 11 51 Dwarf Scrub #AF9~ Alaska onl~ 12 52 Shrub/Scrub #DCC~ Areas domi~ 13 71 Grassland/Herbaceous #FDE~ Areas domi~ 14 72 Sedge/Herbaceous #D1D~ Alaska onl~ 15 73 Lichens #A3C~ Alaska onl~ 16 74 Moss #82B~ Alaska onl~ 17 81 Pasture/Hay #FBF~ Areas of g~ 18 82 Cultivated Crops #CA9~ Areas used~ 19 90 Woody Wetlands #C8E~ Areas wher~ 20 95 Emergent Herbaceous Wetlands #64B~ Areas wher~ Remarquer que les attributs de ce data.frame: ID: correspond à lidentifiant de chaque type de couvert; Description: donne une description du type de couvert; Class: correspond à la classe du type de couvert. Par exemple, tous les couverts de forêt (Deciduous Forest, Evergreen Forest, Mixed Forest) sont de classe forest; Color: correspond aux couleurs (en format hexadécimal) à utiliser pour représenter les types de couvert. La quantité de couverts différents répertoriés dans cette légende est: dim(legende)[1] [1] 20 Nous remarquons que le nombre de catégories dans la légende est supérieur au nombre de catégories dans le raster catégorique R2001f. Créons un tableau sommaire qui reprend les éléments de legende en conservant seulement les types de couverts présents dans le raster R2001f: type2001 &lt;- unique(R2001f) sommaire &lt;- legende[legende$ID %in% type2001, ] sommaire # A tibble: 14 x 4 ID Class Color Description &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; 1 11 Open Water #547~ Areas of o~ 2 21 Developed, Open Space #E8D~ Areas with~ 3 22 Developed, Low Intensity #E29~ Areas with~ 4 23 Developed, Medium Intensity #ff0~ Areas with~ 5 24 Developed High Intensity #B50~ Highly dev~ 6 41 Deciduous Forest #85C~ Areas domi~ 7 42 Evergreen Forest #388~ Areas domi~ 8 43 Mixed Forest #D4E~ Areas domi~ 9 52 Shrub/Scrub #DCC~ Areas domi~ 10 71 Grassland/Herbaceous #FDE~ Areas domi~ 11 81 Pasture/Hay #FBF~ Areas of g~ 12 82 Cultivated Crops #CA9~ Areas used~ 13 90 Woody Wetlands #C8E~ Areas wher~ 14 95 Emergent Herbaceous Wetlands #64B~ Areas wher~ À partir du nouveau data.frame sommaire, nous allons maintenant créer un data.frame appelé rat qui permettra dattacher ces attributs au raster R2001f. La première colonne dun data.frame rat doit toujours se nommer ID et lister les identifiants des différentes catégories présentes dans le raster. # Premiere colonne de rat rat &lt;- levels(R2001f)[[1]] Nous ajoutons les autres attributs au data.frame rat rat$classe &lt;- sommaire$Class rat$description &lt;- sommaire$Description rat ID classe 1 11 Open Water 2 21 Developed, Open Space 3 22 Developed, Low Intensity 4 23 Developed, Medium Intensity 5 24 Developed High Intensity 6 41 Deciduous Forest 7 42 Evergreen Forest 8 43 Mixed Forest 9 52 Shrub/Scrub 10 71 Grassland/Herbaceous 11 81 Pasture/Hay 12 82 Cultivated Crops 13 90 Woody Wetlands 14 95 Emergent Herbaceous Wetlands description 1 Areas of open water, generally with less than 25% cover of vegetation or soil. 2 Areas with a mixture of some constructed materials, but mostly vegetation in the form of lawn grasses. Impervious surfaces account for less than 20% of total cover. These areas most commonly include large-lot single-family housing units, parks, golf courses, and vegetation planted in developed settings for recreation, erosion control, or aesthetic purposes. 3 Areas with a mixture of constructed materials and vegetation. Impervious surfaces account for 20% to 49% percent of total cover. These areas most commonly include single-family housing units. 4 Areas with a mixture of constructed materials and vegetation. Impervious surfaces account for 50% to 79% of the total cover. These areas most commonly include single-family housing units. 5 Highly developed areas where people reside or work in high numbers. Examples include apartment complexes, row houses and commercial/industrial. Impervious surfaces account for 80% to 100% of the total cover. 6 Areas dominated by trees generally greater than 5 meters tall, and greater than 20% of total vegetation cover. More than 75% of the tree species shed foliage simultaneously in response to seasonal change. 7 Areas dominated by trees generally greater than 5 meters tall, and greater than 20% of total vegetation cover. More than 75% of the tree species maintain their leaves all year. Canopy is never without green foliage. 8 Areas dominated by trees generally greater than 5 meters tall, and greater than 20% of total vegetation cover. Neither deciduous nor evergreen species are greater than 75% of total tree cover. 9 Areas dominated by shrubs; less than 5 meters tall with shrub canopy typically greater than 20% of total vegetation. This class includes true shrubs, young trees in an early successional stage or trees stunted from environmental conditions. 10 Areas dominated by gramanoid or herbaceous vegetation, generally greater than 80% of total vegetation. These areas are not subject to intensive management such as tilling, but can be utilized for grazing. 11 Areas of grasses, legumes, or grass-legume mixtures planted for livestock grazing or the production of seed or hay crops, typically on a perennial cycle. Pasture/hay vegetation accounts for greater than 20% of total vegetation. 12 Areas used for the production of annual crops, such as corn, soybeans, vegetables, tobacco, and cotton, and also perennial woody crops such as orchards and vineyards. Crop vegetation accounts for greater than 20% of total vegetation. This class also includes all land being actively tilled. 13 Areas where forest or shrubland vegetation accounts for greater than 20% of vegetative cover and the soil or substrate is periodically saturated with or covered with water. 14 Areas where perennial herbaceous vegetation accounts for greater than 80% of vegetative cover and the soil or substrate is periodically saturated with or covered with water. Nous attachons maintenant la table dattributs rat au raster R2001f en utilisant donc la fonction levels(): levels(R2001f) &lt;- rat R2001f class : RasterLayer dimensions : 500, 500, 250000 (nrow, ncol, ncell) resolution : 30.1, 29.6 (x, y) extent : 325482, 340532, 4470698, 4485498 (xmin, xmax, ymin, ymax) crs : +proj=utm +zone=13 +datum=WGS84 +units=m +no_defs source : memory names : layer values : 11, 95 (min, max) attributes : ID classe from: 11 Open Water to : 95 Emergent Herbaceous Wetlands description Areas of open water, generally with less than 25% cover of vegetation or soil. Areas where perennial herbaceous vegetation accounts for greater than 80% of vegetative cover and the soil or substrate is periodically saturated with or covered with water. a) Refaite les manipulations précédentes pour le raster de la couverture terrestre de 2016. Réponse type2016 &lt;- unique(R2016f) sommaire &lt;- legende[legende$ID %in% type2016, ] rat &lt;- levels(R2016f)[[1]] rat$classe &lt;- sommaire$Class rat$description &lt;- sommaire$Description levels(R2016f) &lt;- rat R2016f class : RasterLayer dimensions : 500, 500, 250000 (nrow, ncol, ncell) resolution : 30.1, 29.6 (x, y) extent : 325482, 340532, 4470698, 4485498 (xmin, xmax, ymin, ymax) crs : +proj=utm +zone=13 +datum=WGS84 +units=m +no_defs source : memory names : layer values : 11, 95 (min, max) attributes : ID classe from: 11 Open Water to : 95 Emergent Herbaceous Wetlands description Areas of open water, generally with less than 25% cover of vegetation or soil. Areas where perennial herbaceous vegetation accounts for greater than 80% of vegetative cover and the soil or substrate is periodically saturated with or covered with water. Question 4 a) Visualiser le raster catégorique de lannée 2001 avec la fonction mapview(). En particulier: Utiliser la colonne Color du data.frame sommaire pour définir largument col.regions. Utiliser largument att = afin que la légende affiche les types de couvertures. Réponse mapview(R2001f, col.regions = sommaire$Color, att = &quot;classe&quot;, legend = TRUE) b) Utiliser la fonction latticeview() de la bibliothèque leafsync pour afficher les cartes des deux années côte à côte. Najouter pas de légende. Réponse library(leafsync) m2001 &lt;- mapview(R2001f, col.regions = sommaire$Color, legend = FALSE) m2016 &lt;- mapview(R2016f, col.regions = sommaire$Color, legend = FALSE) leafsync::latticeview(m2001, m2016, ncol = 2) Question 5 En comparant les deux cartes pour les années 2001 et 2016 nous pouvons observer visuellement des changements dans la couverture terrestre. Cependant, nous désirons faire une comparaison plus quantitative de ces changements. Pour ce faire, nous pouvons utiliser la fonction ratify() de la bibliothèque raster. Celle-ci possède largument count qui permet de compter le nombre de cellules de chaque catégorie^(Noter que la fonction ratify()permet également de transformer un raster numérique en raster catégorique: voir la documentation sur cette fonction.). Par exemple: R2001_nbr&lt;-ratify(R2001f, count = TRUE) levels(R2001_nbr) [[1]] ID COUNT 1 11 925 2 21 2435 3 22 653 4 23 43 5 24 3 6 41 68050 7 42 2762 8 43 1083 9 52 149858 10 71 3586 11 81 15511 12 82 1512 13 90 2563 14 95 1016 Ajoutons ce calcul du nombre de cellules de chaque type de couvert au data.frame sommaire: sommaire$Nbr2001 &lt;- levels(R2001_nbr)[[1]]$COUNT sommaire # A tibble: 14 x 5 ID Class Color Description Nbr2001 &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; 1 11 Open Water #547~ Areas of o~ 925 2 21 Developed, Open Spa~ #E8D~ Areas with~ 2435 3 22 Developed, Low Inte~ #E29~ Areas with~ 653 4 23 Developed, Medium I~ #ff0~ Areas with~ 43 5 24 Developed High Inte~ #B50~ Highly dev~ 3 6 41 Deciduous Forest #85C~ Areas domi~ 68050 7 42 Evergreen Forest #388~ Areas domi~ 2762 8 43 Mixed Forest #D4E~ Areas domi~ 1083 9 52 Shrub/Scrub #DCC~ Areas domi~ 149858 10 71 Grassland/Herbaceous #FDE~ Areas domi~ 3586 11 81 Pasture/Hay #FBF~ Areas of g~ 15511 12 82 Cultivated Crops #CA9~ Areas used~ 1512 13 90 Woody Wetlands #C8E~ Areas wher~ 2563 14 95 Emergent Herbaceous~ #64B~ Areas wher~ 1016 a) Répéter les manipulations précédentes pour lannée 2016. Réponse R2016_nbr&lt;-ratify(R2016f, count = TRUE) sommaire$Nbr2016 &lt;- levels(R2016_nbr)[[1]]$COUNT b) Déterminer le type de couvert qui a le plus augmenté et celui qui a le plus diminué entre lannée 2001 et lannée 2016. Réponse Pour chaque type de couvert, nous calculons la différence entre le nombre de cellules en 2016 et le nombre de cellules en 2001. Nous divisons ensuite par le nombre de cellules totales dans lun ou lautre des rasters (ils on le même nombre), ce qui permet de comparer les catégories entre elles. Diff &lt;- 100*(sommaire$Nbr2016 - sommaire$Nbr2001)/ncell(R2016f) sommaire$Diff2016_2001 &lt;- Diff sommaire # A tibble: 14 x 7 ID Class Color Description Nbr2001 Nbr2016 &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; 1 11 Open Water #547~ Areas of o~ 925 1213 2 21 Developed, ~ #E8D~ Areas with~ 2435 2435 3 22 Developed, ~ #E29~ Areas with~ 653 654 4 23 Developed, ~ #ff0~ Areas with~ 43 44 5 24 Developed H~ #B50~ Highly dev~ 3 3 6 41 Deciduous F~ #85C~ Areas domi~ 68050 68038 7 42 Evergreen F~ #388~ Areas domi~ 2762 2781 8 43 Mixed Forest #D4E~ Areas domi~ 1083 1115 9 52 Shrub/Scrub #DCC~ Areas domi~ 149858 147788 10 71 Grassland/H~ #FDE~ Areas domi~ 3586 3642 11 81 Pasture/Hay #FBF~ Areas of g~ 15511 14869 12 82 Cultivated ~ #CA9~ Areas used~ 1512 3879 13 90 Woody Wetla~ #C8E~ Areas wher~ 2563 2604 14 95 Emergent He~ #64B~ Areas wher~ 1016 935 # ... with 1 more variable: Diff2016_2001 &lt;dbl&gt; Nous pouvons maintenant utiliser les fonctions which.max() et which.min() qui identifient la position, dans un vecteur, des éléments de valeur maximimale et minimale respectivement. sommaire$Class[which.max(sommaire$Diff2016_2001)] [1] &quot;Cultivated Crops&quot; sommaire$Class[which.min(sommaire$Diff2016_2001)] [1] &quot;Shrub/Scrub&quot; Ce sont donc les champs cultivés qui ont le plus augmenté et les peuplements darbustres qui ont le plus diminué au cours de cette période. Les données peuvent être téléchargées sur le site du Multi-Resolution Land Characteristics Consortium. "],["carto.html", "Module 6 Cartographie", " Module 6 Cartographie Ce module porte sur la cartographie et il comporte deux objectifs principaux. Le premier objectif est dapprendre les principes fondamentaux de la cartographie. Le deuxième objectif est dapprendre les fonctionnalités de la bibliothèque R tmap pour créer divers types de carte avec des données vectorielles et matricielles. À la fin de ce module vous saurez: Décrire les principes fondamentaux à respecter lors de la création dune carte. Identifier les éléments cartographiques indispensables et optionnels. Décrire les types de cartes générale et thématique. Définir la symbologie utilisée en cartographie. Comprendre le fonctionnement de base de la bibliothèque tmap. Utiliser les fonctions de tmap pour ajouter des éléments cartographiques et ajuster la mise en page dune carte. Utiliser les fonctions de tmap pour cartographier des données vectorielles de type points, lignes et polygones. Utiliser les fonctions de tmap pour cartographier des données matricielles. Utiliser les fonctions de tmap pour créer des cartes avec symboles proportionnels et choroplèthes. Utiliser les fonctions de tmap pour créer des cartes à panneaux multiples Vous utiliserez les bibliothèques suivantes: tmap grid viridis RColorBrewer Vous apprendrez à utiliser les fonctions suivantes: tm_shape() tm_fill() tm_scale_bar() tm_compass() tm_grid() tm_graticules() tm_credits() tmap_arrange() tm_borders() tm_polygons() tm_layout() tm_style() tm_text() tm_lines() tm_markers() tm_raster() tm_legend() tm_symbols() tm_bubbles() tm_facets() viewport() print() Vous utiliserez les données suivantes: Dans la section leçon, vous utiliserez cinq ensembles de données différents. Quatre ensembles sont formés de données vectorielles. Il sagit de données sur les régions administratives du Québec et la taille de leur population (polygones), des routes du Québec (lignes), des municipalités du Québec (points), et des cas de COVID dans les régions socio-sanitaires du Québec (polygones). Lensemble de données matricielles correspond à des données délévation sur tout le territoire québécois. Dans la section exercice, vous utiliserez des données disponibles dans la bibliothèque tmap. "],["lecon_carto.html", "6.1 Leçon", " 6.1 Leçon 6.1.1 Télécharger les données Les données Importez lensemble des données utilisées dans ce module. Sauvegardez le dossier compressé (Module6_donnees.zip) dans votre répertoire de travail pour ce module, et dézippez-le. Ce dossier comprend lui-même cinq sous-dossiers que vous devez également dézipper: COVID Elevation Population Routes Villes Nous utiliserons ces données à partir de la section 6.1.3. Commençons dabord par une introduction sur les principes de bases de la cartographie. 6.1.2 Éléments de base en cartographie Principes fondamentaux La mise en page dune carte est importante pour que cette dernière puisse être utilisée efficacement. Nous avons tous déjà vu des cartes de mauvaise qualité. Celles-ci peuvent être difficiles à lire et à interpréter. Elles peuvent être peu informatives, trompeuses et même erronées car certaines informations essentielles sont absentes ou sont diffusées incorrectement. La figure 6.1 donne quelques exemples de cartes que lon peut facilement qualifier de mauvaises. FIGURE 6.1: Exemples de mauvaises cartes. a) Carte de la diplomation et du revenu selon les comtés aux États-Unis (source: https://blog.stratasan.com/bad-maps-bad-maps). b) Carte du monde (source:https://carto.com). c) Carte de la localisation de tous les pubs dans le sud est du Royaume-Uni (source:http://www.math.uwaterloo.ca/tsp/pubs/data.html). d) Carte de lEurope (source:https://gis.stackexchange.com). La première carte, par exemple, illustre le niveau de diplomation et de revenu aux États-Unis. Elle utilise une superposition de trois couleurs pour chaque comté du territoire américain. Le rose représente le taux de diplomation à lécole secondaire, le jaune, le taux de diplomation au collègue, et le bleu, le revenu médian. Une multitude de couleurs apparait donc sur la carte la rendant difficile à interpréter. Dans un cas pareil, la carte devient inutile car elle ne permet pas de transmettre un message unique et clair. Une carte est efficace lorsquelle est simple. Il faut donc éviter dy mettre trop dinformations. La deuxième carte illustre lensemble des pays de la planète et présente plusieurs problèmes. Dabord le nom de chaque pays, abrégé par trois lettres, est positionné sur chacun de ceux-ci. Cette approche rend totalement illisible le nom des pays dans les régions où ils sont nombreux. De plus, lusage dabbréviation est peu utile à moins de connaître déjà le nom du pays. Finalement, le choix des couleurs employées pour le texte et pour la carte elle-même est épouvantable. Les lettres sont beaucoup trop pâles, nuisant à la lisibilité des noms, et la palette de couleurs pour représenter les pays et les océans (en jaune!) est dérangeante. La troisième carte donne la position de tous les pubs dans le sud est du Royaume-Uni. Une telle carte est utile si lutilisateur a la possibilité dagrandir lécran en mode zoom. Autrement, la quantité trop grande de marqueurs masque linformation sur la localisation des pubs. Si lobjectif de cette carte est dillustrer labondance des pubs dans ce pays, alors une représentation de la densité de pubs par habitant pour une division administrative donnée serait plus informative. Finalement, la dernière carte représente une section de lEurope. Nous observons un usage exagéré décriture sur la carte qui, en plus, repose sur une trop grande diversité de polices et de tailles de caractère. Cette écriture est dense et nest pas structurée de manière hiérarchique si bien quil est impossible de dégager les éléments importants. Également, la signification du gradient de couleurs utilisé nest pas évidente. Il existe quelques principes fondamentaux à respecter lorsque nous concevons une carte. Nous les résumons ici. Une carte doit être: Claire et cohérente. Nous devons pouvoir comprendre et interpréter la carte facilement. Adaptée à son public cible. Une carte qui sadresse au grand public sera différente dune carte qui sadresse à des experts. Conforme aux conventions. Une carte doit respectée les conventions propres à son domaine dapplication. Cela signifie aussi de respecter les associations naturelles de couleur tel que dillustrer les plans deau par la couleur bleue. Esthétique. Une carte doit, par sa composition, le choix des couleurs, sa typographie, être agréable à loeil. Bien structurée. Une carte doit être dotée dune certaine hierarchie visuelle. La visualisation dune carte doit permettre de dégager rapidement ses éléments importants. Informations indispensables et optionnelles Plusieurs éléments de mise en page sont indispensables dans une carte (Figure 6.2): Un titre Une échelle graphique Une légende Lorientation La source Lauteur ou lautrice La référence spatiale FIGURE 6.2: Éléments indispensables dune carte (source: https://crelaurentides.org/). Le titre est essentiel car il est la synthèse du message cartographie. Il doit être complet mais concis. Il peut être neutre (p. ex: Nouveaux cas de COVID-19) ou subjectif (p. ex: Hausse fulgurante des cas de COVID-19). Léchelle graphique est essentielle pour que le lecteur puisse saisir létendue et la résolution du phénomène illustré dans la carte. Léchelle doit être simple (sans trop de subdivisions), pas trop longue, donner des valeurs arrondies, et toujours fournir lunité métrique utilisée ou son abbréviation (p. ex. kilomètres ou km). La légende est essentielle à linterprétation dune carte. Celle-ci traduit les éléments graphiques en texte. En effet, tous les éléments qui ne sont pas évidents ou conformes doivent apparaître dans la légende de façon alignée et claire. Une légende doit comprendre: les éléments graphiques, le texte associé à chaque élément et les unités de mesure. Les éléments graphiques se rapportant à des données vectorielles doivent idéalement suivre lordre point-ligne-polygone dans la légende. Notez quil est aussi inutile décrire le mot Légende. Lorientation de la carte, spécifiée par une flèche du nord ou une rose des vents, est indispensable si les données illustrées sont en rotation de sorte que le nord ne corresponde pas au haut de la carte. Par exemple, la flèche du nord est indiquée sur la carte du réseau dautobus de nuit de la Société de transport de Montréal (figure 6.3). En effet, pour facilité la lecture de la carte, lîle de Montréal est représentée sur un axe horizontal qui ne correspond pas à laxe géographique est-ouest. La flèche du nord doit être discrète sur une carte. Par ailleurs, si le nord est bien au haut de la carte, la flèche du nord est optionnelle. FIGURE 6.3: La flèche du nord est indispensable lorsque ce dernier ne correspond pas au haut de la carte (source: http://www.mondecarte.com/carte/canada/montreal/montreal_night_bus_plan.png. La source, lauteur.trice, la date, et la projection doivent toujours être présents sur une carte. La citation de la source des données est importante pour des raisons éthiques. Les données illustrées ont été assemblées par une personne ou un organisme et nous devons reconnaître le travail de ce dernier. De plus, la citation dune source, si celle-ci est reconnue, apporte de la crédibilité au contenu de la carte. Finalement, la citation dune source permet au lecteur ou à la lectrice dune carte de retracer et daccéder aux données. Notez que ces quatre éléments devraient apparaître en petits caractères sur la carte car ils ne sont pas centrals au message. Dautres éléments sont souvent présents sur une carte mais sont optionnels: Un cadre Un encart Des graticules Un quadrillage Un cadre sert à délimiter la zone cartographiée (figure 6.4). Un encart est une carte secondaire de petite taille que lon appose à la carte principale (figure 6.4). Cette carte secondaire peut servir, par exemple, à représenter une étendue géographique plus grande qui permet de mieux situer la zone représentée dans la carte principale. Un encart peut être situé à lintérieur ou à lextérieur du cadre. FIGURE 6.4: Un cadre et un encart sont des éléments optionnels de la mise en page dune carte (source: Proulx et al. 2019). Les graticules correspondent au réseau de latitudes et de longitudes permettant dafficher les coordonnées géographiques des données représentées. Les coordonnées, en degrés, sont affichées sur le cadre de la carte (figure 6.5). FIGURE 6.5: Les graticules sont les coordonnées géographiques (degrés de latitude et de longitude) sur le cadre dune carte (indice de sévérité des feux de forêt, source:https://cwfis.cfs.nrcan.gc.ca/) . Un quadrillage, ou une grille, est un réseau de lignes horizontales et verticales perpendiculaires permettant dafficher le système de coordonnées projetées (figure 6.6). FIGURE 6.6: Le quadrillage correspond au système de coordonnées projetées. Il est identifé par le nom de la projection cartographique utilisée (source:https://www.sepaq.com/) . Certaines cartes font lusage à la fois du quadrillage et des graticules (figure 6.7): FIGURE 6.7: Les graticules et le quadrillage peuvent être utilisées sur une même carte (source:https://sbl.umontreal.ca/) . Le texte Différents types de texte apparaissent sur une carte. Il y a le texte utilisé sur ou autour dune carte comme le titre, le texte de la légende et le texte affichant la source des données, la date, la projection, etc. Une carte peut aussi afficher des étiquettes qui servent à décrire les attributs des données spatiales représentées. Par exemple, le nom dun pays sur le polygone délimitant les frontières de ce dernier. Une carte peut aussi contenir des annotations, cest-à-dire du texte apposées sur la carte pour préciser des informations ou identifier des éléments qui ne sont pas nécessairement des attributs des données spatiales représentées. Le choix de la police, de la fonte, de la taille et de la couleur des caractères utilisés dans le texte dune carte a une influence sur sa lisibilité. Il existe quelques principes à respecter lors du choix de ces éléments. Nous devons nous limiter à deux polices de caractères : une police avec empattement (serif en anglais) et une autre sans empattement (sans serif) (figure 6.8). Les polices avec empattement sont généralement utilisées pour étiqueter des objets naturels (plans deau, montagnes, etc.) alors que les polices sans serif sont utilisées pour étiqueter des objets anthropiques (villes, routes, ponts, etc.). FIGURE 6.8: Lettre avec empattement à gauche et sans empattement à droite. La taille de caractère doit être supérieure à 7 points. Il est préférable de conserver une seule taille de caractères à moins de vouloir créer une hiérarchie visuelle dans les étiquettes. Nous devons favoriser également lutilisation dune seule couleur de texte, à moins de vouloir identifier différentes catégories détiquettes. Lusage de différentes couleurs et tailles de caractères dans lobjectif de créer une hiérarchie visuelle peut améliorer la lisibilité dune carte mais doit se faire judicieusement et avec parcimonie. Les figures (6.9) et (6.10) donnent des exemples dans lesquels le texte a été adapté pour améliorer la présentation dune carte. FIGURE 6.9: Exemple de carte où lécriture a été améliorée. Le choix de couleurs différentes pour représenter les frontières et les plans deau, ainsi que lorientation du texte améliore la lisibilité de la carte (source: Guimond 2021 (https://mgimond.github.io/Spatial/good-map-making-tips.html#typefaces-and-fonts)) . FIGURE 6.10: Exemple de carte où lécriture a été améliorée. La carte du dessus fait lusage de caractères de tailles, de fonte, de couleurs et dorientation différentes créant une hiérarchie visuelle efficace (source: https://www.axismaps.com/) . Dans la figure (6.10), remarquez le lettrage en majuscule pour étiqueter des territoires ainsi que la fonte italique et la couleur bleue pour identifier des plans deau. De plus, remarquez que les étiquettes associées aux points ne sont jamais directement dessus, dessous ou à côté des points. Elles sont plutôt en haut à droite, en haut à gauche, en bas à droite ou en bas à gauche. Les types de carte Il existe deux grandes catégories de carte: les cartes générales et les cartes thématiques. Les cartes générales affichent uniquement lemplacement géographiques des données quelles soient sous forme de points, de lignes, de polygones ou de rasters. Les cartes routières, les plans de localisation, les cartes topographiques et les cartes touristiques en sont des exemples (6.11). FIGURE 6.11: Exemples de carte générale. A) Carte routière des environs de Paris (source:https://fr.viamichelin.be/). B) Carte touristique de la Gaspésie (source: http://motoplus.ca). C) Plan du Montréal souterrain (source: https://voyage-montreal.com/montreal-souterrain ). Les cartes thématiques, quant à elles, affichent non seulement lemplacement géographiques des données spatiales mais aussi un ou plusieurs de leurs attributs. Ces cartes utilisent une symbologie pour représenter les attributs des données. Cest-à-dire quelles font appel à différentes couleurs, formes et tailles de symboles pour représenter les données de sorte que celles-ci aquièrent une signification. Ces cartes servent ainsi à transmettre un message. Nous approfondirons les concepts de symbologie à la prochaine section. Pour le moment, notons que plusieurs types de cartes thématiques existent. Voici quelques exemples: Les cartes à symboles gradués et à symboles proportionnels utilisent des symboles de tailles différentes pour afficher une différence quantitative ou relative entre les valeurs de lattribut représenté. Dans le premier cas, les valeurs sont divisées en classes couvrant chacune une certaine plage de valeurs. Chaque classe est alors illustrée par une taille spécifique de symbole (6.12A). Dans le second cas, il ny a pas de classification des valeurs. La plus petite valeur est illustrée par le plus petite taille de symbole, et la taille de chaque symbole augmente proportionnellement avec la valeur absolue de la donnée quelle représente (6.12B). Les cartes de densité de points utilisent des symboles ponctuels de même taille mais dont le nombre varie dune polygone à un autre pour illustrer la variation dans la densité de lattribut représenté (6.12C). FIGURE 6.12: Exemples de (A) carte avec symboles gradués, (B) carte avec symboles proportionnels, (C) carte de densité de points (source: GISGeography 2021. Dot Distribution vs Graduated Symbols vs Proportional Symbol Maps: https://gisgeography.com/dot-distribution-graduated-symbols-proportional-symbol-maps/, Consulté le 30 mars 2021). Les cartes choroplèthes illustrent les régions dune carte en utilisant une palette de couleur qui réflètent la variation relative dun attribut dune région à lautre (par exemple la densité de population)(6.13). Notons que choro signifie aire ou région en grec, et plèthe signifie grande quantité ou multitude. Lapparence dune carte choroplèthe dépend de la façon dont la classification des valeurs dattribut est réalisée; cest-à-dire la plage de valeurs attribuée à chaque couleur. Nous reviendrons sur limportance de la classification dans la prochaine section. FIGURE 6.13: Densité de population à léchelle mondiale. (Source:https://ourworldindata.org/most-densely-populated-countries). Les cartes isoplèthes représentent les données spatiales par des lignes contour. Cest-à-dire des lignes formées en joignant ensemble les points qui ont la même valeur dattribut (iso signifie égal en grec). Les cartes isoplèthes peuvent aussi utiliser une même couleur pour représenter des régions qui ont une même valeur dattribut (6.14). FIGURE 6.14: Période densoleillement en Europe, en heures par année. (Source:http://averagemaps.blogspot.com/2013/10/isoline-map.html). Les cartogrammes illustrent les régions dune carte en modifiant leur taille de façon proportionnelle à lattribut représenté (6.15). FIGURE 6.15: Exemples de (A) carte du monde avec une représentation non modifiée des superficies des états, (B) carte de la population mondiale (la superficie de chaque territoire est proportionnelle à la fraction de la population mondiale y habitant), (C) Carte de la consommation de café en 2014 (la superficie de chaque territoire est proportionnelle à la proportion mondiale de café qui y est consommé (kg par habitants)) (source:https://worldmapper.org/). La symbologie La carte est un outil de communication. La façon dont sont représentées les données spatiales sur une carte joue un rôle primordial dans lefficacité et la justesse de cet outil. On appelle sémiologie graphique38 ou symbologie «lencodage des entités cartographiques dans le but de transmettre une signification.» 39 La symbologie se rapporte donc aux choix faits pour représenter les données spatiales et pour représenter les relations entre ces données. Les variables visuelles sont des différences dans les entités cartographiques pouvant être perçues par loeil humain. Le cartographe Jacques Bertin (1967) proposa lexistence de sept variables visuelles principales: la position, la forme, la taille, la couleur (la teinte), la valeur (la luminosité), la texture et lorientation (6.16). Depuis, dautres variables se sont ajoutées: la saturation, la disposition, la netteté, la résolution, et la transparence. FIGURE 6.16: Les variables visuelles (source: figure adaptée de https://cartosquad.com/) Une relation entre les données exprime généralement une différence qualitative ou une différence quantitative. Par exemple, distinguer sur une carte la capitale des autres villes dun pays relève dune différence qualitative nominale. Nous pouvons alors choisir différents symboles (un point pour une ville et une étoile pour une capitale) ou différentes couleurs (un point bleu pour une ville et un point rouge pour une capitale) pour distinguer ces entités. Les attributs qualitatifs peuvent aussi exprimer une différence ordinale, cest-à-dire une hiérarchie entre les données. Par exemple, les rues, les boulevards, les autoroutes peuvent être représentés par des traits daspects ou dépaisseurs différents. Par ailleurs, nous pourrions vouloir exprimer une différence quantitative entre la taille des populations des villes. Cette quantité absolue pourrait alors être exprimée par lutilisation de point dont le diamètre est proportionnel à la taille de la ville quil représente. Dautre part, pour représenter une quantité relative, par exemple la densité de population de différents états, il vaudra mieux utiliser un gradient de luminosité allant dune couleur pâle à foncée pour remplir les polygones associés aux états. Le tableau de la figure 6.17 résume les choix possibles de symbologie en fonction de la nature des données. Ce tableau est tiré du livre Savoir faire une carte : Aide à la conception et à la réalisation dune carte thématique univariée de Zanin et Trémolo (2003). FIGURE 6.17: Symbologie selon la nature des données (source: Zanin et Trémolo (2003)) Les variables visuelles nont pas toutes la même efficacité à distinguer les données. Certaines variables doivent être favorisées alors que dautres sont à proscrire pour représenter certaines données et leurs relations. Par exemple, la forme est une variable visuelle utile pour distinguer des données nominales. Toutefois, la forme ne devrait pas être utilisée pour représenter des valeurs ordinales ou des valeurs quantitatives. Les couleurs Cette sous-section sattarde aux variables visuelles liées aux couleurs. Elle reprend, en partie, le [chapitre 4] (https://mgimond.github.io/Spatial/symbolizing-features.html) du livre de Gimond (2021). Le choix des couleurs est évidemment important dans une carte puisque celles-ci permettent de distinguer, de catégoriser ou de mettre lemphase sur certains phénomènes spatiaux. Le choix des couleurs ajoute une certaine subjectivité à une carte. Par exemple, la couleur rouge peu facilement être associée à un extrême ou à un danger. La carte de lindice de sévérité des feux de forêt à la figure 6.5 utilise le rouge pour désigner la zone où cet indice est maximal. Le contraire, par exemple utiliser la couleur bleu pour cette zone, aurait porté à confusion et nuit au message véhiculé par la carte. Les dimensions perceptuelles Une couleur est définie par une combinaison de trois valeurs quon appelle dimensions perceptuelles: la teinte, la luminosité et la saturation. La teinte (ou la tonalité, hue en anglais) est la dimension que nous associons aux noms des couleurs. La teinte est généralement utilisée pour représenter différentes catégories de données; cest-à-dire des données qualitatives nominales. FIGURE 6.18: Un exemple de 8 différentes teintes de couleur La luminosité (ou la valeur) est associée à la quantité de lumière quune surface réfléchit ou émet. La luminosité est généralement utilisée pour représenter des données ordinales ou relatives. FIGURE 6.19: Huit différentes teintes (colonnes) déclinées selon des valeurs décroissantes de luminosité (rangées). La saturation (ou la chromaticité) dune couleur mesure son intensité. Une couleur vive a une saturation élevée tandiquune couleur pâle a une saturation faible. La saturation est surtout utilisée pour distinguer des données ordinales. FIGURE 6.20: Huit différentes teintes (colonnes) déclinées selon des valeurs décroissantes de saturation (rangées). Définir les couleurs dans R Dans R, il existe plusieurs façons de définir les couleurs. Nom des couleurs Nous pouvons dabord définir une couleur par son nom. Il existe 657 différents noms de couleur dans R que nous pouvons découvrir en utilisant la fonction colours(). Voyons quelles sont les 50 premières couleurs: colours()[1:50] [1] &quot;white&quot; &quot;aliceblue&quot; &quot;antiquewhite&quot; [4] &quot;antiquewhite1&quot; &quot;antiquewhite2&quot; &quot;antiquewhite3&quot; [7] &quot;antiquewhite4&quot; &quot;aquamarine&quot; &quot;aquamarine1&quot; [10] &quot;aquamarine2&quot; &quot;aquamarine3&quot; &quot;aquamarine4&quot; [13] &quot;azure&quot; &quot;azure1&quot; &quot;azure2&quot; [16] &quot;azure3&quot; &quot;azure4&quot; &quot;beige&quot; [19] &quot;bisque&quot; &quot;bisque1&quot; &quot;bisque2&quot; [22] &quot;bisque3&quot; &quot;bisque4&quot; &quot;black&quot; [25] &quot;blanchedalmond&quot; &quot;blue&quot; &quot;blue1&quot; [28] &quot;blue2&quot; &quot;blue3&quot; &quot;blue4&quot; [31] &quot;blueviolet&quot; &quot;brown&quot; &quot;brown1&quot; [34] &quot;brown2&quot; &quot;brown3&quot; &quot;brown4&quot; [37] &quot;burlywood&quot; &quot;burlywood1&quot; &quot;burlywood2&quot; [40] &quot;burlywood3&quot; &quot;burlywood4&quot; &quot;cadetblue&quot; [43] &quot;cadetblue1&quot; &quot;cadetblue2&quot; &quot;cadetblue3&quot; [46] &quot;cadetblue4&quot; &quot;chartreuse&quot; &quot;chartreuse1&quot; [49] &quot;chartreuse2&quot; &quot;chartreuse3&quot; Vous remarquerez que les couleurs sont nommées par ordre alphabétique sauf pour la première entrée qui est la couleur blanche (white). Pour connaître la couleur associée à chaque nom, vous pouvez consulter la charte suivante: charte des couleurs [PDF]. Vous pouvez utiliser une couleur en la nommant (par ex. \"red\") ou en référant au numéro de sa position dans le vecteur colours() (par ex. colours()[552]) si vous connaissez celui-ci. La fonction grep() permet de trouver des couleurs associées à une couleur dintérêt. Prenons, par exemple, la couleur verte: # Indices des couleurs grep(&quot;green&quot;, colours()) [1] 81 85 86 87 88 89 102 103 104 105 106 139 [13] 254 255 256 257 258 259 393 417 429 448 472 474 [25] 514 515 516 517 518 574 575 576 577 578 610 611 [37] 612 613 614 657 Ces indices sont associées aux couleurs suivantes: FIGURE 6.21: Quarante couleurs vertes identifiées par la fonction grep() Nous pouvons déterminer le nom des couleurs de la façon suivante: # Noms des couleurs colours()[grep(&quot;green&quot;, colours())] [1] &quot;darkgreen&quot; &quot;darkolivegreen&quot; [3] &quot;darkolivegreen1&quot; &quot;darkolivegreen2&quot; [5] &quot;darkolivegreen3&quot; &quot;darkolivegreen4&quot; [7] &quot;darkseagreen&quot; &quot;darkseagreen1&quot; [9] &quot;darkseagreen2&quot; &quot;darkseagreen3&quot; [11] &quot;darkseagreen4&quot; &quot;forestgreen&quot; [13] &quot;green&quot; &quot;green1&quot; [15] &quot;green2&quot; &quot;green3&quot; [17] &quot;green4&quot; &quot;greenyellow&quot; [19] &quot;lawngreen&quot; &quot;lightgreen&quot; [21] &quot;lightseagreen&quot; &quot;limegreen&quot; [23] &quot;mediumseagreen&quot; &quot;mediumspringgreen&quot; [25] &quot;palegreen&quot; &quot;palegreen1&quot; [27] &quot;palegreen2&quot; &quot;palegreen3&quot; [29] &quot;palegreen4&quot; &quot;seagreen&quot; [31] &quot;seagreen1&quot; &quot;seagreen2&quot; [33] &quot;seagreen3&quot; &quot;seagreen4&quot; [35] &quot;springgreen&quot; &quot;springgreen1&quot; [37] &quot;springgreen2&quot; &quot;springgreen3&quot; [39] &quot;springgreen4&quot; &quot;yellowgreen&quot; Composantes RVB Nous pouvons aussi définir une couleur par un vecteur donnant chacune des trois composantes RVB (RGB en anglais) qui la constitue. Rappellons que chacune des composantes RVB (Rouge, Vert, Bleu) prend une valeur discrète entre 0 et 255. La valeur 0 correspond à lintensité la plus faible tandis que la valeur 255 correspond à lintensité la plus élevée. Chaque composante peut aussi être exprimée selon la notation décimale par un nombre entre 0.0 et 1.0. Puisque chaque composante RVB peut prendre 256 valeurs différentes, le format RVB permet de définir 256 x 256 x 256 couleurs différentes (16777216!). La fonction col2rgb() permet de traduire une couleur, identifiée par son nom, vers son format RVB. # Composantes RVB de la couleur verte col2rgb(&quot;green&quot;) [,1] red 0 green 255 blue 0 # Composantes RVB de la couleur vert forêt col2rgb(&quot;forestgreen&quot;) [,1] red 34 green 139 blue 34 Codes HEX Nous pouvons également définir une couleur par son code hexadécimal (HEX). Le code hexadécimal utilise un système en base 16 pour encoder la notation RVB dune couleur en une notation condensée de six chiffres ou lettres. Le code HEX prend la forme #RRVVBB où chaque lettre peut prendre un des 16 symboles suivants: 0,1,2,3,4,5,6,7,8,9,A,B,C,D,E,F. Par exemple, 00 correspond à la valeur 0, et FF correspond à la valeur 255. Ainsi, le code de HEX de la couleur verte est #00FF00. La fonction rgb(red, green, blue) renvoie le code HEX dune couleur identifiée par son format RVB # Notation HEX de la couleur verte rgb(0,255,0, maxColorValue=255) [1] &quot;#00FF00&quot; # Ou en utilisant la forme notation normalisée de RVB rgb(0.0,1.0,0.0) [1] &quot;#00FF00&quot; La fonction rgb() permet aussi de définir des couleurs en leur assignant un nom. Par exemple: rgb(0,(250:255)/255,0, names = paste(&quot;vert&quot;, 0:5, sep=&quot;_&quot;)) vert_0 vert_1 vert_2 vert_3 vert_4 &quot;#00FA00&quot; &quot;#00FB00&quot; &quot;#00FC00&quot; &quot;#00FD00&quot; &quot;#00FE00&quot; vert_5 &quot;#00FF00&quot; Composantes TSL/TSV Selon une approche basée sur la perception des couleurs, nous pouvons définir une couleur par sa combinaison de trois paramètres: sa teinte (hue en anglais), sa saturation (aussi appelée chromaticité) et sa luminosité (lightness en anglais) ou sa valeur (value en anglais). Ces systèmes de description des couleurs se nomment TSL (HSL en anglais) et TSV (HSV en anglais). Ils différent légèrement mais ils sappuient sur les mêmes principes40. La fonction rgb2hsv(red, green, blue) permet de traduire une couleur représentée par le modèle RVG vers le modèle TSV. # La couleur verte rgb2hsv(0,255,0,maxColorValue=255) [,1] h 0.3333 s 1.0000 v 1.0000 Inversément, la fonction hsv(hue, saturation, value) permet dobtenir le code HEX dune couleur représentée selon le modèle TSV. Chaque entrée de la fonction prend une valeur entre 0.0 et 1.0. # La couleur verte hsv(0.333333,1.0,1.0) [1] &quot;#00FF00&quot; La fonction hcl(hue, chroma, luminance) renvoie le code HEX dune couleur représentée selon le modèle TSL. Le paramètre pour la teinte, hue, prend une valeur entre 0 et 360. La valeur maximale du paramètre pour la chromacité, chroma, dépend des valeurs attribuées à la teinte et à la luminosité. Le paramètre pour la luminosité, luminance, prend une valeur entre 0 et 100. Seul un certain domaine de valeurs de luminosité est possible pour une combinaison de teinte et de chromacité donnée. hcl(h = 120, c = 1, l = 0.5) [1] &quot;#000300&quot; Les palettes de couleurs Une palette de couleurs est un ensemble fini de couleurs pré-sélectionnées. Dans une carte thématique, une palette de couleur établit une correspondance entre une valeur dattribut et une couleur de la palette. Il existe trois catégories de palettes de couleurs. Les palettes qualitatives Les palettes séquentielles Les palettes divergentes Les palettes qualitatives sont utilisées pour représenter des données qualitatives nominales, cest-à-dire des données qui ne sont pas ordonnées ni quantitatives. Une palette qualitative est constituée de couleurs de teintes différentes mais de luminosité et de saturation égales. FIGURE 6.22: Un exemple de 4 palettes qualitatives Une palette qualitative sied bien pour illustrer les différents continents de la planète. Les palettes séquentielles sont utilisées pour représenter des données ordonnées, par exemple la température, la densité de population, le revenu moyen par habitant, etc. Une palette séquentielle forme un gradient allant dune couleur pâle (correspondant à la valeur la plus faible de lattribut représenté) à une couleur foncée (correspondant à la valeur la plus forte de lattribut). La palette séquentielle utilise généralement une seule teinte (mais parfois plus) qui est déclinée sur plusieurs niveaux de luminosité ou de saturation. FIGURE 6.23: Un exemple de 5 palettes séquentielles. Les trois premières palettes font appel à une seule teinte (noire, bleue et verte). La quatrième fait appel à deux teintes (jaune et verte) tandis que la dernière fait appel à trois teintes (jaune, orange et rouge) À titre dexemple, une palette séquentielle sied bien pour illustrer comment la densité de population varie dun pays à lautre. Les palettes divergentes sont également utilisées pour représenter des données ordonnées. Toutefois, une palette divergente met laccent sur une valeur centrale à partir de laquelle les données divergent. Généralement, une palette divergente est constituée de deux teintes complémentaires qui dénotent les valeurs extrêmes de part et dautre de la valeur centrale. La saturation et la luminosité de chaque teinte sont alors ajustées pour que les couleurs se répartissent de façon symmétrique autour de la valeur centrale qui est représentée par une couleur pâle. FIGURE 6.24: Un exemple de 4 palettes divergentes. Par exemple, une palette divergente illustre bien la distribution spatiale des produits régionaux bruts. Les palettes de couleurs dans R Il existe plusieurs façons de définir des palettes de couleurs dans R. Les palettes de couleurs de base de R Tout dabord, R comprend des palettes par défaut qui sont définies par les fonctions suivantes: rainbow(n) heat.colors(n) terrain.colors(n) topo.colors(n) cm.colors(n) Le paramètre n spécifie le nombre de couleurs. FIGURE 6.25: Les palettes de base dans R. Les palettes viridis La bibliothèque viridis comprend quatre palettes de couleurs séquentielles qui sont définies par les fonctions suivantes: viridis(n) magma(n) plasma(n) inferno(n) FIGURE 6.26: Les palettes de la bibliothèque viridis. Les palettes ColorBrewer La bibliothèque RColorBrewer contient les palettes de couleurs ColorBrewer particulièrement utiles pour la cartographie. Cette bibliothèque comprend un grand nombre de palettes séquentielles, divergentes et qualitatives. FIGURE 6.27: Les palettes de la bibliothèque RColorBrewer. Remarquez que les palettes de RColorBrewer contiennent un nombre maximal de 12 couleurs (ou moins pour les palettes qualitatives), contrairement aux palettes de base et viridis. Pour choisir une palette particulière, nous utilisons la fonction brewer.pal(n,name) où n est le nombre de couleurs dans la palette, et name est le nom de la palette. Par exemple, brewer.pal(5, &quot;Accent&quot;) [1] &quot;#7FC97F&quot; &quot;#BEAED4&quot; &quot;#FDC086&quot; &quot;#FFFF99&quot; &quot;#386CB0&quot; Ceci retourne un vecteur de cinq couleurs de la palette Accent. 6.1.3 Cartes statiques avec tmap Il existe plusieurs bibliothèques R permettant de visualiser des données spatiales. La bibliothèque mapview, que nous avons déjà utilisée, en est un exemple. La bibliothèque ggplot2, que vous connaissez peut-être, permet de créer des cartes qui peuvent être peaufinées par lutilisation de fonctions des bibliothèques sf et ggspatial41. Dans le cadre de ce cours, nous nous concentrerons sur la bibliothèque tmap et lapprentissage de ses fonctions principales. Nous avons choisi tmap parce que cette bibliothèque est relativement simple à utiliser et que ses fonctions sont intuitives. Le fonctionnement de tmap est très similaire à celui de la bibliothèque ggplot2 qui est fort populaire pour la visualisation de données de toutes sortes. Si vous connaissez déjà ggplot2, alors lapprentissage de tmap vous sera familié. Si vous ne connaissez pas ggplot2, vous pourriez être amenés à lutiliser dans le futur, et dans ce cas votre connaissance de tmap vous sera utile. De façon générale, nous utilisons tmap pour cartographier des données spatiales de la façon suivante: tm_shape(DonneesSpatiales) + tm_fonction1() + tm_fonction2() + ... La fonction tm_shape() est suivi dune ou de plusieurs fonctions qui précisent les objets ou les attributs des données à cartographier ainsi que les éléments cartographiques à ajouter et la mise en page souhaitée. Télécharger la bibliothèque tmap: install.packages(&quot;tmap&quot;) Chargez tmap dans votre session de travail R ainsi que les bibliothèques sf et raster dont nous aurons besoin pour lire et manipuler les données vectorielles et matricielles respectivement: library(tmap) library(sf) library(raster) 6.1.4 Les polygones Données sur les régions administratives du Québec Pour débuter notre exploration des fonctions de cartographie offertes avec tmap nous utiliserons les données vectorielles sur les limites des régions administratives du Québec ainsi que la taille de leur population. La taille des populations des régions administratives provient de la Banque de données des statistiques officielles sur le Québec (https://bdso.gouv.qc.ca/), et les limites géographiques des régions proviennent du site Données Québec (https://www.donneesquebec.ca/recherche/dataset/decoupages-administratifs). Utiliser la fonction st_read() de la bibliothèque sf pour lire le shapefile QC_RegAdm_Pop.shp contenu dans le dossier Population: Q &lt;- st_read(&quot;Module6/Module6_donnees/Population/QC_RegAdm_Pop.shp&quot;) Reading layer `QC_RegAdm_Pop&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module6\\Module6_donnees\\Population\\QC_RegAdm_Pop.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 17 features and 8 fields Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin: -830300 ymin: 118000 xmax: 783300 ymax: 2091000 Projected CRS: NAD83 / Quebec Lambert Observer la structure et les attributs du shapefile Q. Celui-ci contient 17 multipolygones, un pour chacune des régions administratives du territoire québécois. De plus, Q contient 8 attributs: NUM_REG: le numéro associé à la région administrative, NOM_REG: le nom de la région administrative, AREA_REG: la superficie de la région, Pop_tot: la population totale en 2019 dans la région, Pop_0_14: la population agée de 0 à 14 ans, Pop_15_24: la population agée de 15 à 24 ans, Pop_25_64: la population agée de 25 à 64 ans, Pop_65_: la population agée de 65 ans et plus. Intérieur des polygones Fonction tm_fill Créons tout dabord une carte simple du shapefile Q que nous venons de charger. La fonction tm_fill() permet de remplir de façon homogène lintérieur des limites dun polygone. Elle sapplique donc aux données vectorielles de type polygone, et on lajoute à la donction tm_shape(). tm_shape(Q)+ tm_fill() Objet tmap La bibliothèque tmap comprend sa propre classe dobjets: map_Q &lt;- tm_shape(Q)+ tm_fill() class(map_Q) [1] &quot;tmap&quot; En créant un objet tmap, la carte est seulement affichée lorsquon appelle lobjet. La création dobjet tmap est utile car, comme nous le verrons, elle permet de constituer une carte de base à laquelle nous pouvons ajouter des éléments cartographiques. Frontières des polygones Fonction tm_borders() La fonction tm_borders() permet dillustrer les frontières des polygones: # frontiere des regions admin tm_shape(Q) + tm_borders() La fonction tm_borders() peut sutiliser conjointement avec la fonction tm_fill(): # Quebec + frontiere tm_shape(Q) + tm_fill() + tm_borders() Fonction tm_polygons() Par ailleurs, la fonction tm_polygons() est équivalente lutilisation conjointe de tm_borders() et tm_fill(): # tm_polygons = tm_fill + tm_borders tm_shape(Q) + tm_polygons() Paramètres esthétiques Les fonctions tm_borders() et tm_fill() possèdent plusieurs arguments pour ajuster lapparence de la carte. Voici des exemples: # couleur des polygones Q1 &lt;- tm_shape(Q) + tm_fill(col=&quot;green&quot;) # transparence Q2 &lt;- tm_shape(Q) + tm_fill(col=&quot;green&quot;, alpha = 0.4) # couleur des frontières Q3 &lt;- tm_shape(Q) + tm_borders(col=&quot;green&quot;) # épaisseur du trait Q4 &lt;- tm_shape(Q) + tm_borders(col=&quot;pink&quot;, lwd = 4) # type de trait Q5 &lt;- tm_shape(Q) + tm_borders(col=&quot;blue&quot;, lty = 2) # couleur des polygones et des frontières Q6 &lt;- tm_shape(Q) + tm_fill(col=&quot;blue&quot;, alpha = 0.3) + tm_borders(col=&quot;black&quot;) tmap_arrange(Q1,Q2,Q3,Q4,Q5,Q6) FIGURE 6.28: Cette figure est inspirée de la figure 9.3 du livre Geocomputation with R (Lovelace, Nowosad, and Muenchow 2021). Attributs des polygones La création de cartes, à partir de données vectorielles de type polygone, nécessite parfois de colorer individuellement les polygones. Par exemple, la couleur dun polygone peut représenter la valeur dun de ses attributs. Dans ce cas, nous utilisons la fonction tm_fill() en associat à largument col le nom de l`attribut que nous désirons illustrer. tm_shape(Q) + tm_fill(col=&quot;NUM_REG&quot;, title = &quot;Régions&quot;) Dans le cas ci-dessus, lattribut illustré (NUM_REG) est catégorique et distinct pour chaque polygone. Nous pouvons aussi choisir dillustrer un seul des polygones dun shapefile. Dans un tel cas, nous devons isoler le polygone désiré et nillustrer que ce dernier avec la fonction tm_shape(). Par exemple, isolons le polygone correspondant à la région de lOutaouais: Q_Outaouais &lt;- Q[Q$NOM_REG == &quot;Outaouais&quot;,] tm_shape(Q_Outaouais) + tm_fill(col=&quot;blue&quot;, alpha = 0.4) Nous pouvons également vouloir mettre lemphase sur un polygone en particulier, en assignant une couleur seulement à celui-ci, tout en cartographiant lensemble des polygones. Dans ce cas, nous pouvons utiliser le caractère additif des objets tmap. Nous créons un premier objet représentant lensemble des polygones et nous lui additionnons un deuxième objet représentant le polygone que nous souhaitons mettre en évidence. # Une option Q1 &lt;- tm_shape(Q) + tm_borders(col=&quot;black&quot;) Q2 &lt;- tm_shape(Q_Outaouais) + tm_fill(col=&quot;blue&quot;, alpha = 0.4) Q12 &lt;- Q1 + Q2 # Une autre option Q3 &lt;- tm_shape(Q) + tm_fill() Q4 &lt;- tm_shape(Q_Outaouais) + tm_borders(col=&quot;blue&quot;, lwd = 4) Q34 &lt;- Q3 + Q4 tmap_arrange(Q12,Q34) Remarquer lusage de la fonction tmap_arrange() pour afficher des cartes côte-à-côte. 6.1.5 Spécificités cartographiques Barre déchelle et rose des vents Fonctions tm_scale_bar() et tm_compass Lajout dun barre déchelle et dune rose des vents, se fait par lutilisation des fonctions tm_scale_bar() et tm_compass() respectivement: map_Q + # la carte du Québec que nous avons créée plus haut # ajout d&#39;une barre d&#39;échelle tm_scale_bar(breaks = c(0,250,500), text.size = 0.8, position=c(&quot;right&quot;,&quot;bottom&quot;)) + # ajout d&#39;une rose des vents tm_compass(type = &quot;arrow&quot;, position = c(&quot;right&quot;, &quot;top&quot;)) où largument break précise les divisions sur la barre déchelle, text.size la taille du texte sous la barre, et position la position de la barre sur la carte (gauche ou droite, haut ou bas). Plusieurs options darguments sont possibles. Utilisez help(tm_scale_bar) ou help(tm_compass) pour connaître les autres arguments possibles pour ces fonctions. Par exemple, map_Q + tm_scale_bar(width = 2, position=c(&quot;right&quot;,&quot;bottom&quot;)) + tm_compass(type = &quot;4star&quot;, size = 2, show.labels = 2, position = c(&quot;right&quot;, &quot;top&quot;)) Scale bar width set to 0.25 of the map width Grille et graticules Fonctions tm_grid() et tm_borders() La fonction tm_grid() ajoute une grille à la carte selon le système de coordonnées projetées des données. Dans le cas présent, le shapefile Q est exprimé dans le système de coordonnées projetée Conique conforme de Lambert (epsg:32198) qui est métrique. La fonction tm_graticules ajoute les lignes de longitude et de latitude du système de coordonnées géographiques, cest-à-dire non-projetées. Dans le cas présent, le shapefile Q est exprimé dans le système de coordonnées géographiques du Datum North Américain de 1983 (NAD83, espg:4269). Q1 &lt;- map_Q + tm_grid() Q2 &lt;- map_Q + tm_graticules() tmap_arrange(Q1,Q2) Plusieurs options darguments existent pour les fonctions tm_grid() et tm_graticules(). Par exemple, il est possible de préciser le nombre de divisions sur laxe des x (n.x) et sur laxe des y (n.y)42, lépaisseur du trait (lwd), la couleur (col) ou encore la taille de lécriture (labels.size). Q1 &lt;- map_Q + tm_grid(labels.size=0.5, col=&quot;yellow&quot;, lwd=3, n.x = 10, n.y = 4) Q2 &lt;- map_Q + tm_graticules(labels.col = &quot;darkblue&quot;, alpha = 0.3, labels.cardinal = FALSE) tmap_arrange(Q1,Q2) Attribuer les crédits ou la source des données Fonction tm_credits() Il faut utiliser la fonction tm_credits() pour ajouter à la carte une mention sur la source des données, ou toute autre information comme lauteur ou lautrice de la carte et son organisation dattache. Par défaut, la mention apparaît dans le coin inférieur droit. map_Q + tm_credits(&quot;Données récupérées \\nsur le site donneesquebec.ca&quot;, size = 0.6) 6.1.6 Mise en page Fonction tm_layout() La fonction tm_layout permet dajuster la mise en page dune carte et différents éléments de son esthétique. Pour découvrir lensemble des arguments possibles tapez la commande help(tm_layout) (ou ?tm_layout) dans votre console R. Plusieurs des arguments utiles sont présentés ci-dessous. Titre, cadre et couleur du fond Lajout dun titre (title), la taille de ce dernier (title.size) et sa position (title.position). La présence ou labsence dun cadre (frame) et lépaisseur du trait de celui-ci (frame.lw). La taille des marges extérieures au cadre: outer.margins = c(Haut,Droit,Bas,Gauche) où Haut, Droit, Bas, Gauche sont des chiffres entre 0 (pas de marge) et 1 (marge complète). La couleur du fond de la carte (bg.color) et de lespace à lextérieure du cadre (outer.bg.color). Voici quelques exemples de mise en page qui utilisent ces arguments. # Création d&#39;une carte générale map_Q &lt;- tm_shape(Q) + tm_fill() + tm_borders() # Différentes options de mise en page map_Q + tm_layout(title = &quot;Carte du Québec&quot;, title.size =0.8, title.position = c(&quot;right&quot;,&quot;top&quot;)) map_Q + tm_layout(frame = FALSE) map_Q + tm_layout(bg.color = &quot;aquamarine&quot;, scale = 2) map_Q + tm_layout(frame.lwd = 2, outer.margins = c(0, 0.2,0, 0.2), outer.bg.color=&quot;lavender&quot;) Légende La fonction tm_layout() permet aussi de configurer lapparence de la légende. Certains des arguments utiles sont: La présence, ou non, dune légende (legend.show). Par défaut la légende est affichée. Loption de placer la légende à lextérieur du cadre de la figure (legend.outside). La position de la légende à lintérieur (legend.position) ou à lextérieur (legend.outside.position) du cadre. Par défaut,la légende est placée dans le coin où il y a le plus despace. Loption de mettre un cadre autour de la légende (legend.frame) et de définir lépaisseur du trait (legend.frame.lwd) et la couleur de fond de la légende (legend.bg.color) La police de caractère (legend.title.fontfamily), la taille des caractères (legend.title.fontface), et la couleur (legend.title.color) du texte et du titre de la légende. Voici quelques exemples de mise en page de la légende: tm_shape(Q) + tm_polygons(col = &quot;NOM_REG&quot;) + tm_layout(legend.show = FALSE) tm_shape(Q) + tm_polygons(col = &quot;NUM_REG&quot;, title = &quot;Régions administratives&quot;, legend.is.portrait = FALSE) + tm_layout(frame = FALSE, legend.outside = TRUE, legend.outside.position = &quot;bottom&quot;, legend.outside.size = 0.15, legend.text.size = 0.75) tm_shape(Q) + tm_fill(col = &quot;NOM_REG&quot;, title = &quot;Régions administratives&quot;) + tm_layout(legend.outside = TRUE) tm_shape(Q) + tm_fill(col=&quot;NOM_REG&quot;, title = &quot;Régions administratives&quot;) + tm_layout(bg.color = &quot;black&quot;, frame = FALSE, legend.outside = TRUE, legend.outside.position = &quot;left&quot;, legend.title.fontfamily = &quot;serif&quot;, legend.title.fontface = 2, legend.title.color = &quot;lightpink&quot;, legend.text.color = &quot;white&quot;) Ajustement des couleurs De plus, la fonction tm_layout permet dajuster les couleurs présentes dans la carte: Largument aes.color défini la couleur de remplissage des polygones, des frontières, du texte, etc. Largument saturation défini le niveau de saturation des couleurs. La valeur par défaut est 1, et la valeur 0 donne une représentation en noir et blanc. Il est possible de donner des valeurs supérieures à 1 pour des couleurs très saturées. Il est aussi possible de données des valeurs négatives. Largument sepia.intensity est un nombre entre 0 et 1 qui défini le niveau de chaleur des couleurs. Plus sa valeur est grande, plus les couleurs ont une teinte jaune voir brune. La valeur par défaut est 0. Largument aes.palette permet de changer la palette de couleurs utilisées. La librarie tmap utilise les palettes de couleurs de Color Brewer. Dans le cas dattributs catégoriques (comme le nom de régions) la palette utilisée par défaut se nomme Set3, mais il est possible de choisir dautres palettes parmi celles-ci: Accent, Dark2, Paired, Pastel1, Pastel2, Set1, et Set2. Nous reviendrons sur le sujet des palettes un peu plus loin dans cete leçon. Voici quelques exemples de modification des couleurs: Q1 &lt;- tm_shape(Q) + tm_polygons() + tm_layout(aes.color = c(fill=&quot;lightblue&quot;,borders=&quot;darkgreen&quot;)) Q2 &lt;- tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;) + tm_layout(legend.show = FALSE, aes.color = c(borders=&quot;white&quot;), saturation = 0) Q3 &lt;- tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;) + tm_layout(legend.show = FALSE, sepia.intensity = 0.5) Q4 &lt;- tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;) + tm_layout(legend.show = FALSE, aes.palette = list(cat = &quot;Accent&quot;)) Styles prédéfinis Fonction tm_style() La librarie tmap contient des styles prédéfinis quon appelle avec la fonction tm_style et qui permettent de ne pas avoir à définir individuellement des arguments de la fonction tm_layout. Voici quelques uns de ces styles prédéfinis. tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;) + tm_style(&quot;classic&quot;) + tm_layout(legend.show = FALSE) tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;) + tm_style(&quot;bw&quot;) + tm_layout(legend.show = FALSE) tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;) + tm_style(&quot;cobalt&quot;) + tm_layout(legend.show = FALSE) tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;) + tm_style(&quot;col_blind&quot;) + tm_layout(legend.show = FALSE) Vous remarquerez que le style col_blind utilise une palette de couleur permettant aux personnes daltoniennes de pouvoir différencier les polygones de couleurs différentes. 6.1.7 Écriture sur une carte Fonction tm_text() La fonction tm_text() permet décrire sur chaque polygone la valeur dun de ses attributs. Par exemple, nous pouvons ajouter le numéro de la région administrative sur chaque polygone: tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;) + tm_style(&quot;col_blind&quot;) + tm_layout(legend.show = FALSE, frame = FALSE)+ tm_text(&quot;NUM_REG&quot;, size = 0.6, fontface=&quot;bold&quot;) Ou encore: tm_shape(Q) + tm_polygons() + tm_layout(aes.color = c(fill=&quot;black&quot;,borders=&quot;white&quot;), bg.color = &quot;black&quot;, frame = FALSE, legend.bg.color = TRUE, legend.outside = TRUE, legend.text.size = 0.8, legend.text.color = &quot;white&quot;, legend.title.color = &quot;white&quot;) + tm_text(&quot;NUM_REG&quot;, col= &quot;NOM_REG&quot;, palette = &quot;Paired&quot;, size = 0.8, fontface=&quot;bold&quot;, legend.col.show = TRUE, title.col = &quot;Régions administratives&quot;, auto.placement=TRUE, just=&quot;right&quot;) 6.1.8 Les lignes Données sur le réseau routier du Québec Pour explorer les options daffichage de données vectorielles de types ligne et multiligne, nous utilisons le shapefile du réseau des routes du Québec. Chargeons ces données dans notre session de travail R avec la fonction st_read(): Ro &lt;- st_read(&quot;Module6/Module6_donnees/Routes/QC_routes.shp&quot;) Reading layer `QC_routes&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module6\\Module6_donnees\\Routes\\QC_routes.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 223 features and 2 fields Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: -822900 ymin: 118000 xmax: 526000 ymax: 983200 Projected CRS: NAD83 / Quebec Lambert Observer la structure et les attributs du shapefile Ro. Celui-ci contient 223 multilignes et 2 attributs autres que la géométrie: NoRte: le numéro de la route, ClsRte: la classe de la route. En particulier, il existe trois classes possibles de route: Ro$ClsRte &lt;- as.factor(Ro$ClsRte) levels(Ro$ClsRte) [1] &quot;Autoroute&quot; &quot;Nationale&quot; &quot;Régionale&quot; Fonction tm_lines() La bibliothèque tmap possède une fonction particulière pour illustrer des objects vectoriels de type ligne et multigne. Il sagit de la fonction tm_lines(). Celle-ci doit être ajouter à la fonction tm_shape(L) où L est un shapefile contenant des objets de géométrie ligne ou multiligne. Illustrons les multilignes du shapefile Ro: tm_shape(Ro) + tm_lines() Pour superposer la carte des routes sur la carte du Québec, nous utilisons la propriété additive des objets tmap. tm_shape(Q) + tm_fill() + tm_shape(Ro) + tm_lines(col=&quot;brown&quot;) + tm_layout(title = &quot;Réseau routier&quot;) Notez que chaque fois quon ajoute un nouvel ensemble de données à cartographier en utilisant tm_shape(nouvelles_donnees), les fonctions tm_fonctions() qui suivent sappliquent à ces nouvelles données et non aux données antérieures. Pour représenter différemment les objets de type ligne en fonction de la valeur dun de leur attribut, nous pouvons utiliser largument col dans la fonction tm_lines: # créons une palette de trois couleurs pal.col&lt;-c(&quot;red&quot;,&quot;darkgoldenrod4&quot;,&quot;darkslateblue&quot;) tm_shape(Q) + tm_fill() + tm_shape(Ro) + tm_lines(col = &quot;ClsRte&quot;, palette = pal.col, title.col = &quot;Types de route&quot;) 6.1.9 Les points Coordonnées des municipalités du Québec Pour explorer les options daffichage de données vectorielles de types point et multipoint, nous utilisons le shapefile des coordonnées géographiques de quelques municipalités du Québec. Chargeons ces données dans notre session de travail R avec la fonction st_read(): V &lt;- st_read(&quot;Module6/Module6_donnees/Villes/QC_coord_municipalites.shp&quot;) Reading layer `QC_coord_municipalites&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module6\\Module6_donnees\\Villes\\QC_coord_municipalites.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 15 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -78.91 ymin: 45.41 xmax: -64.47 ymax: 62.41 Geodetic CRS: NAD83 Ce shapefile compte 15 objets de type point et un seul attribut (Mncplts) correspondant au nom de la municipalité qui lui est associée. La bibliothèque tmap comprend plusieurs fonctions permettant de représenter des données de type point. Familiarisons-nous dabord avec les fonctions tm_dots() et tm_markers(). Nous verrons plus loin les fonctions tm_bubbles() et tm_symbols(). Fonction tm_dots() La fonction tm_dots() fonctionne de façon similaire aux fonctions tm_polygons() et tm_lines(). Il suffit de lajouté à la fonction tm_shape(P) où P est un shapefile de types point ou multipoint. # Juste les points Q1 &lt;- tm_shape(V) + tm_dots() # Les points et la carte du QC Q2 &lt;- tm_shape(Q) + tm_fill(col = &quot;blue&quot;, alpha = 0.4) + tm_shape(V) + tm_dots(col = &quot;darkblue&quot;, size = 1) # tmap_arrange(Q1,Q2) Nous pouvons également définir la couleur des points en fonction de la valeur de leur attribut. tm_shape(Q) + tm_fill() + tm_shape(V) + tm_dots(col = &quot;Mncplts&quot;, palette = &quot;Paired&quot;, size = 1) + tm_layout(frame = FALSE, legend.outside = TRUE, title = &quot;Municipalités&quot;, legend.title.color = NA, legend.text.size = 0.8) Fonction tm_markers() La fonction tm_markers() représente les points par le symbole de repère géographique: tm_shape(Q) + tm_fill() + tm_shape(V) + tm_markers(size = 0.5, text = &quot;Mncplts&quot;, text.size = 0.8, text.just = &quot;top&quot;) + tm_layout(inner.margins = c(0.1,0.2,0.1,0.2)) La fonction tm_markers() permet dajouter du texte facilement sur les repères et contient des arguments similaires à la fonction tm_text(). 6.1.10 Données matricielles Données délévation du Québec Pour explorer les options daffichage de données matricielles, nous utilisons un raster représentant le relief du territoire québecois sous forme dune matrice délévation. Chargeons ces données dans notre session de travail R avec la fonction raster(). Nous devons prélablement charger la bibliothèque raster: library(raster) E &lt;- raster(&quot;Module6/Module6_donnees/Elevation/QC_Elevation.tif&quot;) Le raster E est une matrice de 810612 cellules, et chacune de ces cellules a une résolution denviron 2 km par 2 km. La valeur maximale délévation est de 1592 m. Fonction tm_raster() La fonction tm_raster() de la bibliothèque tmap permet de visualiser les rasters en assignant des couleurs différentes pour des classes de valeurs différentes. Largument n sert à préciser le nombre approximatif de classes à utiliser. tm_shape(E) + tm_raster(title = &quot;Élévation (m)&quot;) tm_shape(E) + tm_raster(n = 10, title = &quot;Élévation (m)&quot;) Il est possible dafficher en légende un histogramme illustrant la distribution des valeurs. Par exemple: tm_shape(E) + tm_raster(n = 10, title = &quot;Élévation (m)&quot;, legend.hist = TRUE) + tm_legend(outside = TRUE, hist.width = 4) Par défaut, la palette de couleur utilisée est la palette séquentielle YlOrBr de ColorBrewer (de jaune à brun en passant par orange). Or, nous pouvons changer la palette de couleur. Utilisons, par exemple, la fonction colorRampPalette() pour créer notre propre palette de couleur. pal.elevation = colorRampPalette( c(&quot;midnightblue&quot;,&quot;forestgreen&quot;, &quot;darkolivegreen4&quot;,&quot;burlywood&quot;, &quot;chocolate4&quot;)) tm_shape(E) + tm_raster(n = 10, title = &quot;Élévation&quot;, palette = pal.elevation(10), legend.hist = TRUE, colorNA = &quot;beige&quot; ) + tm_legend(outside = TRUE, hist.width = 3) Il existe différentes façons de former des classes de valeur à partir de la distribution. Largument style de la fonction tm_raster() permet de choisir une méthode parmi plusieurs dont les suivantes: \"fixed\": crée des classes de valeurs selon notre propre choix. Ces classes doivent être définies dans un vecteur assigné à largument breaks. \"equal\": divise les valeurs en n classes. Ceci est la méthode par défaut. \"pretty\": choisi automatiquement le nombre de classes qui permet de distinguer les valeurs dans un rendu esthétique. \"quantile\": divise les valeurs en quantiles. \"jenks\": utilise lalgorithme de Jenks pour déterminer le nombre optimal de classes. Visualisons à nouveau la carte des données délévation en utilisant un style fixed et un style quantile: # définir la mise en page pour les deux cartes format_carte &lt;- tm_layout(frame = FALSE, legend.position = c(0.67,0.04), legend.title.size = 0.8, legend.format=c(text.align=&quot;right&quot;), legend.bg.color = &quot;white&quot;, legend.frame = &quot;black&quot;) # style fixed. Efixed &lt;- tm_shape(E) + tm_raster(title = &quot;Élévation(m)&quot;, palette = pal.elevation(10), style = &quot;fixed&quot;, breaks = c(0,100,200,300,400,500,600,700,800,900,1000,1600)) + format_carte # style quantile Equant &lt;- tm_shape(E) + tm_raster(title = &quot;Élévation(m)&quot;, palette=pal.elevation(10), style=&quot;quantile&quot;) + format_carte tmap_arrange(Efixed,Equant) 6.1.11 Carte avec symboles proportionnels Dans des cartes thématiques, il est souvent utile de représentées certains attributs par des symboles proportionnels. Les fonctions tm_symbols() et tm_bubbles() de la bibliothèque tmap sont utiles pour réaliser ce type de cartes. Fonction tm_symbols() La fonction tm_symbols() est similaire à la fonction tm_dots() mais ne sutilise pas nécessairement avec des données vectorielles de type points. En particulier, elle permet de représenter la valeur dattribut dun polygone en affichant un symbole dont la taille ou la couleur est proportionnelle à cette valeur. En guise dexemple, reprenons les données sur les régions administratives du Québec pour lesquelles nous connaissons la taille de la population. Nous pouvons illustrer les régions par un cercle dont le diamètre est proportionnel à la taille de sa population. Il sagit dattribuer à largument size, le nom de lattribut que nous souhaitons représenter. tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;, legend.show = FALSE) + tm_style(&quot;bw&quot;) + tm_symbols(col = &quot;black&quot;, size = &quot;Pop_tot&quot;, legend.size.show = TRUE, legend.size.is.portrait = TRUE, title.size = &quot;Population&quot;) Par défaut, le symbole utilisé est un point. Le point correspond au symbole shape = 21. Nous pouvons toutefois utiliser dautres symboles comme le carré (shape = 15), ou le repère géographique (shape = marker_icon()). Vous pouvez même importer vos propres symboles. carte_base &lt;- tm_shape(Q) + tm_polygons(col=&quot;NUM_REG&quot;, legend.show = FALSE) + tm_style(&quot;bw&quot;) carte_carre &lt;- carte_base + tm_symbols(shape = 15, col = &quot;red&quot;, size = &quot;Pop_tot&quot;, legend.size.show = TRUE, legend.size.is.portrait = TRUE, title.size = &quot;Population&quot;) carte_marqueur &lt;- carte_base + tm_symbols(shape = marker_icon(), border.col = NULL, size = &quot;Pop_tot&quot;, legend.size.show = TRUE, legend.size.is.portrait = TRUE, title.size = &quot;Population&quot;) tmap_arrange(carte_carre, carte_marqueur) Représenter deux légendes Lorsque nous utilisons des symboles proportionnels, nous devons souvent avoir plus dune légende. Par exemple, dans les cartes précédentes, nous avions seulement une légende se rapportant à la taille des populations mais aucune légende pour identifier les régions. Pour ajouter deux légendes (ou plus), nous devons utiliser la fonction tm_layout() avec largument legend.stack qui précise si les légendes seront disposées de façon verticale ou horizontale. tm_shape(Q) + tm_polygons(col=&quot;NOM_REG&quot;, palette=&quot;Set1&quot;, border.col = &quot;darkgrey&quot;, title =&quot;Régions administratives&quot;) + tm_symbols(size = &quot;Pop_tot&quot;, border.col = &quot;grey&quot;, col=&quot;black&quot;, scale = 2, legend.size.show = TRUE, legend.size.is.portrait = FALSE, sizes.legend.labels = c(&quot;500&quot;,&quot;1000&quot;,&quot;1500&quot;,&quot;2000&quot;,&quot;2500&quot;), title.size =&quot;Population (en milliers)&quot;) + tm_layout(frame = FALSE, legend.outside = TRUE, legend.stack = &quot;vertical&quot;, legend.title.fontface = &quot;bold&quot; ) Fonction tm_bubbles() La fonction tm_bubbles() est similaire à la fonction tm_symbols() et sutilise lorsquon souhaite seulement représenter des symboles sous forme de cercle/point. Cette fonction est pratique lorsque nous voulons représenter deux attributs avec un symbole: le premier attribut est représenté par la taille du cercle et le second attribut par sa couleur. Utilisons à nouveau les données sur la taille des populations des régions administratives. Par exemple, représentons chaque région par un cercle dont le diamètre est proportionnel à la taille totale de sa population (comme nous lavons fait plus haut). De plus, colorons chaque cercle en fonction de la proportion denfants (individus agés entre 0 et 14 ans) dans sa population. Tout dabord, nous devons calculer la proportion denfants dans chaque région. Pour le moment, nous connaissons seulement le nombre denfants (A0.14_T). Créons un nouvel attribut pour le shapefile Q: Q$Pop_prop_enfant &lt;- Q$Pop_0_14/Q$Pop_tot Utilisons maintenant la fonction tm_bubbles() en définissant largument size par lattribut \"ATot_T\", et largument col par lattribut \"Pop_prop_enfant\": tm_shape(Q) + tm_polygons(col = &quot;NUM_REG&quot;, legend.show = FALSE, palette = &quot;Greys&quot;) + tm_bubbles(size = &quot;Pop_tot&quot; , col = &quot;Pop_prop_enfant&quot;, style = &quot;quantile&quot;, scale = 2, border.col = &quot;black&quot;, border.lwd = .5, legend.size.show = TRUE, legend.size.is.portrait = FALSE, title.size =&quot;Population (en milliers)&quot;, title.col = &quot;Proportion d&#39;enfants (0-14 ans)&quot;, sizes.legend.labels = c(&quot;500&quot;,&quot;1000&quot;,&quot;1500&quot;,&quot;2000&quot;,&quot;2500&quot;))+ tm_layout(frame = FALSE, legend.outside = TRUE, legend.title.size = 1) Largument style est utilisé pour définir les classes de couleurs. Ici, nous avons choisi une classification en quantile. Noter que nous pouvons définir un titre pour la légende des tailles (title.size) et un titre pour la légende des couleurs (title.col). Remarquer que cette figure nous permet dobserver que la proportion denfants au Nunavik est très grande malgré que la taille de la population soit petite. 6.1.12 Cartes Choroplèthes Les cartes choroplèthes sont utilisées pour représenter des données vectorielles de type polygone en assignant une couleur à chaque polygone en fonction de la valeur dun de ces attributs. Pour créer des cartes choroplèthes, nous utilisons largument col de la fonction tm_polygons(). Lassignation des couleurs se fait de la même façon que pour tm_raster() et tm_bubbles() en définissant des classes de valeur dattribut. Créons des cartes choroplèthes de la proportion denfants dans les régions administratives en utilisant différentes classifications de couleurs. # Par defaut, nous avons 4 classes Qdefaut &lt;- tm_shape(Q) + tm_polygons(col = &quot;Pop_prop_enfant&quot;) # style fixed. Qfixed &lt;- tm_shape(Q) + tm_polygons(col = &quot;Pop_prop_enfant&quot;, style = &quot;fixed&quot;, breaks = c(0.1, 0.14, 0.15, 0.16, 0.18, 0.3)) # style quantile Qquant = tm_shape(Q) + tm_polygons(col = &quot;Pop_prop_enfant&quot;, style = &quot;quantile&quot;) tmap_arrange(Qdefaut,Qfixed,Qquant) Legend labels were too wide. The labels have been resized to 0.6, 0.6, 0.6, 0.6, 0.6. Increase legend.width (argument of tm_layout) to make the legend wider and therefore the labels larger. 6.1.13 Cartes à panneaux multiples Fonction tm_facets() Il est parfois utile illustrer des polygones côte-à-côte afin de faciliter la comparaison dun de leurs attributs. On appelle les cartes des polygones individuellement représentés des panneaux. Pour créer une carte à panneaux multiples, nous utilisons dabord la fonction tm_polygons() pour représenter chaque polygone selon la méthode de notre choix (par exemple selon une représentation choroplèthe dun des attributs). Ensuite, nous ajoutons la fonction tm_facets() pour préciser la disposition des panneaux (arguments nrow ou ncol) ainsi que lattribut utilisé (la facette) pour distinguer chaque panneau (argument by). Représentons à nouveau les polygones des régions administratives selon la proportion denfants dans leur population mais cette fois en créant une carte à panneaux multiples: tm_shape(Q) + tm_polygons(col = &quot;Pop_prop_enfant&quot;, style = &quot;quantile&quot;) + tm_facets(by = &quot;NOM_REG&quot;, nrow = 5, scale.factor = 5) + tm_layout(panel.label.height = 2, panel.label.size = 0.9, legend.show = FALSE) Largument scale.factor détermine la mise à léchelle du texte par rapport à la mise à léchelle des polygones. Les polygones ont été réduits de taille pour entrer dans leur panneau, toutefois nous souhaitons que le titre apparaissant dans la partie supérieure du panneau ne soit pas réduit autant. Il est possible de modifier la police du texte, sa couleur, la couleur de fond des panneaux, le cadre des panneaux, et plus, en utilisant les arguments de la fonction tm_layout(). 6.1.14 Cartes avec encadré Il est parfois nécessaire daccompagner une carte par une autre carte de taille moindre circonscrite dans un encadré sur ou en marge de la carte principale. Ceci est le cas, par exemple, lorsque nous souhaitons préciser la localisation de la carte principale dans une région plus grande. Bibliothèque grid Pour réaliser une carte avec un encadré, nous devons utiliser la bibliothèque grid. Commençons par installer cette bibliothèque: install.packages(&quot;grid&quot;) En guise dexemple, considérons une section du raster délévation E correspondant à la région de lOutaouais. Vous navez pas besoin de comprendre les opérations ci-dessous car nous les apprendrons dans les modules 7 et 8. # Isoler le polygone de l&#39;Outaouais Q_Outaouais &lt;- subset(Q, NOM_REG == &quot;Outaouais&quot;) # Découper le raster E selon l&#39;étendue de Q_Outaouais E_Outaouais &lt;- crop(E, extent(Q_Outaouais)) # Créer un mask E_Outaouais &lt;- mask(E_Outaouais, Q_Outaouais) Créons dabord une carte des données délévation pour la région de lOutaouais. Cette carte consituera notre carte principale. # Définir la carte principale carte_princ &lt;- tm_shape(E_Outaouais) + tm_raster(title = &quot;Élévation (m)&quot;, palette = pal.elevation(5)) + tm_scale_bar(position = c(&quot;left&quot;,&quot;bottom&quot;), text.size = 0.6) # Mise en page de la carte format_carte &lt;- tm_layout(frame = FALSE, legend.outside = TRUE, legend.outside.position = &quot;right&quot;, legend.title.size = 0.8, legend.bg.color = &quot;white&quot;, legend.frame = &quot;black&quot;) Créons maintenant une carte du Québec qui délimite la région de lOutaouais par des frontières de couleur rouge. Cette carte sera lencadré à insérer sur la carte principale. # Définir la carte encadré carte_cadre &lt;- tm_shape(Q) + tm_borders(col = &quot;black&quot;) + tm_shape(Q_Outaouais) + tm_borders(lw=2, col=&quot;red&quot;) Nous pouvons enfin combiner les deux cartes ensembles. Il sagit dafficher la carte principale et dajouter la carte encadré en utilisant la fonction print(). En particulier, nous utilisons la fonction viewport() de la bibliothèque grid qui permet de définir la position de la carte encadré sur la carte ainsi que sa taille. library(grid) carte_princ + format_carte print(carte_cadre, vp = viewport(0.72, 0.42, width = 0.4, height = 0.4)) Les chiffres (0.72,0.42) correspondent aux coordonnées (x,y) de la position de la carte encadrée sur la carte principale (où (0,0) est le coin inférieur gauche de la carte principale, et (1,1) est le coin supérieur droit). Les arguments width et height sont des nombres entre 0 et 1. Ceux-ci correspondent au facteur par lequel nous souhaitons réduire la largeur et la hauteur de la carte encadrée. Les fondements de la sémiologie graphique ont été développés par le cartographe Jacques Bertin qui publia notamment louvrage «Sémiologie Graphique » en 1967. Définition reprise du guide ArcGIS Pro: https://pro.arcgis.com/fr/pro-app/latest/help/mapping/layer-properties/symbolization.htm. Consultez la page Wikipédia pour en apprendre davantage sur les systèmes TSL et TSV. Consulter ce site pour en apprendre davantage sur la cartographie avec ggplot2 Noter que le nombre de divisions créé par tmap est approximativement celui demandé car tmap crée des divisions uniformément espacées situées sur des coordonnées de valeurs entières. "],["ex_carto.html", "6.2 Exercices", " 6.2 Exercices Dans cette section, vous mettrez en pratique certains concepts vus dans la section leçon de ce module. Bien que la réponse à chaque question soit disponible, il est très important de tenter dy répondre par vous même! Cette série dexercices utilise des données comprises avec la bibliothèque tmap. En particulier, vous utiliserez les données World, metro, et land. Charger ces données dans votre session R: data(World) data(metro) data(land) Question 1 a) Quelle est la géométrie des données World, et quels sont leurs attributs? Réponse La géométrie est donnée par la fonction st_geometry() de la bibliothèque sf. st_geometry(World) Geometry set for 177 features Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin: -180 ymin: -89.9 xmax: 180 ymax: 83.65 Geodetic CRS: WGS 84 First 5 geometries: MULTIPOLYGON (((61.21 35.65, 62.23 35.27, 62.98... MULTIPOLYGON (((16.33 -5.877, 16.57 -6.623, 16.... MULTIPOLYGON (((20.59 41.86, 20.46 41.52, 20.61... MULTIPOLYGON (((51.58 24.25, 51.76 24.29, 51.79... MULTIPOLYGON (((-65.5 -55.2, -66.45 -55.25, -66... Les données World sont donc des multipolygones. Chaque multipolygone correspond à un pays de la planète. Nous pouvons connaître le nom des attributs en utilisant la fonction names() names(World) [1] &quot;iso_a3&quot; &quot;name&quot; &quot;sovereignt&quot; [4] &quot;continent&quot; &quot;area&quot; &quot;pop_est&quot; [7] &quot;pop_est_dens&quot; &quot;economy&quot; &quot;income_grp&quot; [10] &quot;gdp_cap_est&quot; &quot;life_exp&quot; &quot;well_being&quot; [13] &quot;footprint&quot; &quot;inequality&quot; &quot;HPI&quot; [16] &quot;geometry&quot; Les différents attributs sont des caractéristiques générales des pays comme leur nom (name), leur continent (continent), leur superficie (area), la taille estimée de leur population (pop_est), la densité estimée de leur population (pop_est_dens), lespérance de vie de leur population (life_exp), etc. b) Déterminer les dix premières entrées des attributs iso_a3 et name des données World. Réponse World[1:10, c(&quot;iso_a3&quot;, &quot;name&quot;)] Simple feature collection with 10 features and 2 fields Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin: -180 ymin: -89.9 xmax: 180 ymax: 49.04 Geodetic CRS: WGS 84 iso_a3 name 1 AFG Afghanistan 2 AGO Angola 3 ALB Albania 4 ARE United Arab Emirates 5 ARG Argentina 6 ARM Armenia 7 ATA Antarctica 8 ATF Fr. S. Antarctic Lands 9 AUS Australia 10 AUT Austria geometry 1 MULTIPOLYGON (((61.21 35.65... 2 MULTIPOLYGON (((16.33 -5.87... 3 MULTIPOLYGON (((20.59 41.86... 4 MULTIPOLYGON (((51.58 24.25... 5 MULTIPOLYGON (((-65.5 -55.2... 6 MULTIPOLYGON (((43.58 41.09... 7 MULTIPOLYGON (((-59.57 -80.... 8 MULTIPOLYGON (((68.94 -48.6... 9 MULTIPOLYGON (((145.4 -40.7... 10 MULTIPOLYGON (((16.98 48.12... Nous comprenons ainsi que lattribut iso_a3 correspond à un code standardisé abrégeant le nom des pays. c) Utiliser le style col_blind pour illustrer la carte du monde. Najouter pas de légende. Réponse tm_shape(World) + tm_polygons(col=&quot;name&quot;) + tm_style(&quot;col_blind&quot;) + tm_layout(legend.show = FALSE) Vous devriez voir afficher un message derreur quant au nombre de pays dépassant le nombre maximal de couleurs pouvant être illustrées. Ceci a peu de conséquences pour cette carte puisque peu de pays adjacents ont la même couleur et que ceux-ci sont délimités par des bordures noires nous permettant de les distinguer. d) Produire une carte identique à la carte de la question c mais représentant uniquement les pays dAfrique. Réponse Isoler le continent africain: Afrique &lt;- World[World$continent == &quot;Africa&quot;,] Produire une carte de lAfrique avec le style col_blind et sans légende. tm_shape(Afrique) + tm_polygons(col=&quot;name&quot;) + tm_style(&quot;col_blind&quot;) + tm_layout(legend.show = FALSE) Notez que la bibliothèque tmap permet de minimiser le nombre de polygones adjacents illustrés avec la même couleur. Pour se faire, il sagit de définir col = MAP_COLORS en argument à la fonction tm_polygons(). tm_shape(Afrique) + tm_polygons(col=&quot;MAP_COLORS&quot;) + tm_style(&quot;col_blind&quot;) + tm_layout(legend.show = FALSE) e) Produire une carte de lAfrique sur laquelle les pays sont identifiés par leur code iso_a3. Réponse Nous reprenons dabord la carte de lAfrique produire en d. Puis, nous ajoutons le code iso_a3 des pays en utilisant la fonction tm_text(): tm_shape(Afrique) + tm_polygons(col=&quot;MAP_COLORS&quot;) + tm_style(&quot;col_blind&quot;) + tm_layout(legend.show = FALSE) + tm_text(&quot;iso_a3&quot;, size = 0.6) f) Produire une carte de lAmérique du Sud où la couleur de chaque pays représente sa densité de population (pop_est_dens). Utiliser le style quantile pour classer les valeurs de densité, et la palette Reds de la bibliothèque RColorBrewer. Assurez-vous que la légende porte le titre Densité de population. Réponse Dans un premier temps, nous devons isoler les pays de lAmérique du Sud. AS &lt;- World[World$continent == &quot;South America&quot;,] Ensuite, nous devons créer la palette de couleur avec la fonction brewer.pal(). Puisque le style quantile sépare les valeurs de densité en cinq classes, la palette doit comprendre cinq couleurs. pal &lt;- brewer.pal(n=5, &quot;Reds&quot;) Nous pouvons maintenant produire la carte: tm_shape(AS) + tm_polygons(col = &quot;pop_est_dens&quot;, palette = pal, style = &quot;quantile&quot;, title = &quot;Densité de population&quot;) g) Produire une carte à panneaux multiples de la densité de population en Amérique du Sud. Votre carte doit comprendre les caractéristiques suivantes: Chaque panneau de la carte doit correspondre à un pays identifié par son nom. La carte doit comprendre quatre rangées de panneaux. Les pays doivent être illustrés avec un facteur déchelle de cinq. Réponse Nous utilisons la fonction tm_facets() pour produire une carte à panneaux multiples: tm_shape(AS) + tm_polygons(col = &quot;pop_est_dens&quot;, palette = pal, style = &quot;quantile&quot;, title = &quot;Densité de population&quot;) + tm_facets(by = &quot;name&quot;, nrow = 4, scale.factor = 5 ) h) Utiliser les arguments de la fonction tm_layout() pour modifier lapparence de la carte à panneaux multiples de la question g. Plus précisément, ajouter les caractéristiques suivantes: Une vignette de hauteur 2 pour chaque facette. Une couleur de fond blanc pour chaque vignette. Un texte de taille 0.9 sur chaque vignette. Une légende encadrée et positionnée à lextérieure à gauche des panneaux. Une légende dont les chiffres sont arrondis à lunité près, et séparés par le symbole -. Réponse Nous devons utiliser les différents arguments de la fonction tm_layout() pour préciser les caractéristiques demandées. tm_shape(AS) + tm_polygons(col = &quot;pop_est_dens&quot;, palette = pal, style = &quot;quantile&quot;, title = &quot;Densité de population&quot;) + tm_facets(by = &quot;name&quot;, nrow = 4, scale.factor = 5 )+ tm_layout(panel.label.height = 2, panel.label.size = 0.9, panel.label.bg.color = &quot;white&quot;, legend.outside = TRUE, legend.outside.position = &quot;left&quot;, legend.format = list(format = &quot;f&quot;, digits = 0, text.separator = &quot;-&quot;), legend.frame = TRUE) Question 2 a) Quelle est la géométrie des données metro, et quels sont leurs attributs? Réponse Nous utilisons la fonction st_geometry() pour connaître la géométrie des données metro: st_geometry(metro) Geometry set for 436 features Geometry type: POINT Dimension: XY Bounding box: xmin: -123.1 ymin: -37.81 xmax: 174.8 ymax: 60.17 old-style crs object detected; please recreate object with a recent sf::st_crs() Geodetic CRS: WGS 84 First 5 geometries: POINT (69.17 34.53) POINT (3.042 36.75) POINT (13.23 -8.837) POINT (-58.4 -34.61) POINT (-64.18 -31.41) Les données metro sont donc composées de points. Les attributs sont donnés par la fonction names(): names(metro) [1] &quot;name&quot; &quot;name_long&quot; &quot;iso_a3&quot; &quot;pop1950&quot; [5] &quot;pop1960&quot; &quot;pop1970&quot; &quot;pop1980&quot; &quot;pop1990&quot; [9] &quot;pop2000&quot; &quot;pop2010&quot; &quot;pop2020&quot; &quot;pop2030&quot; [13] &quot;geometry&quot; Les différents attributs correspondent aux tailles des populations des métropoles du monde à différentes années et leur projection pour lannée 2030. b) Déterminer les dix premières entrées des attributs name et pop2020 des données metro. Réponse metro[1:10, c(&quot;name&quot;,&quot;pop2020&quot;)] old-style crs object detected; please recreate object with a recent sf::st_crs() Simple feature collection with 10 features and 2 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -64.18 ymin: -37.81 xmax: 153 ymax: 40.18 Geodetic CRS: WGS 84 name pop2020 geometry 2 Kabul 5721697 POINT (69.17 34.53) 8 Algiers 2835218 POINT (3.042 36.75) 13 Luanda 6836849 POINT (13.23 -8.837) 16 Buenos Aires 15894307 POINT (-58.4 -34.61) 17 Cordoba 1562509 POINT (-64.18 -31.41) 25 Rosario 1453814 POINT (-60.64 -32.95) 32 Yerevan 1023703 POINT (44.51 40.18) 33 Adelaide 1320783 POINT (138.6 -34.93) 34 Brisbane 2388517 POINT (153 -27.47) 37 Melbourne 4500501 POINT (145 -37.81) c) En utilisant les données metro et World, créer une carte du monde sur laquelle les métropoles sont représentées par un cercle dont le diamètre est proportionnel à la taille de sa population en 2020. La carte doit comprendre les éléments suivants: Chaque métropole est illustrée par un cercle rouge de bordure noire. La légende porte le nom Population. La carte du monde est blanche et seules les frontières noires entre les pays y apparaissent. Réponse Nous utilisons la fonction tm_borders() pour illustrer les frontières des pays, puis, nous utilisons la fonction tm_symbols() pour illustrer les métropoles. tm_shape(World)+ tm_borders(col=&quot;black&quot;)+ tm_shape(metro)+ tm_symbols(col=&quot;red&quot;, border.col = &quot;black&quot;, size = &quot;pop2020&quot;, legend.size.show = TRUE, legend.size.is.portrait = TRUE, title.size = &quot;Population&quot;) Question 3 a) Les données land forment un objet de classe stars. Cest un objet matriciel composé de plusieurs couches dattributs. Déterminer les couches comprises dans land. Réponse Nous utilisons la fonction names() pour déterminer le nom des couches (attributs) des données land: names(land) [1] &quot;cover&quot; &quot;cover_cls&quot; &quot;trees&quot; &quot;elevation&quot; Pour avoir plus dinformations sur lobjet land et connaître les facteurs possibles pour chaque attribut, nous pouvons simplement écrire land dans le terminal R: land stars object with 2 dimensions and 4 attributes attribute(s): cover Water bodies :393060 Snow / Ice : 61986 Herbaceous : 21377 Tree Open : 16171 Sparse vegetation: 12247 Cropland : 11658 (Other) : 66701 cover_cls trees Water :393060 Min. : 0 Snow/ice : 61986 1st Qu.: 0 Forest : 48851 Median : 0 Other natural vegetation : 32611 Mean : 16 Bare area/Sparse vegetation: 26904 3rd Qu.: 19 Cropland : 17843 Max. :100 (Other) : 1945 NA&#39;s :393060 elevation Min. :-412 1st Qu.: 218 Median : 608 Mean :1140 3rd Qu.:1941 Max. :6410 NA&#39;s :389580 dimension(s): from to offset.xmin delta.xmax x 1 1080 -180 0.333333 y 1 540 90 -0.333333 refsys point x/y x +proj=longlat +ellps=WGS8... NULL [x] y +proj=longlat +ellps=WGS8... NULL [y] La couche cover illustre la couverture terrestre et comprend 20 catégories différentes. levels(land$cover) [1] &quot;Broadleaf Evergreen Forest&quot; [2] &quot;Broadleaf Deciduous Forest&quot; [3] &quot;Needleleaf Evergreen Forest&quot; [4] &quot;Needleleaf Deciduous Forest&quot; [5] &quot;Mixed Forest&quot; [6] &quot;Tree Open&quot; [7] &quot;Shrub&quot; [8] &quot;Herbaceous&quot; [9] &quot;Herbaceous with Sparse Tree/Shrub&quot; [10] &quot;Sparse vegetation&quot; [11] &quot;Cropland&quot; [12] &quot;Paddy field&quot; [13] &quot;Cropland / Other Vegetation Mosaic&quot; [14] &quot;Mangrove&quot; [15] &quot;Wetland&quot; [16] &quot;Bare area,consolidated (gravel,rock)&quot; [17] &quot;Bare area,unconsolidated (sand)&quot; [18] &quot;Urban&quot; [19] &quot;Snow / Ice&quot; [20] &quot;Water bodies&quot; La couche cover_cls illustre de façon simplifiée la couverture terrestre en regroupant les 20 catégories précédentes en 8 catégories différentes. levels(land$cover_cls) [1] &quot;Forest&quot; [2] &quot;Other natural vegetation&quot; [3] &quot;Cropland&quot; [4] &quot;Wetland&quot; [5] &quot;Bare area/Sparse vegetation&quot; [6] &quot;Urban&quot; [7] &quot;Snow/ice&quot; [8] &quot;Water&quot; La couche trees illustre le pourcentage de couverture forestière par pixel. Finalement, la couche elevation représente lélévation en mètres. b) Utiliser la palette de couleur Greens de la bibliothèque RColorBrewer pour produire une carte du pourcentage de couvert forestier. De plus, la carte doit comprendre les éléments suivants: Six classes de pourcentage de couvert. Un titre principal Pourcentage de courvert forestier de taille 1. Une légende extérieure à la carte, située sous la carte, horizonale et sans titre. Une légende dont les chiffres sont séparés par le symbole -. Réponse Nous utilisons la fonction tm_raster() pour illustrer la couche trees de lobjet land. De plus, nous utilisons la fonction brewer.pal() de la bibliothèque RColorBrewer pour définir la palette de couleur. Finalement, nous utilisons les arguments de la fonction tm_layout() pour spécifier les éléments demandés. pal = brewer.pal(n=6, &quot;Greens&quot;) tm_shape(land) + tm_raster(&quot;trees&quot;, palette = pal, title = &quot;&quot;, legend.is.portrait = FALSE) + tm_layout(main.title = &quot;Pourcentage de couvert forestier&quot;, main.title.size = 1, legend.outside = TRUE, legend.outside.position = &quot;bottom&quot;, legend.format = list(text.separator = &quot;-&quot;)) "],["manip_vec.html", "Module 7 Manipulation de données vectorielles", " Module 7 Manipulation de données vectorielles Lobjectif principal de ce module est dapprendre à manipuler des données vectorielles. À la fin de ce module vous saurez: Ajouter de nouveaux attributs à des données vectorielles, et également supprimer ou éditer des attributs. Filtrer des données vectorielles en se basant sur leurs attributs. Joindre spatialement deux ensembles de données vectorielles. Extraire un sous-ensemble de données pour lintégrer aux attributs dun second ensemble de données spatiales. Combiner, aggréger et simplifier des objets vectoriels. Transformer la géométrie dobjets vectoriels. Créer des zones tampons autour dobjets vectoriels. Trouver le centroid et les coordonnées dobjets vectoriels. Faire des opérations topologiques sur des objets vectoriels (union, intersection, différence) Confirmer des relations topologiques entre deux objets vectoriels. Calculer des mesures spatiales sur des objets vectoriels (distance, longueur, superficie). Vous utiliserez les bibliothèques suivantes: sf mapview units Vous apprendrez à utiliser les fonctions suivantes: subset() st_coordinates() class() merge() st_join() st_simplify() st_area() set_units() st_buffer() st_intercepts() rowSums() lengths() st_is_longlat() Vous utiliserez les données suivantes: Dans la section leçon, vous utiliserez des données vectorielles portant sur les municipalités du Québec, sur les régions administratives du Québec et sur les parcs nationaux de la Société des établissements de plein air du Québec (SÉPAQ). Dans la section exercices, vous mettrez en pratique les manipulations vues dans la leçon en utilisant les mêmes données. "],["lecon_manip_vec.html", "7.1 Leçon", " 7.1 Leçon Au module 4, vous avez appris les fonctions essentielles pour lire et visualiser des données spatiales vectorielles sous R. Le présent module vous amènera maintenant à manipuler des données vectorielles. Dans un premier temps, cette leçon vous enseignera le fonctionnement dopérations de base sur les données vectorielles. Ces opérations comprennent deux grandes catégories: les opérations qui portent sur les attributs des données vectorielles et les opérations qui portent sur la géométrie des données vectorielles. Les opérations réalisées sur les attributs des données vectorielles sont indépendantes de la composante spatiale des données, alors que les opérations spatiales prennent en considération la géométrie des données et peuvent même la transformer. Dans un second temps, cette leçon vous guidera dans la résolution dune problèmatique qui nécessite de manipuler des données vectorielles. Au cours des différentes étapes permettant de résoudre la problématique, vous mettrez en pratique les diverses fonctions R apprises jusquà maintenant. Plus précisément, nous allons explorer le territoire Québécois en se posant la question suivante: Parmi les dix plus grandes villes du Québec, quelle est celle qui dispose du plus grand nombre de parcs nationaux dans un rayon de 70 km ? 7.1.1 Télécharger les données Les données Dans cette leçon, nous allons utiliser les données vectorielles relatives aux municipalités et aux régions administratives du Québec, ainsi quau réseau de la Société des établissements de plein air du Québec, la SÉPAQ. Afin de faciliter le téléchargement de ces données, lensemble de ces couches dinformations spatiales peuvent être téléchargées en cliquant sur un seul lien: données pour le module 7. Sauvegardez le dossier compressé (zip) dans votre répertoire de travail Module7_donnees pour ce module, et dézippez-le. Le dossier comprend trois sous-dossiers et un fichier .csv: villes, parcs.gdb, regions_admin, population.csv. 7.1.2 Opérations de base 7.1.2.1 Importer et visualiser les données Commençons par charger les bibliothèques requises pour lire les données spatiales vectorielles (sf) et les visualiser (mapview). library(sf) library(mapview) Maintenant, allons lire le fichier shapefile de lensemble des municipalités du Québec en utilisant la fonction st_read() tel que vu dans le module 4. municipalites &lt;- st_read(&quot;Module7/Module7_donnees/villes/villes.shp&quot;) Reading layer `villes&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module7\\Module7_donnees\\villes\\villes.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 767 features and 17 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -83.64 ymin: 42.05 xmax: -51.73 ymax: 64.19 Geodetic CRS: Geographic Coordinate System Le shapefile a été importé dans un objet R de classe sf (cest-à-dire un objet importé ou généré par lutilisation de la bibliothèque sf). Nous remarquons que la géométrie de cet object vectoriel est de type point (POINT). Plus précisément, cet objet contient 767 points (features) et 17 attributs (fields). Pour en savoir davantage sur ces attributs de nature géographique, démographique et administrative, vous pouvez télécharger et consulter la [documentation] (https://www.donneesquebec.ca/recherche/fr/dataset/base-de-donnees-geographiques-et-administratives/resource/beb4472a-0edb-4824-b67e-40e20b425326) disponible sur le site de Données Québec. Nous pouvons maintenant visuellement valider que limportation des données a bien été réussie en utilisant la fonction mapview() : mapview(municipalites, legend = FALSE) Dans le précédent module portant sur la cartographie, nous avons décrit plusieurs fonctionnalités de la bibliothèque tmap et avons démontré sa flexibilité et à sa capacité à produire des cartes de grande qualité. Toutefois, la bibliothèque mapview demeure fort utile lorsque nous souhaitons visualiser rapidement des données. Par défaut, la fonction mapview() affiche la carte dOpenstreeMap en arrière-pan, ce qui permet de contextualiser facilement les données. De plus, les cartes produites avec mapview() sont interactives, permettant daccéder directement à la table dattributs des données vectorielles représentées. Par exemple, sur la carte ci-dessus, vous navez quà cliquer sur le marqueur géographique correspondant à chaque municipalité (point) ou à chaque parc (polygone) pour obtenir la liste des attributs et leur valeur. De plus, vous pouvez choisir dafficher lune ou lautre des couches en cochant la couche désirée dans la fenêtre située dans le coin supérieur gauche. 7.1.2.2 Opérations sur les attributs des données vectorielles Les opérations sur les données vectorielles peuvent être séparées en deux grandes catégories. Les opérations qui portent sur les attributs des données et les opérations qui portent sur la géométrie des données. Les opérations réalisées sur les attributs des données vectorielles sont indépendantes de la composante spatiale des données. Ce sont des fonctions générales pour manipuler des bases de données et qui sappliquent aux data.frame des données vectorielles. La présente section sattarde à décrire certaines de ces fonctions. Filter des attributs Une opération fréquente lorsque nous manipulons des données vectorielles est celle de filtrer les données. Par exemple, dans le shapefile municipalites que nous venons dimporter, nous pourrions vouloir sélectionner seulement certaines municipalités parmi les 767 répertoriées ou certains attributs parmi les 17. Nous pourrions aussi vouloir déterminer quelles municipalités possédent une valeur spécifique pour un attribut donné. Dans les sous-sections qui suivent, nous présenterons des opérations qui permettent de filtrer les attributs de données vectorielles. Sélectionner des attributs à partir de leur indice Les objets sf sont manipulables de la même façon quun data.frame (étant eux-mêmes des data.frame). Les attributs correspondent aux colonnes tandis que les entités spatiales (points, lignes ou polygones) correspondent aux lignes du data.frame. Par exemple, lobjet spatial municipalites contient 767 points correspondant chacun à une municipalité. La table dattributs contient quant à elle 18 colonnes correspondant à chacun des attributs permettant de décrire les municipalités. Pour sélectionner un élément spatial spécifique dun shapefile, nous pouvons simplement spécifier lindice de la ligne qui lui est associée dans le data.frame. Par exemple : municipalites[1, ] # Pour accéder à la première ligne. Simple feature collection with 1 feature and 17 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -57.13 ymin: 51.43 xmax: -57.13 ymax: 51.43 Geodetic CRS: Geographic Coordinate System LAYER AREA PERIMETER HABIT_P. 1 Unknown Point Feature 0 0 1 HABIT_P_ID HABIT_P_ HABIT_P_I1 HAP_CO_PRE 1 1 1 417 PRE HAP_NO_IND HAP_DE_IND HAP_CO_CLA HAP_CO_TOP 1 03 63 0000 001 Lieu habité TER 236021 HAP_NM_TOP HAP_DA_TOP HAP_CO_VER HAP_DA_MOD 1 Blanc-Sablon 20010115 BDGA1M v1.1 0 INT_AFF geometry 1 2M POINT (-57.13 51.43) Nous remarquons que le nombre de features (points) est maintenant de 1 (voir la première ligne de la sortie produite par R). En effet, puisque nous avons sélectionné le premier point de lobjet spatial municipalites nous avons exclu les 766 autres points. De la même manière, pour sélectionner un attribut spécifique, nous pouvons simplement spécifier lindice de la colonne qui lui est associée : municipalites[, 2] # Pour accéder à la deuxième colonne. Simple feature collection with 767 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -83.64 ymin: 42.05 xmax: -51.73 ymax: 64.19 Geodetic CRS: Geographic Coordinate System First 10 features: AREA geometry 1 0 POINT (-57.13 51.43) 2 0 POINT (-57.2 51.41) 3 0 POINT (-76.25 51.69) 4 0 POINT (-78.75 51.49) 5 0 POINT (-58.65 51.23) 6 0 POINT (-59.62 50.47) 7 0 POINT (-73.87 50.41) 8 0 POINT (-60.67 50.22) 9 0 POINT (-62.81 50.29) 10 0 POINT (-64.33 50.29) Nous remarquons également que le nombre de fields (colonnes) à diminuer à 1. Sélectionner des attributs à partir de leur nom Il est également possible de sélectionner un attribut particulier en spécifiant son nom. Les colonnes disposent toujours dun nom unique dans un data.frame. Nous pouvons afficher le nom des colonnes en utilisant la fonction names() : names(municipalites) [1] &quot;LAYER&quot; &quot;AREA&quot; &quot;PERIMETER&quot; [4] &quot;HABIT_P.&quot; &quot;HABIT_P_ID&quot; &quot;HABIT_P_&quot; [7] &quot;HABIT_P_I1&quot; &quot;HAP_CO_PRE&quot; &quot;HAP_NO_IND&quot; [10] &quot;HAP_DE_IND&quot; &quot;HAP_CO_CLA&quot; &quot;HAP_CO_TOP&quot; [13] &quot;HAP_NM_TOP&quot; &quot;HAP_DA_TOP&quot; &quot;HAP_CO_VER&quot; [16] &quot;HAP_DA_MOD&quot; &quot;INT_AFF&quot; &quot;geometry&quot; Cette table contient 17 attributs. Lattribut nommé HAP_NM_TOP réfère au nom des municipalités. Notez que labréviation TOP signifie toponyme. Pour sélectionner cet attribut nous pouvons le faire simplement en utilisant son nom. Par exemple, en utilisant la syntaxe suivante : municipalites[, &quot;HAP_NM_TOP&quot;] Simple feature collection with 767 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -83.64 ymin: 42.05 xmax: -51.73 ymax: 64.19 Geodetic CRS: Geographic Coordinate System First 10 features: HAP_NM_TOP geometry 1 Blanc-Sablon POINT (-57.13 51.43) 2 Lourdes-de-Blanc-Sablon POINT (-57.2 51.41) 3 Nemiscau POINT (-76.25 51.69) 4 Waskaganish POINT (-78.75 51.49) 5 Saint-Augustin POINT (-58.65 51.23) 6 Chevery POINT (-59.62 50.47) 7 Mistissini POINT (-73.87 50.41) 8 La Romaine POINT (-60.67 50.22) 9 Baie-Johan-Beetz POINT (-62.81 50.29) 10 Rivière-Saint-Jean POINT (-64.33 50.29) # Ce qui revient également au même que la syntaxe suivante municipalites[, 13] Simple feature collection with 767 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -83.64 ymin: 42.05 xmax: -51.73 ymax: 64.19 Geodetic CRS: Geographic Coordinate System First 10 features: HAP_NM_TOP geometry 1 Blanc-Sablon POINT (-57.13 51.43) 2 Lourdes-de-Blanc-Sablon POINT (-57.2 51.41) 3 Nemiscau POINT (-76.25 51.69) 4 Waskaganish POINT (-78.75 51.49) 5 Saint-Augustin POINT (-58.65 51.23) 6 Chevery POINT (-59.62 50.47) 7 Mistissini POINT (-73.87 50.41) 8 La Romaine POINT (-60.67 50.22) 9 Baie-Johan-Beetz POINT (-62.81 50.29) 10 Rivière-Saint-Jean POINT (-64.33 50.29) # Puisque cette colonne est en treizième position. Notez que la syntaxe familière municipalites$HAP_NM_TOP retourne un vecteur listant les valeurs de lattribut HAP_NM_TOP, mais ne conserve pas la géométrie du shapefile: head(municipalites$HAP_NM_TOP) [1] &quot;Blanc-Sablon&quot; &quot;Lourdes-de-Blanc-Sablon&quot; [3] &quot;Nemiscau&quot; &quot;Waskaganish&quot; [5] &quot;Saint-Augustin&quot; &quot;Chevery&quot; Toutefois, la syntaxte précédente conserve la géométrie du shapefile et peut ainsi être utilisée pour définir un nouvel objet spatial. Par exemple, créons un nouveau shapefile qui contient seulement le nom des municipalités et leur position géographique : villes &lt;- municipalites[,&quot;HAP_NM_TOP&quot;] villes Simple feature collection with 767 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -83.64 ymin: 42.05 xmax: -51.73 ymax: 64.19 Geodetic CRS: Geographic Coordinate System First 10 features: HAP_NM_TOP geometry 1 Blanc-Sablon POINT (-57.13 51.43) 2 Lourdes-de-Blanc-Sablon POINT (-57.2 51.41) 3 Nemiscau POINT (-76.25 51.69) 4 Waskaganish POINT (-78.75 51.49) 5 Saint-Augustin POINT (-58.65 51.23) 6 Chevery POINT (-59.62 50.47) 7 Mistissini POINT (-73.87 50.41) 8 La Romaine POINT (-60.67 50.22) 9 Baie-Johan-Beetz POINT (-62.81 50.29) 10 Rivière-Saint-Jean POINT (-64.33 50.29) Profitons-en pour renommer lattribut HAP_NM_TOP afin davoir un intitulé de colonne plus explicite : names(villes) &lt;- c(&quot;toponyme&quot;, &quot;geometry&quot;) names(villes) [1] &quot;toponyme&quot; &quot;geometry&quot; Filtrer des valeurs dattribut On peut vouloir sélectionner un ou plusieurs éléments spatiaux dun shapefile qui possèdent une valeur spécifique dattribut. Cette opération peut être réalisée en utilisant les fonctions subset() ou which(). Fonction subset() La fonction subset() nest pas spécifique aux données spatiales, cest une fonction générale de R qui retourne le sous-ensemble dun vecteur, dune matrice or dun tableau de données qui satisfait une condition donnée. Par exemple, nous pouvons utiliser la fonction subset() pour filtrer le jeu de données villes afin dobtenir la localisation dune municipalité précise: la_poc &lt;- subset(villes, toponyme == &quot;La Pocatière&quot;) mapview(la_poc, legend = FALSE) Notez que lobjet retourné, ici la_poc, est de même classe que lobjet filtré, ici villes. Nous pouvons valider la classe dun objet dans R avec la fonction class(). class(la_poc) [1] &quot;sf&quot; &quot;data.frame&quot; Fonction which() La fonction which() est aussi une fonction générale de R. Elle identifie la position des éléments de valeur TRUE dans un vecteur logique. Par exemple: #Exemple 1 which(c(TRUE, FALSE, TRUE, FALSE, TRUE)) [1] 1 3 5 #Exemple 2 which(c(1, 1, 2) == 2) [1] 3 Maintenant, utilisons la fonction which() pour isoler la ville de La Pocatière: which(villes$toponyme == &quot;La Pocatière&quot;) [1] 128 Remarquez que la fonction which() retourne lindice de la ligne dans la table dattributs de lobjet villes satisfaisant la condition toponyme == \"La Pocatière\". Nous pouvons ensuite consigner cet identifiant dans lobjet id_la_poc et lutiliser pour déterminer la localisation de la ville de La Pocatière: id_la_poc &lt;- which(villes$toponyme == &quot;La Pocatière&quot;) villes[id_la_poc,] Simple feature collection with 1 feature and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -70.04 ymin: 47.37 xmax: -70.04 ymax: 47.37 Geodetic CRS: Geographic Coordinate System toponyme geometry 128 La Pocatière POINT (-70.04 47.37) Ajouter des attributs Un autre type de manipulations fréquemment utilisé est celui denrichir un jeu de données vectorielles en lui ajoutant des attributs. Ces nouvelles informations peuvent provenir dune base de données non-spatiales ou dun autre shapefile. Dans le cas de données non-spatiales, nous pouvons combiner les attributs désirés en utilisant lopération merge() que nous définissons dans cette sous-section. Lorsque nous souhaitons ajouter des attributs provenant de données spatiales, nous devons faire une jointure spatiale en utilisant lopération st_join(). Nous définirons st_join() dans la section suivante portant sur les opérations spatiales sur les données vectorielles. La fonction merge() La fonction merge() est une fonction générale de R qui sert à combiner deux tableaux de données différents en se servant de rangées ou de colonnes communes. Par exemple, ajoutons à chacune des municipilatés contenues dans le shapefile villes la taille de sa population. Cette information est contenue dans un fichier csv (Module7_donnees/ville/population.csv) et provient du répertoire des municipalités du Québec. Nous allons dabord importer ce fichier CSV dans R en utilisant la fonction read.csv(). Ensuite, nous sélectionnerons les colonnes pertinentes de ce tableau, et nous ajouterons ces informations aux attributs de lobjet spatial villes. pop &lt;- read.csv(&quot;Module7/Module7_donnees/villes/population.csv&quot;,encoding=&quot;UTF-8&quot;) Notez que la précision de lencodage assure que les accents français sont bien importés lors de la lecture du document. Lobjet pop est un data.frame de 114 colonnes décrivant un ensemble dinformations propres aux municipalités du Québec allant de leur nom jusquà la composition de leur conseil municipal. Toutes ces informations ne sont pas pertinentes pour le présent exercice. Pour faciliter la manipulation de ce tableau, sélectionnons seulement les colonnes suivantes: munnom: Nom de la ville. msuperf: Superficie de la municipalité. mpopul: Taille de la population de la municipalité. pop &lt;- pop[, c(&quot;munnom&quot;, &quot;msuperf&quot;, &quot;mpopul&quot;)] Le nouvel objet pop ainsi défini, contient seulement 3 colonnes. Nous voulons à présent fusionner lobjet pop avec lobjet spatial villes en utilisant la fonction merge(). Cette fusion entre les deux objets villes et pop sera réalisée sur les colonnes toponyme et munnom respectivement. Ces deux colonnes contiennent le nom des municipalités et agissent donc comme dénominateur commun entre les deux jeux de données. #villes_qc &lt;- merge(x = villes_qc, y = pop, by.x=&quot;toponyme&quot;, by.y=&quot;munnom&quot;, all.x = TRUE) villes_pop &lt;- merge(x = villes, y = pop, by.x=&quot;toponyme&quot;, by.y=&quot;munnom&quot;) villes_pop Simple feature collection with 485 features and 3 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -82.93 ymin: 42.31 xmax: -56.18 ymax: 62.42 Geodetic CRS: Geographic Coordinate System First 10 features: toponyme msuperf mpopul geometry 1 Acton Vale 91.1 7733 POINT (-72.56 45.65) 2 Aguanish 680.6 238 POINT (-62.08 50.22) 3 Akulivik 82.3 678 POINT (-78.2 60.81) 4 Albanel 205.0 2232 POINT (-72.44 48.88) 5 Alma 232.6 30831 POINT (-71.65 48.54) 6 Amherst 249.5 1459 POINT (-64.21 45.83) 7 Amos 437.2 12769 POINT (-78.12 48.57) 8 Amqui 128.3 6065 POINT (-67.43 48.46) 9 Armagh 170.6 1502 POINT (-70.59 46.74) 10 Asbestos 31.8 6837 POINT (-71.93 45.77) Le nouveau shapefile villes_pop contient les mêmes attributs que villes auxquels se sont ajoutés les attributs de pop. Remarquez que villes_pop contient moins déléments que villes. En effet, la fonction merge() na retenue que les villes qui étaient contenues à la fois dans le shapefile villes et dans la base de données pop. Pour conserver lentièreté des éléments initialement présents dans villes, il faudrait ajouter largument all.x = TRUE à la fonction merge(). Dans ce cas, les villes dont la population nest pas définie dans pop se verraient attribuer une valeur NA à lattribut mpopul. Renommons les colonnes de villes_pop pour quelles portent un nom plus représentatif de leur contenu. names(villes_pop) [1] &quot;toponyme&quot; &quot;msuperf&quot; &quot;mpopul&quot; &quot;geometry&quot; names(villes_pop)[2:3] &lt;- c(&quot;superficie&quot;, &quot;population&quot;) names(villes_pop) [1] &quot;toponyme&quot; &quot;superficie&quot; &quot;population&quot; &quot;geometry&quot; 7.1.2.3 Opérations spatiales sur les données vectorielles Les opérations réalisées dans la section précédente sur les attributs des données vectorielles, telles merge(), which() et subset(), sont indépendantes de la composante spatiale des données. Si nous changions la géométrie des objets spatiaux décrits par les données vectorielles (par exemple en changeant les coordonnées des villes), ces opérations produiraient les mêmes résultats. Ce sont des fonctions générales pour manipuler des bases de données et qui sappliquent aux data.frame des données vectorielles. Dans la présente section, nous verrons plutôt des opérations qui dépendent de la composante spatiale des données vectorielles. Ces opérations prennent en considération la géométrie des données et certaines peuvent aussi la transformer. Jointure spatiale Une opération de jointure permet de lier entre eux des éléments spatiaux sur la base dune valeur dattribut commune. La fonction st_join() La fonction st_join() de la bibliothèque sf permet de joindre à un shapefile de linformation provenant dune autre couche spatiale. Cette opération constitue une jointure spatiale. Par exemple, importons le shapefile des régions administratives du Québec, disponible dans le dossier Module7_données, et réalisons une jointure entre cette couche et la couche villes. regions &lt;- st_read(&quot;Module7/Module7_donnees/regions_admin/regions_admin.shp&quot;) Reading layer `regions_admin&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module7\\Module7_donnees\\regions_admin\\regions_admin.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 21 features and 1 field Geometry type: POLYGON Dimension: XY Bounding box: xmin: -79.76 ymin: 44.99 xmax: -56.93 ymax: 62.58 Geodetic CRS: GCS_Geographic_Coordinate_System # on observe le contenu de ce shaphefile regions Simple feature collection with 21 features and 1 field Geometry type: POLYGON Dimension: XY Bounding box: xmin: -79.76 ymin: 44.99 xmax: -56.93 ymax: 62.58 Geodetic CRS: GCS_Geographic_Coordinate_System First 10 features: Rgns_Ad 1 Côte-Nord 2 Côte-Nord 3 Côte-Nord 4 Saguenay - Lac-Saint-Jean 5 Gaspésie - Îles-de-la-Madeleine 6 Bas-Saint-Laurent 7 Abitibi-Témiscamingue 8 Mauricie 9 Capitale-Nationale 10 Outaouais geometry 1 POLYGON ((-66.69 55, -66.64... 2 POLYGON ((-66.26 55, -66.25... 3 POLYGON ((-67.22 55, -67 55... 4 POLYGON ((-72.07 47.95, -72... 5 POLYGON ((-67.15 49.19, -67... 6 POLYGON ((-67.15 49.19, -66... 7 POLYGON ((-75.52 47.85, -75... 8 POLYGON ((-74.47 48.95, -74... 9 POLYGON ((-72.07 47.95, -72... 10 POLYGON ((-75.52 47.85, -75... # on le visualise mapview(regions) Notez que les éléments de regions sont des polygones. Ces polygones possèdent un seul attribut, \"Rgns_Ad\", correspondant au nom des régions administratives que ceux-ci délimitent. Nous allons maintenant faire une jointure spatiale entre villes et regions afin dassocier à chaque municipalité sa région administrative dattache. villes_reg = st_join(villes, regions[ ,&quot;Rgns_Ad&quot;]) villes_reg Simple feature collection with 767 features and 2 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -83.64 ymin: 42.05 xmax: -51.73 ymax: 64.19 Geodetic CRS: Geographic Coordinate System First 10 features: toponyme Rgns_Ad 1 Blanc-Sablon Côte-Nord 2 Lourdes-de-Blanc-Sablon Côte-Nord 3 Nemiscau Nord-du-Québec 4 Waskaganish Nord-du-Québec 5 Saint-Augustin Côte-Nord 6 Chevery Côte-Nord 7 Mistissini Nord-du-Québec 8 La Romaine Côte-Nord 9 Baie-Johan-Beetz Côte-Nord 10 Rivière-Saint-Jean Côte-Nord geometry 1 POINT (-57.13 51.43) 2 POINT (-57.2 51.41) 3 POINT (-76.25 51.69) 4 POINT (-78.75 51.49) 5 POINT (-58.65 51.23) 6 POINT (-59.62 50.47) 7 POINT (-73.87 50.41) 8 POINT (-60.67 50.22) 9 POINT (-62.81 50.29) 10 POINT (-64.33 50.29) Remarquez que lobjet villes_reg est identique à lobjet villes mais contient un attribut supplémentaire: la colonne Rgns_Ad. Il est important de préciser que la fonction st_join() nécessite que les deux couches spatiales à joindre utilisent le même système de coordonnées de référence (SCR). Contrairement à la fonction merge() vue plus haut, la fonction st_join() est bien une opération spatiale. En effet, st_join(x,y) détermine sil y a une intersection spatiale entre chaque élément de lobjet de gauche (x = villes) et lun ou lautre des éléments de lobjet de droite (y = regions). Une intersection entre deux éléments spatiaux se produit lorsquils partagent une même portion de lespace. Ainsi, il y a une intersection entre le point associé à la ville de Shawinigan et le polygone associé à la région de la Mauricie. Par ailleurs, il ny a pas dintersection entre le point associé à la ville de Sherbrooke et le polygone de la Mauricie. Lorsque st_join(x,y) identifie la présence dune intersection entre deux éléments, elle assigne à lélément de gauche la valeur de lattribut (ici \"Rgns_Ad\") de lélément de droite. Lorsquil ny a pas dintersection entre deux éléments, la fonction assigne une valeur dattribut NA à lélément de gauche. Par exemple, les données villes contiennent des municipalités qui ne sont pas situées au Québec. On retrouve entre autres la ville dAlbany dans létat de New York aux États-Unis. Ainsi aucune région na pu être associée à ces villes. villes_reg[692,] Simple feature collection with 1 feature and 2 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -73.77 ymin: 42.66 xmax: -73.77 ymax: 42.66 Geodetic CRS: Geographic Coordinate System toponyme Rgns_Ad geometry 692 Albany &lt;NA&gt; POINT (-73.77 42.66) Si nous souhaitons que la fonction st_join(x,y) conserve seulement les éléments de x qui intersectent un ou lautre des éléments de y, nous devons ajouter largument left = FALSE : villes_reg &lt;- st_join(villes, regions[ ,&quot;Rgns_Ad&quot;], left = FALSE) Visualisons le nouveau shapefile que nous venons de créer. Ce dernier contient seulement les municipalités à lintérieur du territoire québécois. mapview(villes_reg, legend = FALSE) Notez que lorsque vous cliquez sur les points de la carte, la valeur de lattribut Rngs_Ad est maintenant également donnée. Vous pouvez ainsi différencier visuellement les municipalités selon leur région administrative dattache. mapview(villes_reg, zcol = &quot;Rgns_Ad&quot;, legend = FALSE) Que se produit-il si nous inversons les arguments villes et regions dans la fonction st-join()  ? Dans ce cas, la jointure spatiale associe à chaque région les villes qui sont situées (cest-à-dire intersectent) son territoire. Observons le résultat dune telle jointure : reg_villes &lt;- st_join(regions, villes[,&quot;toponyme&quot;], left = FALSE) reg_villes Simple feature collection with 620 features and 2 fields Geometry type: POLYGON Dimension: XY Bounding box: xmin: -79.76 ymin: 44.99 xmax: -57.11 ymax: 62.58 Geodetic CRS: GCS_Geographic_Coordinate_System First 10 features: Rgns_Ad toponyme 3 Côte-Nord Kawawachikamach 3.1 Côte-Nord Matimekosh 3.2 Côte-Nord Schefferville 4 Saguenay - Lac-Saint-Jean Girardville 4.1 Saguenay - Lac-Saint-Jean Albanel 4.2 Saguenay - Lac-Saint-Jean Mistassini 4.3 Saguenay - Lac-Saint-Jean Dolbeau 4.4 Saguenay - Lac-Saint-Jean Normandin 4.5 Saguenay - Lac-Saint-Jean Sainte-Monique 4.6 Saguenay - Lac-Saint-Jean La Doré geometry 3 POLYGON ((-67.22 55, -67 55... 3.1 POLYGON ((-67.22 55, -67 55... 3.2 POLYGON ((-67.22 55, -67 55... 4 POLYGON ((-72.07 47.95, -72... 4.1 POLYGON ((-72.07 47.95, -72... 4.2 POLYGON ((-72.07 47.95, -72... 4.3 POLYGON ((-72.07 47.95, -72... 4.4 POLYGON ((-72.07 47.95, -72... 4.5 POLYGON ((-72.07 47.95, -72... 4.6 POLYGON ((-72.07 47.95, -72... Le shapefile reg_villes est constitué des polygones de regions. Puisque plusieurs municipalités intersectent chaque région, le polygone dune région donnée est dupliqué pour chacun des points. Cest-à-dire quune nouvelle ligne est ajoutée pour chacune des intersections identifiées. Remarquez que nous pouvons aussi utiliser la fonction join_st() en vue de créer un filtre spatial, par exemple avec la fonction subset()  : villes_CN&lt;- subset(villes_reg, Rgns_Ad==&quot;Côte-Nord&quot;) mapview(villes_CN, legend = FALSE) Cette opération nous a permis de filtrer les municipalités du Québec pour retenir seulement celles situées dans la région administrative de la Côte-Nord. Opérations géométriques Les opérations géométriques sur les données vectorielles sont des opérations qui peuvent changer la géométrie des données ou qui peuvent créer, à partir de celles-ci, des nouveaux objets vectoriels de géométrie différente. La fonction aggregate() La fonction aggregate() de la bibliothèque sf permet dagréger (cest-à-dire de grouper) des éléments spatiaux dune même couche de données vectorielles. Afin de démontrer comment opère la fonction aggregate() considérons dabord lobjet villes_reg_pop. Ce dernier est formé par la jointure spatiale entre villes_pop, le shapefile associant à chaque municipalité la taille de sa population, et regions : villes_reg_pop &lt;- st_join(villes_pop, regions[ ,&quot;Rgns_Ad&quot;], left = FALSE) villes_reg_pop Simple feature collection with 477 features and 4 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -79.5 ymin: 45.05 xmax: -57.13 ymax: 62.42 Geodetic CRS: Geographic Coordinate System First 10 features: toponyme superficie population 1 Acton Vale 91.1 7733 2 Aguanish 680.6 238 3 Akulivik 82.3 678 4 Albanel 205.0 2232 5 Alma 232.6 30831 7 Amos 437.2 12769 8 Amqui 128.3 6065 9 Armagh 170.6 1502 10 Asbestos 31.8 6837 11 Aupaluk 32.7 224 Rgns_Ad geometry 1 Montérégie POINT (-72.56 45.65) 2 Côte-Nord POINT (-62.08 50.22) 3 Nord-du-Québec POINT (-78.2 60.81) 4 Saguenay - Lac-Saint-Jean POINT (-72.44 48.88) 5 Saguenay - Lac-Saint-Jean POINT (-71.65 48.54) 7 Abitibi-Témiscamingue POINT (-78.12 48.57) 8 Bas-Saint-Laurent POINT (-67.43 48.46) 9 Chaudière-Appalaches POINT (-70.59 46.74) 10 Estrie POINT (-71.93 45.77) 11 Nord-du-Québec POINT (-69.61 59.3) Lobjet villes_reg_pop associe à chaque municipalité la taille de sa population ainsi que sa région administrative. En agrégeant ensemble les villes dune même région, il nous est possible de déterminer la taille de la population de cette région. Cest ce que nous allons faire en utilisant la fonction aggregate() : reg_pop&lt;-aggregate(villes_reg_pop[&quot;population&quot;], by = list(villes_reg_pop$Rgns_Ad), FUN = sum, na.rm = TRUE) reg_pop Simple feature collection with 17 features and 2 fields Attribute-geometry relationship: 0 constant, 1 aggregate, 1 identity Geometry type: GEOMETRY Dimension: XY Bounding box: xmin: -79.5 ymin: 45.05 xmax: -57.13 ymax: 62.42 Geodetic CRS: Geographic Coordinate System First 10 features: Group.1 population 1 Abitibi-Témiscamingue 125833 2 Bas-Saint-Laurent 143428 3 Capitale-Nationale 684340 4 Centre-du-Québec 201807 5 Chaudière-Appalaches 372758 6 Côte-Nord 72674 7 Estrie 251011 8 Gaspésie - Îles-de-la-Madeleine 62017 9 Lanaudière 409733 10 Laurentides 388382 geometry 1 MULTIPOINT ((-79.5 48.87), ... 2 MULTIPOINT ((-70.04 47.37),... 3 MULTIPOINT ((-72.27 46.76),... 4 MULTIPOINT ((-72.82 46.06),... 5 MULTIPOINT ((-72 46.57), (-... 6 MULTIPOINT ((-69.8 48.24), ... 7 MULTIPOINT ((-72.31 45.49),... 8 MULTIPOINT ((-66.69 49.1), ... 9 MULTIPOINT ((-73.92 46.68),... 10 MULTIPOINT ((-75.62 46.09),... De façon générale, la fonction aggregate(x, by, FUN) comprend trois arguments: x est lobjet spatial que lon souhaite agréger, by défini la condition utilisée pour regrouper les éléments de x, FUN défini la fonction selon laquelle lattribut dun groupement est calculé à partir des attributs des éléments agrégés. Dans notre exemple, nous avons regroupé les points de lobjet spatial villes_reg_pop[\"population\"] qui possèdent la même valeur dattribut \"Rgns_Ad\". Les points ainsi regroupés forment une géométrie multipoint (MULTIPOINT). Chaque groupe de points est identifié par le nom de sa région administrative (Abitibi-Témiscamingue, Bas-Saint-Laurent, etc.). Lattribut dun groupe est calculé en faisant la somme (FUN = sum) des attributs des points qui le constituent. Largument additionnel na.rm = TRUE précise que lors du calcul de la somme, les éléments dont lattribut \"population\" prend la valeur NA doivent être ignorés. En effet, la population de quelques municipalités nest pas définie dans cette base de données. Notez quune autre fonction aurait pu être utilisée, par exemple la moyenne, le maximum, le minimum, etc. La condition by peut prendre différentes formes. Elle peut être définie par une liste de longueur égale au nombre déléments dans x (cest-à-dire le même nombre de rangées). Cest de cette façon que nous lavons définie plus haut (la liste est de longueur égale aux nombres de points dans villes_reg_pop). De plus, by peut prendre la forme dun objet spatial dont la géométrie est utilisée pour grouper les éléments de x. Dans ce cas, la géométrie du nouvel objet créé par la fonction aggregate() est la même que lobjet by. Donnons un exemple illustrant cette situation. Agrégeons maintenant les municipalités de lobjet villes_pop[\"population\"] en utilisant directement lobjet regions constitué de polygones  : reg_pop2 &lt;-aggregate(villes_pop[&quot;population&quot;], by = regions, FUN = sum, na.rm = TRUE) reg_pop2 Simple feature collection with 21 features and 1 field Geometry type: POLYGON Dimension: XY Bounding box: xmin: -79.76 ymin: 44.99 xmax: -56.93 ymax: 62.58 Geodetic CRS: GCS_Geographic_Coordinate_System First 10 features: population geometry 1 NA POLYGON ((-66.69 55, -66.64... 2 NA POLYGON ((-66.26 55, -66.25... 3 157 POLYGON ((-67.22 55, -67 55... 4 91339 POLYGON ((-72.07 47.95, -72... 5 62017 POLYGON ((-67.15 49.19, -67... 6 143428 POLYGON ((-67.15 49.19, -66... 7 125833 POLYGON ((-75.52 47.85, -75... 8 275487 POLYGON ((-74.47 48.95, -74... 9 684340 POLYGON ((-72.07 47.95, -72... 10 311130 POLYGON ((-75.52 47.85, -75... Observez que les groupements sont maintenant des polygones, et non des multipoints. Par ailleurs le calcul de lattribut \"population\" est le même. Une visualisation du nouvel objet reg_pop2 permet dillustrer les régions selon la taille de leur population : mapview(reg_pop2) Donnons un dernier exemple de lutilisation de la fonction aggregate() en considérant le shapefile régions regions Simple feature collection with 21 features and 1 field Geometry type: POLYGON Dimension: XY Bounding box: xmin: -79.76 ymin: 44.99 xmax: -56.93 ymax: 62.58 Geodetic CRS: GCS_Geographic_Coordinate_System First 10 features: Rgns_Ad 1 Côte-Nord 2 Côte-Nord 3 Côte-Nord 4 Saguenay - Lac-Saint-Jean 5 Gaspésie - Îles-de-la-Madeleine 6 Bas-Saint-Laurent 7 Abitibi-Témiscamingue 8 Mauricie 9 Capitale-Nationale 10 Outaouais geometry 1 POLYGON ((-66.69 55, -66.64... 2 POLYGON ((-66.26 55, -66.25... 3 POLYGON ((-67.22 55, -67 55... 4 POLYGON ((-72.07 47.95, -72... 5 POLYGON ((-67.15 49.19, -67... 6 POLYGON ((-67.15 49.19, -66... 7 POLYGON ((-75.52 47.85, -75... 8 POLYGON ((-74.47 48.95, -74... 9 POLYGON ((-72.07 47.95, -72... 10 POLYGON ((-75.52 47.85, -75... Remarquez que certaines régions, comme la Côte-Nord, sont représentées par plusieurs polygones. Cest pour cette raison que ce shapefile contient 21 éléments spatiaux alors quil y a 17 régions administratives au Québec. Utilisons la fonction aggregate() pour agréger en un seul multipolygone les polygones qui portent la même valeur dattribut \"Rgns_Ad\" : regions_agg &lt;-aggregate(regions, by=list(regions$Rgns_Ad), unique) regions_agg Simple feature collection with 17 features and 2 fields Attribute-geometry relationship: 0 constant, 1 aggregate, 1 identity Geometry type: GEOMETRY Dimension: XY Bounding box: xmin: -79.76 ymin: 44.99 xmax: -56.93 ymax: 62.58 Geodetic CRS: GCS_Geographic_Coordinate_System First 10 features: Group.1 1 Abitibi-Témiscamingue 2 Bas-Saint-Laurent 3 Capitale-Nationale 4 Centre-du-Québec 5 Chaudière-Appalaches 6 Côte-Nord 7 Estrie 8 Gaspésie - Îles-de-la-Madeleine 9 Lanaudière 10 Laurentides Rgns_Ad 1 Abitibi-Témiscamingue 2 Bas-Saint-Laurent 3 Capitale-Nationale 4 Centre-du-Québec 5 Chaudière-Appalaches 6 Côte-Nord 7 Estrie 8 Gaspésie - Îles-de-la-Madeleine 9 Lanaudière 10 Laurentides geometry 1 POLYGON ((-75.52 47.85, -75... 2 POLYGON ((-67.15 49.19, -66... 3 POLYGON ((-72.07 47.95, -72... 4 POLYGON ((-72.08 46.57, -72... 5 POLYGON ((-70.2 47.41, -70.... 6 MULTIPOLYGON (((-67.41 54.9... 7 POLYGON ((-71.46 45.82, -71... 8 POLYGON ((-67.15 49.19, -67... 9 POLYGON ((-74.89 47.76, -74... 10 POLYGON ((-75.52 47.76, -75... Cette fois nous avons utilisé la fonction unique pour agréger les attributs qui sont de classe caractère. Remarquez que la Côte-Nord est maintenant représentée par un multipolygone (MULTIPOLYGON) et que le nouveau shapefile regions_agg contient 17 éléments, un pour chacune des régions administratives. Retirons la première colonne superflue de ce nouveau shapefile et utilisons-le dans les futurs exemples pour désigner les régions administratives. regions &lt;- regions_agg[-1] #pour retirer la première colonne La fonction st_simplify() Il est parfois utile de simplifier les objets vectoriels de types ligne ou polygone afin de produire des cartes à des échelles plus petites. La simplification permet de réduire lutilisation de la mémoire, du disque, et de la bande passante. La fonction st_simplify() de la bibliothèque sf permet de simplifier des objets vectoriels de types ligne ou polygone en réduisant le nombre de points que ceux-ci comprennent. Souvenez-vous quune ligne est constituée dune succession de points et quun polygone est constitué dun ensemble de lignes. Cette fonction est basée sur lalgorithme de Douglas-Peucker. Décrire le fonctionnement de cet algorithme dépasse lobjectif de ce cours. Grosso modo, lalgorithme fait appel à un seuil de distance (le paramètre dTolerance) quil utilise pour transformer en ligne droite toute courbe qui dévie dune ligne droite par une quantité moindre que ce seuil. Cette distance réflète en quelque sorte la résolution que nous souhaitons atteindre avec lobjet simplifié. Le seuil de tolérance étant une distance, nous lexprimons en mètres. Nous devons alors nous assurer que lobjet spatial à simplifier est dans un système de coordonnées métriques. En guise dexemple, simplifions le shapefile des régions administratives du Québec (??): regions_nad &lt;- st_transform(regions, crs = 32198) regions_simple_10 &lt;- st_simplify(regions_nad, dTolerance = 10000) #10000m regions_simple_40 &lt;- st_simplify(regions_nad, dTolerance = 40000) #40000m Remarquez que nous avons dabord transformé lobjet spatial regions dans le système de coordonnées de référence NAD83, dont le EPSG correspond à 32198, puisque lunité de ce système est le mètre. La fonction st_combine() La fonction st_combine() de la bibliothèque sf sert à combiner des géométries afin den former une seule. Cette opération peut être utile lorsque nous souhaitons considérer plusieurs géométries comme formant un même objet spatial. Reading layer `regn_tours_s250k_20160125&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module7\\data\\regions_touristiques\\Shapefile\\regn_tours_s250k_20160125.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 21 features and 4 fields Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin: -79.77 ymin: 44.99 xmax: -56.93 ymax: 62.58 Geodetic CRS: WGS 84 Considérons le shapefile GIM contenant deux géométries: le polygone délimitant la Gaspésie et un polygone délimitant les Îles-de-la-Madeleine. GIM Simple feature collection with 2 features and 2 fields Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin: -68.52 ymin: 46.84 xmax: -60.4 ymax: 49.72 Geodetic CRS: WGS 84 Id Nom_reg 1 1 Îles-de-la-Madeleine 2 2 Gaspésie geometry 1 MULTIPOLYGON (((-61 48.67, ... 2 MULTIPOLYGON (((-64.95 47.9... Maintenant, combinons ces deux polygones pour former une géométrie unique qui correspondra à la région administrative de la Gaspésie - Îles-de-la-Madeleine GIM_combine &lt;- st_combine(GIM) GIM_combine Geometry set for 1 feature Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin: -68.52 ymin: 46.84 xmax: -60.4 ymax: 49.72 Geodetic CRS: WGS 84 MULTIPOLYGON (((-61 48.67, -60.75 48.67, -60.5 ... Le nouvel objet GIM_combine est effectivement formé dune seule géométrie. Notez cependant que la fonction st_combine() ne fusionne pas les frontières à lintérieur du nouveau polygone formé (??). Pour unir deux polygones, il faut plutôt utiliser la fonction st_union() que nous définirons plus bas dans cette leçon. La fonction st_cast() La fonction st_cast() sert à convertir la géométrie dun objet spatial donné vers une autre géométrie. Cette fonction comprend deux arguments : st_cast(x, to). Le premier argument, x, correspond à lobjet vectoriel dont on souhaite modifier la géométrie, alors que le second argument, to, correspond à la géométrie que lon souhaite lui attribuer. Donnons un exemple. Utilisons dabord le shapefile regions pour isoler le polygone de la région administrative de la Mauricie grâce à la fonction subset() : Mauricie &lt;- subset(regions,Rgns_Ad==&quot;Mauricie&quot;) Mauricie Simple feature collection with 1 feature and 1 field Attribute-geometry relationship: 0 constant, 1 aggregate, 0 identity Geometry type: POLYGON Dimension: XY Bounding box: xmin: -75.52 ymin: 46.15 xmax: -71.89 ymax: 49 Geodetic CRS: GCS_Geographic_Coordinate_System Rgns_Ad geometry 12 Mauricie POLYGON ((-74.47 48.95, -74... Nous observons que lobjet Mauricie est bel et bien de type polygone. Maintenant utilisons la fonction st_cast() pour transformer la géométrie de cet objet en type multiligne et multipoint  : Mauricie_lines &lt;- st_cast(Mauricie, to = &quot;MULTILINESTRING&quot;) Mauricie_lines Simple feature collection with 1 feature and 1 field Attribute-geometry relationship: 0 constant, 1 aggregate, 0 identity Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: -75.52 ymin: 46.15 xmax: -71.89 ymax: 49 Geodetic CRS: GCS_Geographic_Coordinate_System Rgns_Ad geometry 12 Mauricie MULTILINESTRING ((-74.47 48... Mauricie_pts&lt;-st_cast(Mauricie, to = &quot;MULTIPOINT&quot;) Mauricie_pts Simple feature collection with 1 feature and 1 field Attribute-geometry relationship: 0 constant, 1 aggregate, 0 identity Geometry type: MULTIPOINT Dimension: XY Bounding box: xmin: -75.52 ymin: 46.15 xmax: -71.89 ymax: 49 Geodetic CRS: GCS_Geographic_Coordinate_System Rgns_Ad geometry 12 Mauricie MULTIPOINT ((-74.47 48.95),... Nous observons que les deux nouveaux objets vectoriels ont bel et bien la géométrie souhaitée (??). Dans cet exemple, nous avons en quelque sorte décomposé la géométrie dun polygone en lignes puis en points. Or, la fonction st_cast() peut également servir à consolider des géométries. En guise dexemple, considérons lobjet villes_NQ_combo créé en isolant du shapefile villes_reg les villes situées dans la région administrative du Nord-du-Québec et en les combinant par lutilisation de la fonction st_combine() : villes_NQ &lt;- subset(villes_reg, Rgns_Ad == &quot;Nord-du-Québec&quot;) villes_NQ_combo &lt;- st_combine(villes_NQ) villes_NQ_combo Geometry set for 1 feature Geometry type: MULTIPOINT Dimension: XY Bounding box: xmin: -79.29 ymin: 49.05 xmax: -65.95 ymax: 62.42 Geodetic CRS: Geographic Coordinate System MULTIPOINT ((-76.25 51.69), (-78.75 51.49), (-7... Cet objet possède une géométrie multipoint où chaque point correspond à une municipalité du Nord-du-Québec. Utilisons maintenant la fonction st_cast() pour transformer la géométrie de cet objet en ligne et en polygone  : villes_NQ_lines&lt;-st_cast(villes_NQ_combo, to = &quot;LINESTRING&quot;) villes_NQ_lines Geometry set for 1 feature Geometry type: LINESTRING Dimension: XY Bounding box: xmin: -79.29 ymin: 49.05 xmax: -65.95 ymax: 62.42 Geodetic CRS: Geographic Coordinate System LINESTRING (-76.25 51.69, -78.75 51.49, -73.87 ... villes_NQ_pol&lt;-st_cast(villes_NQ_combo, to = &quot;POLYGON&quot;) villes_NQ_pol Geometry set for 1 feature Geometry type: POLYGON Dimension: XY Bounding box: xmin: -79.29 ymin: 49.05 xmax: -65.95 ymax: 62.42 Geodetic CRS: Geographic Coordinate System POLYGON ((-76.25 51.69, -78.75 51.49, -73.87 50... Lobjet villes_NQ_lines correspond effectivement à un ensemble de lignes et lobjet villes_NQ_lines à un ensemble de polygones formés en reliant les points ensembles. La fonction st_buffer() Une zone tampon (appelée buffer en anglais) est un polygone dont les frontières sont définies par une distance donnée autour dun objet vectoriel. Une zone tampon peut être créée autour de tout objet vectoriel, que ce soit des points, des lignes ou des polygones. La création de zones tampons est généralement réalisée pour répondre à des questions de nature géographique. Par exemple, combien de garderies se situent à une distance de 2 km de ma maison ? Ou encore, combien de stations services se situent à moins de 500 m de la route menant de Chelsey à Cantley en Outaouais ? La fonction st_buffer() de la bibliothèque sf permet de créer des zones tampons. Cette fonction comprend obligatoirement deux arguments. Le premier correspond à lobjet vectoriel autour du quel nous souhaitons construire une zone tampon, et le deuxième argument défini la distance sur laquelle la zone tampon sétendra autour de lobjet vectoriel. Comme pour la fonction st_simplify(), lobjet vectoriel auquel nous appliquons la fonction st_buffer() doit être exprimé dans un SCR dunité de mesure métrique. Construisons des zones tampons autour de la ville de La Pocatière, que nous avons isolée plus haut, en considérant deux distances différentes (7.1): la_poc_nad &lt;- st_transform(la_poc, crs = 32198) la_poc_tampon10 &lt;- st_buffer(la_poc_nad, dist = 10e3) la_poc_tampon50 &lt;- st_buffer(la_poc_nad, dist = 50e3) Notez que lexpression e3 correspond au chiffre 1000 (cest-à-dire 10 exposent 3). FIGURE 7.1: Deux zones tampons de 10 km (en bleu) et de 50 km (en vert) autour de la ville de La Pocatière Maintenant, construisons des zones tampons autour des régions administratives de lAbitibi-Témiscamingue et du Saguenay - Lac-Saint-Jean (7.2). Utilisons dabord la fonction subset() pour isoler les polygones correspondants à ces régions à partir du shapefile regions_nad dont lunité de mesure du SCR est le mètre. # Isoler les polygones des deux régions Abitibi &lt;- subset(regions_nad, Rgns_Ad == &quot;Abitibi-Témiscamingue&quot;) SagStJean &lt;- subset(regions_nad, Rgns_Ad == &quot;Saguenay - Lac-Saint-Jean&quot;) # Calculer une zone tampon pour chacun des polygones Abitibi_tampon20 &lt;- st_buffer(Abitibi, dist = 20e3) #20 km SagStJean_tampon50 &lt;- st_buffer(SagStJean, dist = 70e3) #70 km FIGURE 7.2: Une zone tampon de 20 km autour de la région administrative de lAbitibi-Témicamingue et une zone tampon de 70 km autour du Saguenay - Lac-Saint-Jean. Notez que la zone tampon dun polygone inclue le polygone dorigine. Cest-à-dire que ce nest pas simplement une bordure autour du polygone. La fonction st_centroid Le centroïde dun polygone en cartographie correspond approximativement au centre géométrique dun polygone43. Ces coordonnées servent parfois à définir la localisation du polygone. La fonction st_centroid() de la bibliothèque sf permet de calculer le centroïde de polygones. Déterminons le centroïde des polygones de lAbitibi et du Saguenay - Lac-Saint-Jean (7.3). Notez que la fonction st_centroid() nécessite également que le polygone soit défini selon un SCR dont lunité de mesure est le mètre. centre_Abitibi &lt;- st_centroid(Abitibi) centre_Abitibi Simple feature collection with 1 feature and 1 field Attribute-geometry relationship: 0 constant, 1 aggregate, 0 identity Geometry type: POINT Dimension: XY Bounding box: xmin: -689600 ymin: 483300 xmax: -689600 ymax: 483300 Projected CRS: NAD83 / Quebec Lambert Rgns_Ad geometry 1 Abitibi-Témiscamingue POINT (-689572 483277) centre_SagStJean &lt;- st_centroid(SagStJean) centre_SagStJean Simple feature collection with 1 feature and 1 field Attribute-geometry relationship: 0 constant, 1 aggregate, 0 identity Geometry type: POINT Dimension: XY Bounding box: xmin: -233200 ymin: 645400 xmax: -233200 ymax: 645400 Projected CRS: NAD83 / Quebec Lambert Rgns_Ad geometry 17 Saguenay - Lac-Saint-Jean POINT (-233243 645360) La fonction st_centroid() retourne un objet vectoriel de type point qui conserve les attributs du polygone. FIGURE 7.3: Les centroïdes (en rouge) des régions de lAbitibi-Témicamingue (en bleu) et du Saguenay - Lac-Saint-Jean (vert) calculés avec la fonction st_centroid(). La fonction st_coordinates La fonction st_coordinates() permet de connaître les coordonnées dun objet vectoriel. Trouvons, par exemple, les coordonnées de la ville de La Pocatière que nous avons isolée plus haut  : st_coordinates(la_poc) X Y 1 -70.04 47.37 Dans le cas présent, les coordonnées sont exprimées en degrés. Le X correspond à la longitude et le Y, à la latitude. En effet, le SCR de la_poc utilise des longitudes-latitudes. Ceci peut-être confirmé en utilisant la fonction st_is_longlat()  : st_is_longlat(la_poc) [1] TRUE Dautre part, lobjet la_poc_nad, que nous avons obtenu en transformant la_poc dans le SCR NAD83 utilise plutôt des mètres. Ainsi  : st_is_longlat(la_poc_nad) [1] FALSE Conséquemment, les coordonnées identifiées par la fonction st_coordinates() sont en mètres  : st_coordinates(la_poc_nad) X Y 1 -116039 375793 Notez que cette fonction peut être utilisée sur tout objet de type vectoriel (ligne, multiligne, polygone, etc.). La sortie correspondra alors à un tableau donnant les coordonnées de chaque point consituant lobjet. Opérations topologiques entre deux couches Les opérations topologiques décrivent les relations spatiales entre des objets44. Ces opérations sont équivalentes aux opérations ensemblistes en mathématiques, telles lunion ou lintersection, mais sappliquent cette fois à des objets définis par une géométrie. La bibliothèque sf contient plusieurs opérateurs topologiques; par exemple: st_union(), st_intersection(), st_difference() et st_sym_difference(). Ces opérateurs forment un nouvel objet spatial à partir des deux objets spatiaux intérroger. Par exemple, la géométrie de lobjet z formé par lopération z &lt;- st_union(x,y) est constituée de la géométrie de x et de celle de y sans toutefois quil y ait de chevauchement. Pour illustrer les opérations topologiques entre deux objets vectoriels considérons les polygones A et B créés en définissant des zones tampons à partir des polygones de lAbitibi-Témiscamingue et du Saguenay - Lac-Saint-Jean respectivement. A &lt;- st_buffer(Abitibi, dist = 80e3) B &lt;- st_buffer(SagStJean, dist = 100e3) Calculons maintenant des opérations topologiques sur ces polygones  : union_AB &lt;- st_union(A,B) inter_AB &lt;- st_intersection(A,B) diff_AB &lt;- st_difference(A,B) diff_BA &lt;- st_difference(B,A) sym_diff_AB &lt;- st_sym_difference(A,B) Observons les géométries produites par ces opérations (figure ??)  : Opérations topologiques de confirmation Les opérations topologiques de confirmation sont des fonctions qui permettent de vérifier si deux objets spatiaux satisfont à une relation topologique donnée. Ces opérations ne créent pas un nouvel objet spatial, elles retournent plutôt une valeur binaire qui confirme si oui ou non la relation existe entre les deux objets interrogés. La bibliothèque sf contient plusieurs opérateurs topologiques de confirmation; par exemple: st_intersects(), st_disjoint(), st_crosses(), st_overlaps(), st_touches(), st_within() et st_contains(). La fonction st_intersects La fonction st_intersects() vérifie si deux objets spatiaux X et Y occupent un espace commun. La fonction confirmera quil y a bel et bien une intersection entre les deux objets si leurs intérieurs ou leurs frontières se recoupent. X et Y peuvent avoir nimporte quelle géométrie (point, multipoint, ligne, multiligne, polygone, multipolygone) (figure 7.4). FIGURE 7.4: Combinaisons de géométries satisfaisant à la condition dintersection. Récupérer sur le site de documentation de postgis: http://postgis.net/workshops/postgis-intro/spatial_relationships.html Pour bien comprendre comment opère st_intersects() considérons le polygone A utilisé précédemment ainsi que lobjet spatial points constitués de cinq points de couleur différente. points Simple feature collection with 5 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -902900 ymin: 476800 xmax: -224400 ymax: 668000 Projected CRS: NAD83 / Quebec Lambert geometry couleur 1 POINT (-685765 476835) Bleu 2 POINT (-224449 667962) Rouge 3 POINT (-480113 560159) Violet 4 POINT (-395847 597020) Jaune 5 POINT (-902947 480553) Vert FIGURE 7.5: Exemples illustrant la fonction st_intersects(). Utilisons a fonction st_intersects() pour déterminer quels points intersectent le polygone A : st_intersects(points, A) Sparse geometry binary predicate list of length 5, where the predicate was `intersects&#39; 1: 1 2: (empty) 3: 1 4: (empty) 5: 1 La sortie est exprimée sous forme dune liste contenant 5 paires éléments; une paire pour chacun des points interrogés. Le premier élément dune paire (cest-dire,le chiffre avant le deux-points) correspond à lindice du point. Le second élément prend la valeur 1 si le point intersecte le polygone A, et la valeur empty si le point ne recoupe pas le polygone A. Il est aussi possible dajouter largument sparse = FALSE afin que la sortie sexprime sous une forme matricielle déléments logiques. st_intersects(points, A, sparse = FALSE) [,1] [1,] TRUE [2,] FALSE [3,] TRUE [4,] FALSE [5,] TRUE La forme logique est particulièrement utile lorsque nous voulons filtrer les géométries qui satisfont à la condition dintersection. Par exemple, cette commande retourne seulement les points qui intersectent le polygone A : points[st_intersects(points, A, sparse = FALSE),] Simple feature collection with 3 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -902900 ymin: 476800 xmax: -480100 ymax: 560200 Projected CRS: NAD83 / Quebec Lambert geometry couleur 1 POINT (-685765 476835) Bleu 3 POINT (-480113 560159) Violet 5 POINT (-902947 480553) Vert Que se passent-ils si nous inversons les arguments de la fonction st_intersects() ? st_intersects(A, points) Sparse geometry binary predicate list of length 1, where the predicate was `intersects&#39; 1: 1, 3, 5 Dans ce cas, la fonction retourne une liste dune seule combinaison éléments associée au polygone interrogé. Cette fois, les éléments à droite du deux-points correspondent aux indices des points qui satisfont à la condition dintersection. La fonction st_disjoint La fonction st_disjoint() vérifie la condition inverse de la fonction st_intersects(), cest-à-dire labsence dintersection entre deux objets X et Y (figure 7.6). FIGURE 7.6: Combinaisons de géométries disjointes. Image récupérée sur le site de documentation de postgis: http://postgis.net/workshops/postgis-intro/spatial_relationships.html Par exemple, la fonction st_disjoint() permet de confirmer que les points jaune et rouge sont disjoints du polygone A (Figure 7.5) : st_disjoint(A, points) Sparse geometry binary predicate list of length 1, where the predicate was `disjoint&#39; 1: 2, 4 # ou encore points$couleur[st_disjoint(A, points,sparse = FALSE)] [1] &quot;Rouge&quot; &quot;Jaune&quot; La fonction st_crosses La fonction st_crosses() vérifie si deux objets spatiaux X et Y se croisent. Cette fonction est donc similaire à la fonction st_intersects() mais elle contient des conditions supplémentaires: lintersection entre les deux géométries inclue une partie mais pas lentièreté de leurs intérieurs, la dimension géométrique de lintersection doit être inférieure à la dimension maximale des deux géométries, lintersection ne peut être égale à lune ou lautre des géométries. La figure 7.7 illustre différentes combinaisons de géométries qui satisfont à la condition st_crosses. FIGURE 7.7: Combinaisons de géométries qui se croisent. Image récupérée sur le site de documentation de postgis: http://postgis.net/workshops/postgis-intro/spatial_relationships.html Donnons quelques exemples pour démontrer en quoi la fonction st_crosses() diffère de la fonction st_intersects(). Pour ce faire, considérons les géométries illustrées à la figure 7.8. FIGURE 7.8: Exemples illustrant la fonction st_crosses(). Bien que toutes ces géométries sintersectent, elles ne se croisent pas toutes. Vérifions dabord la condition dintersection  : st_intersects(A,trait_bleu) Sparse geometry binary predicate list of length 1, where the predicate was `intersects&#39; 1: 1 st_intersects(A,trait_mauve) Sparse geometry binary predicate list of length 1, where the predicate was `intersects&#39; 1: 1 st_intersects(A,B) Sparse geometry binary predicate list of length 1, where the predicate was `intersects&#39; 1: 1 Puis, la condition de croisement  : st_crosses(A,trait_bleu) Sparse geometry binary predicate list of length 1, where the predicate was `crosses&#39; 1: (empty) st_crosses(A,trait_mauve) Sparse geometry binary predicate list of length 1, where the predicate was `crosses&#39; 1: 1 st_crosses(A,B) Sparse geometry binary predicate list of length 1, where the predicate was `crosses&#39; 1: (empty) Le trait bleu ne croise pas le polygone A car lintersection entre ces deux géométries est égale au trait bleu. De plus, les polygones A et B ne se croisent pas non plus car leur intersection forme un polygone. Un polygone a une dimension géométrique de 2, tout comme les polygones A et B. Ainsi, seul le trait mauve croise le polygone A. En effet, une partie seulement de sa géométrie intersecte le polygone A, le reste étant situé à lextérieur du polygone. La fonction st_overlaps La fonction st_overlaps() vérifie si lintersection entre deux géométries de même dimension possède aussi la même dimension. De plus, cette intersection ne peut être égale à une des deux géométries interrogées. La figure 7.9 illustre différentes combinaisons de géométries qui satisfont à la condition de superposition. FIGURE 7.9: Combinaisons de géométries qui se superposent. Image récupérée sur le site de documentation de postgis: http://postgis.net/workshops/postgis-intro/spatial_relationships.html Considérons les polygones A, B, ainsi que celui de lAbitibi-Témiscamingue illustrés à la figure 7.10. FIGURE 7.10: Exemples illustrant la fonction st_overlaps(). Les polygones A et B satisfont la condition de superposition car leur intersection est aussi un polygone. Par ailleurs le polygone A et celui de lAbitibi ne satisfont pas à la condition de superposition car lintersection est identique au polygone de lAbitibi-Témiscamingue. st_overlaps(A,B) Sparse geometry binary predicate list of length 1, where the predicate was `overlaps&#39; 1: 1 st_overlaps(Abitibi,A) Sparse geometry binary predicate list of length 1, where the predicate was `overlaps&#39; 1: (empty) La fonction st_touches La fonction st_touches() vérifie si deux objets X et Y ont au moins un point en commun sans toutefois que leurs interieurs sintersectent. La figure 7.11 illustre différentes combinaisons de géométries qui se touchent. FIGURE 7.11: Combinaisons de géométries qui se touchent. Image récupérée sur le site de documentation de postgis: http://postgis.net/workshops/postgis-intro/spatial_relationships.html Considérons par exemple les objets spatiaux illustrés à la figure ??  : La fonction st_touches() nous permet de vérifier que le polygone B, en rouge, touche au trait mauve et que le polygone A, en bleu, touche au point vert. Par ailleurs, la fonction confirme aussi que le polygone A ne touche pas au point bleu car ce sont leurs intérieurs qui sintersectent. La même situation sobserve pour les polygones A et B qui partagent plus que leurs frontières. Cependant les polygones de lAbitibi-Témiscamingue, en vert, et de la Mauricie, en jaune, sintersectent seulement le long de leurs frontières et ainsi se touchent. st_touches(B, trait_mauve) Sparse geometry binary predicate list of length 1, where the predicate was `touches&#39; 1: 1 st_touches(A, point_vert) Sparse geometry binary predicate list of length 1, where the predicate was `touches&#39; 1: 1 st_touches(A, point_bleu) Sparse geometry binary predicate list of length 1, where the predicate was `touches&#39; 1: (empty) st_touches(A,B) Sparse geometry binary predicate list of length 1, where the predicate was `touches&#39; 1: (empty) st_touches(Abitibi,Mauricie) Sparse geometry binary predicate list of length 1, where the predicate was `touches&#39; 1: 1 Les fonctions st_within et st_contains La fonction st_within(X,Y) vérifie si lobjet X est entièrement à lintérieur de lobjet Y. À lopposé, la fonction st_contains(X,Y) vérifie si lobjet X contient entièrement lobjet Y. Lordre des arguments est donc important dans lutilisation de ces deux fonctions. La figure 7.12 illustre différentes combinaisons de géométries qui sont contenues dans une autre géométrie. FIGURE 7.12: Combinaisons de géométries qui contiennent ou sont contenues dans une autre géométrie. Image récupérée sur le site de documentation de postgis: http://postgis.net/workshops/postgis-intro/spatial_relationships.html Pour illustrer ces fonctions, considérons les objets spatiaux illustrés à la figure 7.13  : FIGURE 7.13: Exemples illustrant les fonctions st_contains() et st_within(). La fonction st_contains() nous permet de vérifier que le polygone A, en bleu, contient le point bleu et le trait bleu. Par contre, le polygone A ne contient pas le trait mauve puisque ce dernier nest pas entièrement à lintérieur de A. De plus, le contour rose du polygone B contient entièrement le trait mauve. st_contains(A, point_bleu) Sparse geometry binary predicate list of length 1, where the predicate was `contains&#39; 1: 1 st_contains(A, trait_bleu) Sparse geometry binary predicate list of length 1, where the predicate was `contains&#39; 1: 1 st_contains(A, trait_mauve) Sparse geometry binary predicate list of length 1, where the predicate was `contains&#39; 1: (empty) st_contains(contour_rose, trait_mauve) Sparse geometry binary predicate list of length 1, where the predicate was `contains&#39; 1: 1 La fonction st_contains() comporte une subtilité qui peut être trompeuse. La condition st_contains(X,Y) est satisfaite, cest-à-dire, lobject X contient lobjet Y, si et seulement si aucun points de Y se trouve à lextérieur de X, et quau moins un point de Y se trouve à lintérieur de X45. En particulier, ceci signifie quun polygone ne contient jamais sa frontière. Ainsi, dans lillustration de la figure 7.13, le polygone B, en rouge, ne contient pas le contour rose. Le polygone B ne contient pas non plus le trait mauve. Cependant, il contient le trait vert car ce dernier comporte des points à lintérieur du polygone B. st_contains(B, contour_rose) Sparse geometry binary predicate list of length 1, where the predicate was `contains&#39; 1: (empty) st_contains(B, trait_mauve) Sparse geometry binary predicate list of length 1, where the predicate was `contains&#39; 1: (empty) st_contains(B, trait_vert) Sparse geometry binary predicate list of length 1, where the predicate was `contains&#39; 1: 1 La fonction st_contains() vérifie exactement la condition inverse de la fonction st_within() : st_within(point_bleu, A) Sparse geometry binary predicate list of length 1, where the predicate was `within&#39; 1: 1 st_within(trait_bleu, A) Sparse geometry binary predicate list of length 1, where the predicate was `within&#39; 1: 1 st_within(trait_mauve, A) Sparse geometry binary predicate list of length 1, where the predicate was `within&#39; 1: (empty) st_within(trait_mauve, contour_rose) Sparse geometry binary predicate list of length 1, where the predicate was `within&#39; 1: 1 st_within(contour_rose, B) Sparse geometry binary predicate list of length 1, where the predicate was `within&#39; 1: (empty) st_within(trait_mauve, B) Sparse geometry binary predicate list of length 1, where the predicate was `within&#39; 1: (empty) st_within(trait_vert, B) Sparse geometry binary predicate list of length 1, where the predicate was `within&#39; 1: 1 Terminons cette sous-section par une remarque importante: La fonction st_join(), vue plus, qui permet de faire une jointure spatiale entre deux objets vectoriels sappuie, par défaut, sur la fonction de confirmation st_intersects(). En effet, la fonction st_join(x,y) identifie la présence dune intersection entre les éléments de x et de y puis assigne les attributs de y aux éléments de x qui satisfont cette condition dintersection. Par aileurs, il est possible dutiliser la fonction st_join() en utilisant dautres opérations topologiques de confirmation que celle par défaut. En effet, il est possible de définir un troisième argument, join, pour préciser une autre opération comme st_contains, st_touches, st_overlaps etc. Donnons un exemple. Pour chaque régions administratives du Québec, déterminons les régions qui lui sont adjacentes. Il sagit ici dutiliser la fonction st_join() avec la condition st_touches : st_join(regions, regions, join = st_touches) Simple feature collection with 76 features and 2 fields Geometry type: GEOMETRY Dimension: XY Bounding box: xmin: -79.76 ymin: 44.99 xmax: -56.93 ymax: 62.58 Geodetic CRS: GCS_Geographic_Coordinate_System First 10 features: Rgns_Ad.x 1 Abitibi-Témiscamingue 1.1 Abitibi-Témiscamingue 1.2 Abitibi-Témiscamingue 2 Bas-Saint-Laurent 2.1 Bas-Saint-Laurent 2.2 Bas-Saint-Laurent 2.3 Bas-Saint-Laurent 3 Capitale-Nationale 3.1 Capitale-Nationale 3.2 Capitale-Nationale Rgns_Ad.y 1 Mauricie 1.1 Nord-du-Québec 1.2 Outaouais 2 Capitale-Nationale 2.1 Chaudière-Appalaches 2.2 Côte-Nord 2.3 Gaspésie - Îles-de-la-Madeleine 3 Bas-Saint-Laurent 3.1 Centre-du-Québec 3.2 Chaudière-Appalaches geometry 1 POLYGON ((-75.52 47.85, -75... 1.1 POLYGON ((-75.52 47.85, -75... 1.2 POLYGON ((-75.52 47.85, -75... 2 POLYGON ((-67.15 49.19, -66... 2.1 POLYGON ((-67.15 49.19, -66... 2.2 POLYGON ((-67.15 49.19, -66... 2.3 POLYGON ((-67.15 49.19, -66... 3 POLYGON ((-72.07 47.95, -72... 3.1 POLYGON ((-72.07 47.95, -72... 3.2 POLYGON ((-72.07 47.95, -72... Cette fonction nous retourne un objet spatial composé de deux attributs. Lattribut de gauche, Rgns_Ad.x donne le nom de chaque polygone des régions administratives de regions alors que lattribut de droite, Rgns_Ad.y, assigne à chacun de ces polygones, le nom dune des régions administrives qui lui est voisine. Puisque chaque polygone possède plus dune région voisine, leur nom et leur géométrie sont répétées pour chaque région voisine. Opérations de mesure Plusieurs fonctions de la bibliothèque sf permettent de calculer des mesures spatiales comme la distance, la superficie, ou la longueur. La fonction st_distance() La fonction st_distance() retourne la distance euclidienne entre deux objets spatiaux. Par exemple, nous pouvons utiliser cette fonction pour calculer la distance entre deux points. Calculons la distance qui sépare la ville de La Pocatière, dont nous avons isolé les coordonnées plus haut, et la ville de Rimouski. # Isoler le point correspondant aux coordonnées de la ville # de Rimouski à partir du shapefile des villes du Québec rimouski &lt;- subset(villes, toponyme == &quot;Rimouski&quot;) # Transformer rimouski dans le même SCR d&#39;unité métrique que la_poc rimouski_nad &lt;- st_transform(rimouski, crs = 32198) # Calculer la distance distance_lapoc_rimou &lt;- st_distance(la_poc_nad, rimouski_nad) distance_lapoc_rimou Units: [m] [,1] [1,] 164694 La distance calculée est de 164693 m, soit environ as.integer(round(distance_lapoc_rimou[1]/1000)) km. Notez que nous avons calculé la distance géométrique et non la distance que lodomètre dune voiture calculerait en voyageant sur lautoroute entre La Pocatière et Rimouski. Observez que la fonction st_distance() retourne aussi lunité de mesure, ici des mètres. En effet, lobjet retourné par cette fonction est de classe units : class(distance_lapoc_rimou) [1] &quot;units&quot; Nous pouvons également utiliser la fonction st_distance() pour calculer la distance entre plusieurs points. Par exemple, considérons le shapefile villes et calculons la distance qui sépare La Pocatière de chacune des villes du Québec. # Transformer le SRC de villes villes_nad &lt;- st_transform(villes, crs = 32198) # Calculer les distances distance_la_poc_villes &lt;- st_distance(villes_nad, la_poc_nad) # Assigner le nom des villes rownames(distance_la_poc_villes) &lt;- villes$toponyme colnames(distance_la_poc_villes) &lt;- &quot;La Pocatière&quot; # Les premières entrées head(distance_la_poc_villes) Units: [m] La Pocatière Blanc-Sablon 1032719 Lourdes-de-Blanc-Sablon 1027494 Nemiscau 654358 Waskaganish 775654 Saint-Augustin 926883 Chevery 833225 Ou encore, calculons la distance qui sépare chacune des villes du Québec  : distance_villes_villes &lt;- st_distance(villes_nad, villes_nad) colnames(distance_villes_villes) &lt;- villes$toponyme rownames(distance_villes_villes) &lt;- villes$toponyme quelques_villes &lt;- c(49, 154, 314, 549, 639) distance_villes_villes[quelques_villes, quelques_villes] Units: [m] Rouyn-Noranda Québec Gatineau Gaspé Rouyn-Noranda 0 607593 399903 1069375 Québec 607593 0 373067 549266 Gatineau 399903 373067 0 921441 Gaspé 1069375 549266 921441 0 Montréal 514725 231996 163439 778264 Montréal Rouyn-Noranda 514725 Québec 231996 Gatineau 163439 Gaspé 778264 Montréal 0 Cette fois, la fonction st_distance() retourne une matrice pour laquelle chaque entrée correspond à la distance entre deux villes. Cette matrice est bien sûr symétrique et sa diagonale est nulle. Nous pouvons aussi utiliser la fonction st_distance()pour calculer la distance entre un point et un polygone. Par exemple, calculons la distance entre le point correspondant au centre du polygone de lAbitibi-Témiscamingue et le polygone du Saguenay - Lac-Saint-Jean (voir la figure 7.3). st_distance(centre_Abitibi, SagStJean) Units: [m] [,1] [1,] 268327 Notez que pour calculer la distance entre un polygone et un point, ce dernier doit être situé à lextérieur du polygone, sans quoi cette fonction retourne la valeur zéro  : st_distance(centre_Abitibi, Abitibi) Units: [m] [,1] [1,] 0 La distance entre deux polygones se calcule de façon similaire. st_distance(Abitibi, SagStJean, by_element = TRUE) 76459 [m] Cette mesure correspond à la plus petite distance séparant les deux polygones. La fonction st_area() La fonction st_area() calcule la superficie dun polygone. Calculons par exemple la superficie des polygones illustrés à la figure 7.13) : st_area(A) 1.74e+11 [m^2] st_area(B) 2.863e+11 [m^2] st_area(inter_AB) 1.642e+10 [m^2] Remarquez que les unités, ici des mètres carrés, sont fournies. Lobjet retourné par la fonction st_area() est aussi de classe units : class(st_area(A)) [1] &quot;units&quot; La superficie dobjets spatiaux de dimension inférieure à deux est bien nulle : st_area(point_bleu) 0 [m^2] st_area(trait_bleu) 0 [m^2] La fonction st_length() La fonction st_length() calcule la longueur dun objet spatial unidimensionnel (LINESTRING, MULTILINESTRING). st_length(trait_bleu) 227718 [m] st_length(trait_mauve) 361759 [m] st_length(contour_rose) 2095138 [m] Comme pour les fonctions st_distance() et st_area(), la fonction st_length() retourne un objet de classe units. La fonction calcule une longueur nulle pour les polygones ou les points : st_length(A) 0 [m] st_length(point_bleu) 0 [m] La fonction set_units Il peut être pratique de changer les unités de mesure avec lesquelles nous travaillons. Par exemple, utiliser les mètres carrés lorsque nous traitons de larges étendues peut être encombrant. La fonction set_units de la bibliothèque units permet de transformer les unités de mesure dun objet ou den assigner à un objet sans unités. Par exemple, pour les unités de longueur : library(units) udunits database from C:/Users/elise/AppData/Local/R/win-library/4.2/units/share/udunits/udunits2.xml L_m &lt;- st_length(trait_bleu) L_km &lt;- set_units(L_m,km) L_miles &lt;- set_units(L_m, miles) L_m 227718 [m] L_km 227.7 [km] L_miles 141.5 [miles] Et, pour les unités daire : A_m2 &lt;- st_area(A) A_km2 &lt;- set_units(A_m2, km2) A_ha &lt;- set_units(A_m2, ha) # 1 hectare (ha) mesure 100 m x 100 m A_m2 1.74e+11 [m^2] A_km2 174004 [km2] A_ha 17400384 [ha] 7.1.3 Problématique à résoudre Maintenant que nous avons appris les opérations de base pour manipuler les données vectorielles, nous sommes en mesure de résoudre la problématique énoncée au début de cette leçon : Parmi les dix plus grandes villes du Québec, quelle est celle qui dispose du plus grand nombre de parcs nationaux dans un rayon de 70 km ? Les étapes de la démarche de résolution sont les suivantes: Obtenir la taille de la population de chacune des municipalités. Filtrer ces municipalités pour retenir les 10 municipalités ayant la taille de population la plus importante. Lire la géodatabase du réseau de la SÉPAQ. Tracer une zone tampon de 70 km de rayon autour de chacune des dix plus grandes villes. Pour chaque zone, compter le nombre de parcs présent dans la zone tampon de 70 km. Déterminer la ville qui compte le plus grand nombre de parcs dans la zone tampon qui lui est associée. Commençons! 1. Taille des populations pour chaque municipalité Nous devons obtenir la taille de la population de chacune des municipalités québécoises. Nous avons déjà réalisé cette opération lorsque nous avons appris à utiliser la fonction merge(). En effet, nous avons associé à chaque municipalité contenue dans le shapefile villes la taille de sa population telle que donnée dans le dataframe pop. Nous avons utilisé la fonction merge() sur les colonnes toponyme et munnom qui agissent comme dénominateur commun des deux jeux de données. Voici un rappel de lopération exécutée : villes_pop &lt;- merge(x = villes, y = pop, by.x=&quot;toponyme&quot;, by.y=&quot;munnom&quot;) names(villes_pop)[2:3] &lt;- c(&quot;superficie&quot;, &quot;population&quot;) # Nous avions aussi changer le nom des colonnes! head(villes_pop) Simple feature collection with 6 features and 3 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -78.2 ymin: 45.65 xmax: -62.08 ymax: 60.81 Geodetic CRS: Geographic Coordinate System toponyme superficie population 1 Acton Vale 91.1 7733 2 Aguanish 680.6 238 3 Akulivik 82.3 678 4 Albanel 205.0 2232 5 Alma 232.6 30831 6 Amherst 249.5 1459 geometry 1 POINT (-72.56 45.65) 2 POINT (-62.08 50.22) 3 POINT (-78.2 60.81) 4 POINT (-72.44 48.88) 5 POINT (-71.65 48.54) 6 POINT (-64.21 45.83) 2. Dix municipalités les plus grandes Nous devons filtrer lobjet villes_pop et sélectionner les 10 municipalités de plus grande population. Tout dabord, il sagit dordonner lattribut population contenu dans lobjet villes_pop. Pour ce faire, nous allons utiliser la fonction order(): villes_pop &lt;- villes_pop[order(villes_pop$population, decreasing = TRUE), ] Lobjet villes_pop est maintenant ordonné de manière décroissante en fonction de la taille de la population des municipalités. Ainsi, les 10 premières lignes de cet objet correspondent aux 10 municipalités les plus grandes du Québec. On peut donc assigner les 10 premières lignes à un nouvelle objet intitulé top10_villes: top10_villes &lt;- villes_pop[1:10, ] top10_villes Simple feature collection with 10 features and 3 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -75.64 ymin: 45.31 xmax: -71.18 ymax: 46.81 Geodetic CRS: Geographic Coordinate System toponyme superficie population 204 Montréal 431.7 1801546 240 Québec 485.2 546958 166 Laval 266.8 439754 94 Gatineau 380.6 286755 175 Longueuil 122.6 249338 442 Sherbrooke 366.0 169136 174 Lévis 498.3 147440 456 Trois-Rivières 334.2 138134 449 Terrebonne 158.5 117664 336 Saint-Jean-sur-Richelieu 233.7 98036 geometry 204 POINT (-73.56 45.51) 240 POINT (-71.21 46.81) 166 POINT (-73.75 45.55) 94 POINT (-75.64 45.48) 175 POINT (-73.52 45.54) 442 POINT (-71.89 45.4) 174 POINT (-71.18 46.8) 456 POINT (-72.54 46.34) 449 POINT (-73.63 45.69) 336 POINT (-73.25 45.31) Visualisons ce nouvel objet avec la fonction mapview(). mapview(top10_villes, zcol= &quot;population&quot;) 3. Géodatabase du réseau de la SÉPAQ La troisième étape consiste à charger la couche dinformations spatiales contenant les différentes aires récréatives du Québec. Cette information se trouve à lintérieur de la géodatabase parcs.gdb disponible dans le répertoire Module7_donnees que vous avez téléchargé au début de la leçon. Comme vu dans le module 4, les géodatabase permettent de contenir plusieurs couches vectorielles. Nous devons donc lire la géodatabase et explorer les différentes couches afin de déterminer celle qui correspond aux aires récréatives. st_layers(&quot;Module7/Module7_donnees/parcs.gdb&quot;) Driver: OpenFileGDB Available layers: layer_name geometry_type features fields crs_name 1 Terafc_s Multi Polygon 5 18 NAD83 2 Terpnq_s Multi Polygon 27 18 NAD83 3 Terfer_s Multi Polygon 1 18 NAD83 4 Terpla_s Multi Polygon 27 18 NAD83 5 Terpma_s Multi Polygon 1 18 NAD83 6 Terpnc_s Multi Polygon 4 18 NAD83 7 Terrec_s Multi Polygon 72 18 NAD83 8 Terref_s Multi Polygon 21 18 NAD83 9 Terrfa_s Multi Polygon 9 18 NAD83 10 Terrnf_s Multi Polygon 8 18 NAD83 11 Terrom_s Multi Polygon 28 18 NAD83 12 Tersfo_s Multi Polygon 1 18 NAD83 13 Tertec_s Multi Polygon 1 18 NAD83 14 Terzec_s Multi Polygon 86 18 NAD83 15 Terepa_s Multi Polygon 1 18 NAD83 16 Terpde_s Multi Polygon 189 18 NAD83 17 Terpre_s Multi Polygon 17 18 NAD83 Nous pouvons remarquer que les intitulés des différentes couches ne sont pas bien définis. Il faut donc prendre le temps de regarder la documentation accessible sur le site de données ouvertes Québec. Ne vous inquiétez pas, je lai fait pour vous! En sintéressant à la structure de données et à la nomenclature utilisée et décrite, nous pouvons déterminer que la couche terpnq_s correspond aux territoires des parc nationaux du Québec. Nous pouvons donc faire la lecture de la géodatabase avec la fonction st_read() en précisant cette couche à laide de largument layer. parcs_nationaux &lt;- st_read(&quot;Module7/Module7_donnees/parcs.gdb&quot;, layer = &quot;terpnq_s&quot;) Reading layer `terpnq_s&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module7\\Module7_donnees\\parcs.gdb&#39; using driver `OpenFileGDB&#39; Simple feature collection with 27 features and 18 fields Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin: -79.39 ymin: 45.29 xmax: -62.41 ymax: 61.45 Geodetic CRS: NAD83 Visualisons les polygones de parcs_nationaux. mapview(parcs_nationaux, zcol = &quot;TRQ_NM_TER&quot;, legend = FALSE) Notez que lattribut TRQ_NM_TER de lobjet parcs_nationaux correspond au nom de chaque parc national. parcs_nationaux$TRQ_NM_TER [1] &quot;Parc national des Pingualuit&quot; [2] &quot;Parc national Kuururjuaq&quot; [3] &quot;Parc national Ulittaniujalik&quot; [4] &quot;Parc national Tursujuq&quot; [5] &quot;Parc national d&#39;Anticosti&quot; [6] &quot;Parc national de la Gaspésie&quot; [7] &quot;Parc national de la Pointe-Taillon&quot; [8] &quot;Parc national des Monts-Valin&quot; [9] &quot;Parc national d&#39;Aiguebelle&quot; [10] &quot;Parc national de l&#39;Île-Bonaventure-et-du-Rocher-Percé&quot; [11] &quot;Parc national du Fjord-du-Saguenay&quot; [12] &quot;Parc national du Bic&quot; [13] &quot;Parc national de Miguasha&quot; [14] &quot;Parc national des Hautes-Gorges-de-la-Rivière-Malbaie&quot; [15] &quot;Parc national du Lac-Témiscouata&quot; [16] &quot;Parc national des Grands-Jardins&quot; [17] &quot;Parc national de la Jacques-Cartier&quot; [18] &quot;Parc national d&#39;Opémican&quot; [19] &quot;Parc national du Mont-Tremblant&quot; [20] &quot;Parc national de Frontenac&quot; [21] &quot;Parc national des Îles-de-Boucherville&quot; [22] &quot;Parc national de Plaisance&quot; [23] &quot;Parc national du Mont-Saint-Bruno&quot; [24] &quot;Parc national d&#39;Oka&quot; [25] &quot;Parc national du Mont-Mégantic&quot; [26] &quot;Parc national de la Yamaska&quot; [27] &quot;Parc national du Mont-Orford&quot; 4. Zones tampons autour des plus grandes municipalités Nous traçons maintenant une zone tampon (POLYGON) de 70 km de rayon autour de chaque municipalité (POINT) du shapefile top10_villes. Pour se faire, nous allons utiliser la fonction st_buffer(). Avant de réaliser cette opération, nous devons vérifier que le système de coordonnées de référence de lobjet spatial top10_villes est défini en unité métrique. En effet, la distance de 70 km pourrait être interprétée comme étant 70 degrés si lunité de la projection était en degré. Attention, cette erreur est très courante! Lorsque lon veut calculer des distances euclidiennes, il faut toujours sassurer que lunité du système de projection est en mètre et non en degré. st_crs(top10_villes)$proj4string [1] &quot;+proj=longlat +ellps=GRS80 +no_defs&quot; +proj=longlat atteste que la projection est en degré. Nous allons donc reprojeter lobjet top10_villes dans le système de coordonnées de référence NAD83 qui est métrique et dont le EPSG est 32198. NAD83 correspond au système de coordonnées Conique conforme de Lambert. top10_villes_lcc &lt;- st_transform(top10_villes, crs = 32198) # On valide que les unités sont métriques (+units=m) st_crs(top10_villes_lcc)$proj4string [1] &quot;+proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; Traçons à présent les zones tampon (buffer) autour des municipalités à laide de la fonction st_buffer() comme expliqué précédemment, et visualisons le résultat de cette opération top10_villes_buffer &lt;- st_buffer(top10_villes_lcc, dist = 70e3) # 70 kms en mètres = 70e3 mapview(top10_villes_buffer, zcol = &quot;toponyme&quot;, legend = FALSE) Rappelons que le premier argument de la fonction st_buffer() correspond à lobjet spatial à partir duquel nous créons les zones tampons, et le second argument correspond à la longueur du rayon des zones tampon en mètres (70 km = 70e3 m). 5. Nombre de parcs dans chaque zone tampon Nous allons utiliser la fonction st_intersects() pour déterminer quels parcs de lobjet parcs_nationaux se trouvent, partiellement ou entièrement, à lintérieur de chacune des zones tampons de lobjet top10_villes_buffer. Avant de réaliser cette opération spatiale, nous devons nous assurer que les deux objets spatiaux (top10_villes_buffer et parcs_nationaux) utilisent le même système de coordonnées de référence. st_crs(top10_villes_buffer) == st_crs(parcs_nationaux) [1] FALSE Puisque la réponse est négative, transformons le SCR de lobjet parcs_nationaux. parcs_nationaux_lcc = st_transform(parcs_nationaux, crs = st_crs(top10_villes_buffer)) Nous pouvons maintenant utiliser la fonction st_intersects(): st_intersects(x = top10_villes_buffer, y = parcs_nationaux_lcc, sparse = FALSE) [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [1,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [2,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [3,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [4,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [5,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [6,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [7,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [8,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [9,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [10,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [,9] [,10] [,11] [,12] [,13] [,14] [,15] [,16] [1,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [2,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [3,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [4,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [5,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [6,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [7,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [8,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [9,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [10,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [1,] FALSE FALSE FALSE FALSE TRUE FALSE TRUE TRUE [2,] TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [3,] FALSE FALSE FALSE FALSE TRUE FALSE TRUE TRUE [4,] FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE [5,] FALSE FALSE FALSE FALSE TRUE FALSE TRUE TRUE [6,] FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE [7,] TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [8,] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE [9,] FALSE FALSE FALSE FALSE TRUE FALSE TRUE TRUE [10,] FALSE FALSE FALSE FALSE TRUE FALSE TRUE TRUE [,25] [,26] [,27] [1,] FALSE FALSE FALSE [2,] FALSE FALSE FALSE [3,] FALSE FALSE FALSE [4,] FALSE FALSE FALSE [5,] FALSE FALSE FALSE [6,] TRUE TRUE TRUE [7,] FALSE FALSE FALSE [8,] FALSE FALSE FALSE [9,] FALSE FALSE FALSE [10,] FALSE TRUE FALSE La fonction st_intersects avec largument sparse = FALSE retourne une matrice avec en ligne les zones tampons des 10 plus grandes villes (argument x ci-dessus) et en colonne, les 27 parcs nationaux du Québec (argument y ci-dessus). Pour chacune des combinaisons, la valeur boléenne renvoyée (TRUE ou FALSE) spécifie si les deux polygones se chevauchent (partiellement ou non). Lune des propriétés intéressante des valeurs boléennes (TRUE ou FALSE), renvoyées par la fonction st_intersects, est que la valeur TRUE peut être interprétée par R comme une valeur de 1 et FALSE comme une valeur de 0. Il est donc possible de réaliser des opérations mathématiques sur des valeurs boléennes. Par exemple, nous pouvons effectuer une sommation sur les lignes (zones tampons de chaque grande municipalité) afin de déterminer combien de parcs nationaux se trouvent à lintérieur des zones tampons (c-à-d combien déléments ont la valeur TRUE). rowSums(st_intersects(x = top10_villes_buffer, y = parcs_nationaux_lcc, sparse = FALSE)) [1] 3 1 3 1 3 4 1 0 3 4 Consignons à présent ces valeurs dans une nouvelle colonne de la table dattributs de lobjet top10_villes. top10_villes$nbr_parcs &lt;- rowSums(st_intersects(x = top10_villes_buffer, y = parcs_nationaux_lcc, sparse = FALSE)) top10_villes Simple feature collection with 10 features and 4 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -75.64 ymin: 45.31 xmax: -71.18 ymax: 46.81 Geodetic CRS: Geographic Coordinate System toponyme superficie population 204 Montréal 431.7 1801546 240 Québec 485.2 546958 166 Laval 266.8 439754 94 Gatineau 380.6 286755 175 Longueuil 122.6 249338 442 Sherbrooke 366.0 169136 174 Lévis 498.3 147440 456 Trois-Rivières 334.2 138134 449 Terrebonne 158.5 117664 336 Saint-Jean-sur-Richelieu 233.7 98036 geometry nbr_parcs 204 POINT (-73.56 45.51) 3 240 POINT (-71.21 46.81) 1 166 POINT (-73.75 45.55) 3 94 POINT (-75.64 45.48) 1 175 POINT (-73.52 45.54) 3 442 POINT (-71.89 45.4) 4 174 POINT (-71.18 46.8) 1 456 POINT (-72.54 46.34) 0 449 POINT (-73.63 45.69) 3 336 POINT (-73.25 45.31) 4 6. Ville qui compte le plus grand nombre de parcs Pour répondre à la question posée, ordonnons la table dattributs de lobjet top10_villes en se basant sur la nouvelle colonne nbr_parcs. top10_villes &lt;- top10_villes[order(top10_villes$nbr_parcs, decreasing = TRUE), ] top10_villes Simple feature collection with 10 features and 4 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -75.64 ymin: 45.31 xmax: -71.18 ymax: 46.81 Geodetic CRS: Geographic Coordinate System toponyme superficie population 442 Sherbrooke 366.0 169136 336 Saint-Jean-sur-Richelieu 233.7 98036 204 Montréal 431.7 1801546 166 Laval 266.8 439754 175 Longueuil 122.6 249338 449 Terrebonne 158.5 117664 240 Québec 485.2 546958 94 Gatineau 380.6 286755 174 Lévis 498.3 147440 456 Trois-Rivières 334.2 138134 geometry nbr_parcs 442 POINT (-71.89 45.4) 4 336 POINT (-73.25 45.31) 4 204 POINT (-73.56 45.51) 3 166 POINT (-73.75 45.55) 3 175 POINT (-73.52 45.54) 3 449 POINT (-73.63 45.69) 3 240 POINT (-71.21 46.81) 1 94 POINT (-75.64 45.48) 1 174 POINT (-71.18 46.8) 1 456 POINT (-72.54 46.34) 0 Nous constatons que Sherbrooke et Saint-Jean-sur-Richelieu disposent toutes deux du plus grand nombre (4) de parcs nationaux dans un rayon de 70 km! Le centre géométrique dune forme planaire est la moyenne des positions de tous les points constituants la forme. Vous pouvez trouver des informations supplémentaires sur le centroïde [ici]^(http://wiki.gis.com/wiki/index.php/Centroid). https://geocompr.robinlovelace.net/spatial-operations.html#topological-relations http://lin-ear-th-inking.blogspot.com/2007/06/subtleties-of-ogc-covers-spatial.html "],["ex_map_vec.html", "7.2 Exercices", " 7.2 Exercices Dans cette section, vous mettrez en pratique certains concepts vus dans la section leçon de ce module. Bien que la réponse à chaque question soit disponible, il est très important de tenter dy répondre par vous même! Question 1 a) Construire un polygone de la forme dun quadrilatère dont les sommets correspondent aux municipalités suivantes: Blanc-Sablon, Gaspé, Ivujivik et Chisasibi. Réponse Utiliser la fonction subset() pour filtrer le shapefile municipalites et isoler ces quatres villes. Selection &lt;- subset(villes, (toponyme == &quot;Blanc-Sablon&quot;) | (toponyme == &quot;Gaspé&quot;) | (toponyme == &quot;Ivujivik&quot;) | (toponyme == &quot;Chisasibi&quot;)) Selection Simple feature collection with 4 features and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -78.9 ymin: 48.83 xmax: -57.13 ymax: 62.42 Geodetic CRS: Geographic Coordinate System toponyme geometry 1 Blanc-Sablon POINT (-57.13 51.43) 549 Gaspé POINT (-64.48 48.83) 710 Chisasibi POINT (-78.9 53.78) 718 Ivujivik POINT (-77.91 62.42) Le symbole | signifie et. Combiner ces quatres villes (points) en un seul objet spatial (multipoints) en utilisant la fonction st_combine() : Combo_Selection &lt;- st_combine(Selection) Combo_Selection Geometry set for 1 feature Geometry type: MULTIPOINT Dimension: XY Bounding box: xmin: -78.9 ymin: 48.83 xmax: -57.13 ymax: 62.42 Geodetic CRS: Geographic Coordinate System MULTIPOINT ((-57.13 51.43), (-64.48 48.83), (-7... Transformer cet objet multipoints en polygone en utilisant la fonction st_cast() : Poly_Selection &lt;- st_cast(Combo_Selection, to = &quot;POLYGON&quot;) Poly_Selection Geometry set for 1 feature Geometry type: POLYGON Dimension: XY Bounding box: xmin: -78.9 ymin: 48.83 xmax: -57.13 ymax: 62.42 Geodetic CRS: Geographic Coordinate System POLYGON ((-57.13 51.43, -64.48 48.83, -78.9 53.... Confirmer votre réponse en visualisant le polygone formé : mapview(Poly_Selection) b) Quelle est la superficie, en km, de ce polygone? Réponse Sassurer dabord que le polygone est représenté dans une projection métrique : st_crs(Poly_Selection)$proj4string [1] &quot;+proj=longlat +ellps=GRS80 +no_defs&quot; +proj=longlat atteste que la projection est en degré. Reprojeter lobjet dans le SCR NAD83 dont le EPSG est 32198 : Poly_Selection_nad83 &lt;- st_transform(Poly_Selection, crs = 32198) st_crs(Poly_Selection_nad83)$proj4string [1] &quot;+proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs&quot; Les unités sont à présent en mètres. Calculer la superficie du polygone en utilisant la fonction st_area() et convertisser les unités en \\(km^2\\) en utilisant la fonction set_units() : Aire &lt;- st_area(Poly_Selection_nad83) Aire_km2 &lt;- set_units(Aire, km2) Aire_km2 1020565 [km2] Question 2 a) Combien de villes se trouvent dans une zone tampon de 20 km autour de la frontière séparant les régions administratives des Laurentides et de Lanaudière. Réponse Utiliser la fonction subset() pour filtrer le shapefile regions et isoler les polygones correspondants aux Laurentides et à Lanaudière. regions_nad &lt;- st_transform(regions, crs = 32198) #utiliser une projection métrique Laurentides &lt;- subset(regions_nad, Rgns_Ad == &quot;Laurentides&quot;) Lanaudiere &lt;- subset(regions_nad, Rgns_Ad == &quot;Lanaudière&quot;) Trouver la frontière entre les deux régions en utilisant la fonction st_intersection() : Frontiere &lt;- st_intersection(Laurentides, Lanaudiere) mapview(Frontiere) La visualisation permet de valider votre calcul. Créer maintenant une zone tampon de 50 km autour de la frontière en utilisant la fonction st_buffer : Frontiere_tampon &lt;- st_buffer(Frontiere, dist = 20e3) mapview(Frontiere_tampon) Utiliser à nouveau la fonction st_intersection() pour trouver les municipalités à lintérieur de la zone tampon. Il sagit, en effet, de trouver lintersection entre les shapeliles villes et Frontiere_tampon. villes_nad &lt;- st_transform(villes, crs = 32198) #utiliser une projection métrique Villes_Frontiere_tampon &lt;- st_intersection(villes_nad, Frontiere_tampon) mapview(Villes_Frontiere_tampon) Utiliser la fonction nrow() pour trouver le nombre de villes dans la zone tampon. nrow(Villes_Frontiere_tampon) [1] 28 b) Calculer la taille de la population qui habite cette zone tampon. Réponse Utiliser la fonction merge() pour combiner le tableau pop listant la taille des populations municipales à lobjet Villes_Frontiere_tampon défini plus haut. Villes_Frontiere_tampon_pop &lt;- merge(x = Villes_Frontiere_tampon, y = pop, by.x = &quot;toponyme&quot;, by.y = &quot;munnom&quot; ) head(Villes_Frontiere_tampon_pop) Simple feature collection with 6 features and 5 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -421200 ymin: 187600 xmax: -396100 ymax: 246500 Projected CRS: NAD83 / Quebec Lambert toponyme Rgns_Ad Rgns_Ad.1 msuperf mpopul 1 Blainville Laurentides Lanaudière 55.4 60838 2 Boisbriand Laurentides Lanaudière 29.5 26899 3 Chertsey Laurentides Lanaudière 302.1 4816 4 Deux-Montagnes Laurentides Lanaudière 7.3 17998 5 Laval Laurentides Lanaudière 266.8 439754 6 Mascouche Laurentides Lanaudière 107.6 49466 geometry 1 POINT (-419531 202664) 2 POINT (-415976 194824) 3 POINT (-416660 246456) 4 POINT (-421211 187607) 5 POINT (-409628 187891) 6 POINT (-396135 208723) Utiliser la fonction sum() pour calculer la population totale comprise dans la zone tampon. sum(Villes_Frontiere_tampon_pop$mpopul) [1] 977256 Une autre façon dobtenir le même résultat est dutiliser la fonction aggregate() : villes_nad_pop &lt;- merge(x = villes_nad, y = pop, by.x = &quot;toponyme&quot;, by.y = &quot;munnom&quot; ) aggregate(villes_nad_pop[&quot;mpopul&quot;], by = Frontiere_tampon, FUN = sum) Simple feature collection with 1 feature and 1 field Geometry type: POLYGON Dimension: XY Bounding box: xmin: -496800 ymin: 180900 xmax: -386800 ymax: 459700 Projected CRS: NAD83 / Quebec Lambert mpopul geometry 10 977256 POLYGON ((-489069 423212, -... Question 3 Trouver les régions administratives traversées par la ligne reliant la ville de Sherbrooke à celle de Fermont. Réponse Utiliser la fonction subset() pour isoler les points du shapefile villes_nad correspondants aux villes de Sherbrooke et de Fermont. Sherb_Fermont &lt;- subset(villes_nad, (toponyme == &quot;Sherbrooke&quot;) | (toponyme == &quot;Fermont&quot;)) mapview(Sherb_Fermont) Utiliser la fonction st_combine() pour combiner ces deux points en une seule géométrie multipoint. Sherb_Fermont_points &lt;- st_combine(Sherb_Fermont) Utiliser la fonction st_cast() pour transformer la géométrie multipoint en ligne. Sherb_Fermont_ligne &lt;- st_cast(Sherb_Fermont_points, to = &quot;LINESTRING&quot;) mapview(Sherb_Fermont_ligne) Utiliser maintenant la fonction st_crosses pour déterminer les régions administratives traversées par cette ligne. regions_nad[st_crosses(regions_nad, Sherb_Fermont_ligne, sparse = FALSE ),] Simple feature collection with 6 features and 1 field Attribute-geometry relationship: 0 constant, 1 aggregate, 0 identity Geometry type: GEOMETRY Dimension: XY Bounding box: xmin: -434800 ymin: 117900 xmax: 787400 ymax: 1229000 Projected CRS: NAD83 / Quebec Lambert Rgns_Ad 3 Capitale-Nationale 4 Centre-du-Québec 5 Chaudière-Appalaches 6 Côte-Nord 7 Estrie 17 Saguenay - Lac-Saint-Jean geometry 3 POLYGON ((-265892 445785, -... 4 POLYGON ((-274244 292963, -... 5 POLYGON ((-127822 380938, -... 6 MULTIPOLYGON (((69033 12183... 7 POLYGON ((-230167 207127, -... 17 POLYGON ((-265892 445785, -... Utiliser la fonction mapview() pour valider visuellement votre réponse. regions_traversees &lt;- regions_nad[st_crosses(regions_nad, Sherb_Fermont_ligne, sparse = FALSE ),] mapview(regions_traversees) + mapview(Sherb_Fermont_ligne) Question 4 La problématique résolue à la fin de la leçon, nous a permis de déterminer que 4 parcs de la SÉPAQ se trouvent dans un rayon de 70 km de la municipalité de Saint-Jean-sur-Richelieu. Quelle est la superficie totale couverte par ces parcs à lintérieur de ce rayon ? Réponse À partir de lobjet spatial top10_villes_buffer créé plus tôt, isoler la zone tampon autour de la municipalité de Saint-Jean-sur-Richelieu en utilisant la fonction subset(). SJSR_tampon &lt;- subset(top10_villes_buffer, toponyme == &quot;Saint-Jean-sur-Richelieu&quot;) Utiliser la fonction st_intersection pour trouver les parcs du shapefile parcs_nationaux_lcc qui intersectent cette zone tampon. Parcs_SJSR_tampon &lt;- st_intersection(parcs_nationaux_lcc, SJSR_tampon) mapview(Parcs_SJSR_tampon) + mapview(SJSR_tampon, col.regions = &quot;red&quot;, alpha.regions = 0.2) Utiliser la fonction st_area() pour déterminer la superficie de chacun des parcs. Aire_Parcs_SJSR_tampon &lt;- st_area(Parcs_SJSR_tampon) Aire_Parcs_SJSR_tampon Units: [m^2] [1] 8030419 8860076 22905154 13477000 Utiliser la fonction sum() pour déterminer la superficie totale, puis la fonction set_units() pour transformer les mètres carrés en hectares. AireTot_Parcs_SJSR_tampon &lt;- sum(Aire_Parcs_SJSR_tampon) AireTot_Parcs_SJSR_tampon &lt;- set_units(AireTot_Parcs_SJSR_tampon, ha) AireTot_Parcs_SJSR_tampon 5327 [ha] "],["manip_mat.html", "Module 8 Manipulation de données matricielles", " Module 8 Manipulation de données matricielles Cette leçon porte sur la manipulation des données spatiales matricielles. À la fin de ce module vous saurez: Attribuer des catégories aux valeurs des cellules dun raster. Filtrer des cellules dun raster selon leur valeur. Filtrer des cellules dun raster selon leurs coordonnées. Découper un raster en utilisant un rectangle de délimitation. Découper un raster en utilisant un objet vectoriel. Combiner des rasters pour en former un seul. Déterminer les coordonnées dune cellule à partir de son indice. Déterminer lobjet spatial le plus proche dun autre. Vous utiliserez les bibliothèques suivantes: mapview raster sf elevatr Vous apprendrez à utiliser les fonctions suivantes: reclassify() crop() mask() extract() st_sfc(), st_as_sf() st_nearest_feature() xyFromCell() cumsum() get_elev_raster() De plus, vous utiliserez aussi des fonctions vues dans les modules précédents: nrow(), ncol() et ncell() summary() unique() subset() which(), which.max() max() as.data.frame(), data.frame() extent() plot() crs(), st_crs() st_polygon() st_intersects() Vous utiliserez les données suivantes: Dans la section Leçon ainsi que dans la section Exercices, vous utiliserez des données matricielles délévation pour le Québec, des données vectorielles des sentiers de randonnées de la SÉPAQ, ainsi que les limites de quatre parcs nationaux identifiés au module 7. "],["lecon_mat_mani.html", "8.1 Leçon", " 8.1 Leçon Au module 5, vous avez appris les fonctions essentielles pour lire et visualiser des données spatiales matricielles sous R. Le présent module vous amènera maintenant à manipuler conjointement des données matricielles et vectorielles. Dans un premier temps, cette leçon vous enseignera le fonctionnement dopérations de base sur les données matricielles. Dans un second temps, cette leçon vous guidera dans la résolution dune problèmatique qui nécessite de manipuler des données matricielles. Au cours des différentes étapes permettant de résoudre la problématique, vous mettrez en pratique les diverses fonctions R apprises jusquà maintenant. Plus précisément, nous allons pousser plus loin la problématique étudiée au module 7 en répondant aux deux questions suivantes: Parmi les quatre parcs nationaux de la région de Sherbrooke, lequel dispose du plus haut sommet? Quelle est le profil topographique du sentier se rendant au plus proche de ce sommet? 8.1.1 Télécharger les données Les données Dans cette leçon, nous allons utiliser le modèle délévation numérique aussi appelé Digital Elevation Model (DEM). Cette couche dinformation spatiale est produite par le gouvernement du Canada (accessible sur ce portail). Cette couche est une matrice de données (raster) contenant des valeurs délévation en mètres. Nous allons également nous servir de la base de données vectorielles des sentiers de randonnées de la SÉPAQ (source), ainsi que celle des parcs nationaux de la région de Sherbrooke identifiés au module 7. Afin de faciliter le téléchargement de ces données, lensemble de ces couches dinformations spatiales peuvent être téléchargée en cliquant sur un seul lien: données pour le module 8. Une fois téléchargé, le dossier compressé (zip) doit être dézippé dans votre répertoire de travail. Le dossier Module8_donnees comprend deux sous-dossiers et un fichier: parcs_sherbrooke DEM.tif sentiers_sepaq 8.1.2 Opération de bases Dans cette section, nous allons nous familiariser avec les opérations fréquemment utilisées sur les données matricielles. 8.1.2.1 Importer et visualiser les données Dans allons dabord importer les différentes couches dinformations spatiales dans lenvironnement R. Nous commençons par charger les bibliothèques requises pour importer les données spatiales vectorielles (sf), pour importer les données spatiales matricielles (raster) et pour visualiser ces données (mapview). library(sf) library(raster) library(mapview) Ensuite, nous utilisons la fonction st_read() pour importer le shapefile parcs_sherbrooke qui contient les quatre parcs se situant dans un rayon de 70 km de la municipalité de Sherbrooke (voir la problématique du module 7). parcs &lt;- st_read(&quot;Module8/Module8_donnees/parcs_sherbrooke/parcs_sherbrooke.shp&quot;) Reading layer `parcs_sherbrooke&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module8\\Module8_donnees\\parcs_sherbrooke\\parcs_sherbrooke.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 4 features and 18 fields Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin: -323500 ymin: 151800 xmax: -201900 ymax: 226200 Projected CRS: NAD83 / Quebec Lambert Enfin, nous importons la couche délévation DEM pour la région dintérêt en utilisant la fonction raster(). dem &lt;- raster(&quot;Module8/Module8_donnees/DEM.tif&quot;) Nous visualisons ensuite les deux objets spatiaux afin de valider limportation en utilisant la fonction mapview(). mapview(dem) + mapview(parcs, zcol = &quot;TRQ_NM_&quot;) Notez que lattribut TRQ_NM_ correspond aux noms des parcs nationaux. 8.1.2.2 Filtrer les cellules dun raster Une des opérations les plus fréquentes sur les raster est celle de filtrer les cellules (ou pixels). Ceci peut être fait dans le but de sélectionner des cellules possédant une valeur dattribut particulière. Par exemple, à partir dune couche matricielle des différentes classes dutilisation du sol pour une région donnée, nous pourrions vouloir sélectionner les pixels de la classe Eaux ou encore ceux de la classe Terres humides. Filtrer les cellules peut également être fait dans le but de sélectionner des cellules sur la base de leur localisation spatiale. Par exemple, nous pourrions vouloir choisir les cellules dun raster qui sont à lintérieur des limites administratives dune municipalité. Dans les sous-sections qui suivent, nous présenterons des fonctions qui permettent de réaliser ces deux types dopération de filtrage de données matricielles. Filtrer en utilisant la valeur des cellules Fonction which() Au module 5, nous avons vu comment accéder et manipuler les données de raster en utilisant, entre autres, les fonctions summary() et getValues(). Il est ainsi possible davoir une idée de la distribution des valeurs du raster dem en utilisant la ligne de commande suivante : summary(getValues(dem)) Min. 1st Qu. Median Mean 3rd Qu. Max. 30 211 303 314 410 1174 NA&#39;s 3839 Nous pouvons apercevoir que certaines cellules du raster dem contiennent des valeurs négatives. Notez que ces valeurs ne sont pas aberrantes et signifient simplement que ces pixels se retrouvent en dessous du niveau de la mer. Pour la suite de la leçon (et à titre dexemple), nous allons exclure ces valeurs négatives. En dautres termes, nous allons appliquer un filtre sur les cellules du raster, filtre qui ne laissera passer que les valeurs positives. Plus précisément, nous allons utiliser la fonction which() pour filter les données du raster dem. Rappelons que la fonction which() identifie la position des éléments de valeur TRUE dans un vecteur logique (voir le module 7 pour un rappel). Utilisons donc cette fonction pour trouver les cellules qui ont des valeurs délévation négatives. ind &lt;- which(getValues(dem) &lt; 0) ind integer(0) La ligne de commande ci-dessus retourne les indices des cellules qui satisfont la condition demandée (cest-à-dire avoir une valeur négative). Pour savoir combien de cellules possèdent une valeur délévation négative, nous pouvons tout simplement compter le nombre déléments contenus dans le vecteur retourné par la fonction which(). Si les cellules identifiées étaient nombreuses ou si nous avions besoin de conserver ce nombre en mémoire pour lutiliser dans la suite de notre analyse, nous pourrions obtenir ce compte en utilisant la fonction générale length() qui retourne la taille dun vecteur: nombre &lt;- length(ind) nombre [1] 0 Notons quil est aussi possible daccéder aux valeurs de ces cellules en utilisant les indices ind identifiés: getValues(dem)[ind] numeric(0) Nous observons que les valeurs sont belles et bien négatives! Pour filtrer ces cellules aux valeurs négatives, cest-à-dire exclure ces valeurs de notre analyse, nous allons remplacer leur valeur par le terme NA. Rappelons que NA signifie non applicable. dem[ind] &lt;- NA Voyons maintenant comment cette modification aux valeurs de certaines cellules altère les statistiques générales sur les valeurs du raster dem : summary(getValues(dem)) Min. 1st Qu. Median Mean 3rd Qu. Max. 30 211 303 314 410 1174 NA&#39;s 3839 Lélévation minimale est maintenant de 2 et le nombre de NA a augmenté de 0. Ceci confirme que notre filtre a bien été appliqué. La fonction which() peut aussi être utilisée pour filtrer des données selon des expressions logiques plus complexes. Nous pouvons, par exemple, remplacer getValues(dem) &lt; 0 par getValues(dem) &lt; 0 | getValues(dem) &gt; 1000 pour exclure également les cellules avec des valeurs plus grandes que 1000 m. De plus, il est aussi possible de changer les valeurs des cellules identifiées en dautres valeurs que NA. Fonction reclassify La fonction reclassify() de la bibliothèque raster permet également de filtrer des données matricielles et de leur assigner de nouvelles valeurs. Démontrons son utilisation par un cas simple. Nous allons catégoriser le niveau délévation, cest-à-dire les valeurs du raster dem, en trois catégories: catégorie 1: classe délévation faible allant de 0 à 250 m, catégorie 2: classe délévation modérée allant de 251 à 500 m, catégorie 3: classe délévation forte allant de 501 à 1200 m. Avant de pouvoir utiliser la fonction reclassify() il est nécessaire de construire une matrice indiquant les bornes limites des différentes classes. nouvelles_classes &lt;- matrix(c(0, 250, 1, 250, 500, 2, 500, 1200, 3), nrow = 3, ncol = 3, byrow = TRUE) colnames(nouvelles_classes) &lt;- c(&quot;Limite_min&quot;, &quot;Limite_max&quot;, &quot;nouvelles_classes&quot;) nouvelles_classes Limite_min Limite_max nouvelles_classes [1,] 0 250 1 [2,] 250 500 2 [3,] 500 1200 3 Cette matrice est utilisée comme argument de la fonction reclassify() afin dassigner les nouvelles classes aux valeurs du raster dem. nouvelles_classes_dem &lt;- reclassify(dem, nouvelles_classes, rigth = FALSE) Notez que lutilisation par défaut de la fonction reclassify() inclue la borne supérieure mais pas la borne inférieure de lintervalle de reclassification (]limite_lim, limite_max]). Lajout de largument rigth = FALSE vient spécifier que nous souhaitons le contraire, cest-à-dire linclusion de la borne inférieure mais pas de la borne supérieure ([limite_lim, limite_max[). Ainsi, nous avons précisé que les valeurs inclues dans la nouvelle classe 1 vont de 0 à 249 m plutôt que de 1 à 250 m. Visualisons la nouvelle classification du domaine de valeurs du raster délévation dem à laide de la fonction mapview(): mapview(nouvelles_classes_dem) Notez que nous pouvons aussi utiliser NA pour exclure certaines cellules: nouvelles_classes2 &lt;- matrix(c(0, 250, NA, 250, 500, 2, 500, 1200, 3), nrow = 3, ncol = 3, byrow = TRUE) mapview(reclassify(dem, nouvelles_classes2)) Filtrer en utilisant les coordonnées spatiales des cellules Une des opérations les plus fréquentes sur les raster est de filtrer les cellules en fonction de leurs coordonnées spatiales. Dans cette section nous allons apprendre à utiliser les fonctions crop() et mask() pour réaliser ces manipulations. Fonction crop() La fonction crop() vous permet de rogner un raster, autrement dit dutiliser un rectangle pour filter les cellules selon quelles soient ou non à lintérieur de ce dernier. Pour utiliser la fonction crop(), nous avons besoin de deux objets. Le premier objet est le raster à rogner et le second objet est le rectangle avec lequel le raster sera rogné. Ce rectangle est un objet de classe Extent (étendue en français). Un tel objet peut être créé en utilisant les coordonnées de ses coins inférieur-gauche (xmin, ymin) et supérieur-droit (xmax, ymax): ext &lt;- extent(c(-72, -71.5, 45.2, 45.8)) ext class : Extent xmin : -72 xmax : -71.5 ymin : 45.2 ymax : 45.8 Avec la fonction plot(), nous pouvons visualiser la partie du raster qui sera rognée. Notez que la fonction mapview() ne peut pas être utilisée pour visualiser des objets de classe Extent. plot(dem) plot(ext, add = TRUE) Il est très important de relever que de manière implicite les valeurs des coordonnées utilisées dans extent() sont exprimées dans le SCR de notre raster dem. Utilisons maintenant la fonction crop() dont le premier argument est le raster à rogner et le second argument est lobjet de classe Extent. dem_cr &lt;- crop(dem, ext) La sortie est un raster (que nous appelons dem_cr) qui est recadré selon ext. Les cellules qui ne sont pas dans ce rectangle sont exclues. mapview(dem_cr) La fonction crop() accepte en second argument, non seulement les objets de classe Extent, mais aussi tout objet à partir duquel un objet de classe Extent peut être extrait. Ceci signifie que le second argument peut aussi comprendre les objets spatiaux de classe RasterLayer et de classe sf. En guise dexemple, nous allons maintenant rogner le raster dem en utilisant les limites du premier parc de la SÉPAQ identifié dans les données vectorielles parcs. Il est en effet possible dextraire un objet de classe Extent à partir de ces données. Vérifions-le en utilisant la fonction extent(): extent(parcs[1,]) class : Extent xmin : -215252 xmax : -201928 ymin : 195972 ymax : 226160 Avant dutiliser la fonction crop() nous avons besoin de re-projeter le raster dem dans le SCR des données vectorielles parcs (notez que nous pourrions aussi faire linverse). Lopération qui suit utilise de façon implicite létendue spatiale de parcs[1, ] pour rogner dem_lcc. dem_lcc &lt;- projectRaster(dem, crs = crs(parcs)) dem_cr_p &lt;- crop(dem_lcc, parcs[1, ]) mapview(dem_cr_p) Fonction mask() La fonction mask() permet de découper un raster avec un polygone de nimporte quelle forme et non uniquement selon un rectangle. Pour illustrer cette fonction nous allons dabord créer un polygone avec la fonction st_as_sf() de la bibliothèque sf (voir le module 4) : # `mat` est une matrice 7x2 des coordonnées du polygone. mat &lt;- matrix(c( -72.5, 45.8, -72, 45.5, -72.5, 45.2, -71.5, 45.4, -71.7, 45.6, -71.5, 45.7, -72.5, 45.8), ncol = 2, byrow = TRUE) # nous transformons mat en un data frame puis en un objet de class `sf` pol &lt;- st_as_sf( data.frame( var = 1, geom = st_sfc(st_polygon(x = list(mat))) ), crs = st_crs(dem) ) Notons que nous avons utilisé le même SCR que dem. Regardons ce à quoi ressemble le polygone que nous venons de créer. mapview(dem)+mapview(pol) La fonction mask() permet de sélectionner uniquement les cellules du raster dem qui sont à lintérieur du polygone pol (passé en second argument): dem_ma &lt;- mask(dem, pol) mapview(dem_ma) La fonction mask() est dotée dun argument inverse qui, sil prend la valeur TRUE, permet de sélectionner toutes les cellules dun raster qui sont à lextérieur du polygone fourni: dem_ma_inv &lt;- mask(dem, pol, inverse = TRUE) mapview(dem_ma_inv) La fonction mask() permet ainsi de filtrer les données matricielles de façon plus complexe quavec la fonction which(). En effet, les valeurs du raster dem_ma correspondent aux valeurs du sous-ensemble des cellules de dem qui sont à lintérieur du polygone pol de forme complexe. Nous avons donc filtré spatialement les données de dem et nous avons assigné ce raster à la variable dem_ma que nous pouvons alors utiliser comme tout autre raster. summary(getValues(dem_ma)) Min. 1st Qu. Median Mean 3rd Qu. Max. 100 221 259 270 304 839 NA&#39;s 38445 Terminons cette section sur les opérations de filtre par trois remarques importantes: Létendue du raster retourné par la fonction crop() sera différente de celle du raster initial (sauf si létendue initiale est utilisée pour rogner). À linverse, la fonction mask() préserve létendue spatiale. Vous pouvez en faire la vérification: extent(dem) class : Extent xmin : -72.72 xmax : -70.85 ymin : 45 ymax : 46.06 extent(dem_cr) class : Extent xmin : -72 xmax : -71.5 ymin : 45.2 ymax : 45.8 extent(dem_ma) class : Extent xmin : -72.72 xmax : -70.85 ymin : 45 ymax : 46.06 Le temps de calcul pour réaliser lopération crop() est souvent très rapide, ce qui nest pas le cas de lopération mask() quand le polygone est complexe. Il est parfois possible davoir des gains defficacité en faisant appel à crop() avant dutiliser mask(). Dans la situation où seules les valeurs des cellules filtrées nous intéresse, il est possible dutiliser la fonction extract() plutôt que la fonction mask(). La fonction extract() de la bibliothèque raster retourne une liste pour laquelle chaque élément donne les valeurs des cellules extraites pour chaque couche du raster. Par exemple, le raster dem possède une seule couche, ainsi la liste retournée par la fonction extract() ne possède quun seul élément. Toutefois, cet élément est un vecteur de taille 6075 listant la valeur de chacune des cellules extraites. [1] 6075 Min. 1st Qu. Median Mean 3rd Qu. Max. 100 221 259 270 304 839 dem_ex &lt;- extract(dem, pol) length(dem_ex[[1]]) summary(dem_ex[[1]]) 8.1.2.3 Combiner des rasters Une opération qui peut savérer utile est celle de combiner des rasters, cest-à-dire former un seul raster à partir de deux rasters ou plus. Par exemple, une telle opération pourrait être nécessaire si, pour une problématique donnée, nous devions combiner des rasters délévation de chaque région administrative du Québec pour obtenir un seul raster couvrant lentièreté de la province. Fonction merge() La fonction merge() de la bibliothèque raster permet de combiner deux rasters ou plus. Cette fonction sutilise différemment de la fonction générale merge() vue au module 7 pour combiner des data frame. En guise dexemple, combinons les rasters dem_ma et dem_ma_inv créés plus haut en applicant la fonction mask() au raster dem : dem_merge &lt;- merge(dem_ma, dem_ma_inv) Notez que pour combiner des rasters avec la fonction merge() ceux-ci doivent avoir la même résolution et posséder le même système de coordonnées de référence (SCR). Il est possible que deux rasters que lon souhaite combiner couvrent certaines régions communes. Cest-à-dire que certains pixels se superposent. Si la valeur des pixels se superposant diffère, la fonction merge() choisira la valeur que prend le pixel dans le raster donné en premier argument. Par exemple, créons un raster qui soit identique à dem_cr mais pour lequel tous les pixels ont une altitude 100 m plus grande : #Ajoutons 100m à tous les pixels de dem_cr dem_cr_plus &lt;- dem_cr + 100 Ensuite, combinons dem_cr_plus à dem_ma avec la fonction merge(). Le raster combiné prendra des valeurs différentes sur les pixels qui se superposent selon lordre des arguments : dem_merge_ordre1 &lt;- merge(dem_cr_plus, dem_ma) dem_merge_ordre2 &lt;- merge(dem_ma, dem_cr_plus) Fonction mosaic() La fonction mosaic() de la bibliothèque raster est similaire à merge() mais offre plus de flexibilité pour définir la valeur des pixels qui se chevauchent. En particulier, elle possède un troisième argument servant à préciser la fonction avec laquelle la valeur des pixels redondants est calculée. Par exemple, la fonction pourrait choisir la valeur la plus grande, la valeur la plus petite, ou encore la moyenne des valeurs. La fonction pourrait aussi être définie par lusager et prendre une forme plus spécifique. dem_mosaic_min &lt;- mosaic(dem_cr_plus, dem_ma, fun = min) dem_mosaic_max &lt;- mosaic(dem_cr_plus, dem_ma, fun = max) dem_mosaic_mean &lt;- mosaic(dem_cr_plus, dem_ma, fun = mean) La fonction mosaic() requière également que les rasters utilisés possèdent la même résolution et le même SCR. Il existe des bibliothèques spécialisés qui offrent des fonctions plus avancées pour le traitement des pixels aux frontières des rasters qui se chevauchent (par exemple les bibliothèques landsat et satellite). Lutilisation de ces méthodes dépassent toutefois les objectifs de ce cours. 8.1.3 Problématique à résoudre Maintenant que nous avons appris les opérations de base pour manipuler les données matricielles, nous sommes en mesure de résoudre la problématique énoncée au début de cette leçon. Résolution de la question 1 Rappelons la première question : Parmi les quatre parcs nationaux de la région de Sherbrooke, lequel dispose du plus haut sommet? Les étapes de la démarche de résolution sont les suivantes: Sassurer que le raster délévation dem et les données vectorielles parcs sont dans le même SCR. Utiliser la fonction mask() pour extraire les cellules de dem qui sont dans les parcs nationaux considérés, Déterminer la valeur maximale délévation dans ce sous-ensemble de cellules extraites, Trouver les coordonnées spatiales associées à ce point de valeur délévation maximale. Déterminer dans quel parc se trouve les coordonnées spatiales du sommet le plus haut. Commençons! 1. Vérication des SRC Commençons par vérifier si les systèmes de coordonnées de référence (SCR) de dem et de parcs sont identiques: st_crs(dem) == st_crs(parcs) [1] FALSE Puisque les SCR diffèrent, nous allons re-projeter le raster dem en utilisant le SCR de parcs en utilisant la fonction projectRaster(). Nous avons déjà réalisé cette opération à la section précédente et nous reprenons donc ci-dessous la ligne de commande vue plus haut : dem_lcc &lt;- projectRaster(dem, crs = crs(parcs)) Pour les prochaines manipulations, nous utiliserons donc dem_lcc et parcs. 2. Filtrer le raster dem Nous cherchons ensuite à filtrer les cellules du raster délévation dem pour extraire celles situées à lintérieur des limites de lun ou de lautre des quatre parcs nationaux considérés. Le shapefile parcs contient justement les polygones déliminant les quatre parcs. Nous pouvons donc appliquer la fonction mask() au raster dem en utilisant directement le shapefile parcs en second argument. dem_parcs &lt;- mask(dem_lcc, parcs) mapview(dem_parcs) Le raster dem_parcs obtenus par lopération mask() possède la même étendue que le raster original dem_lcc mais ses valeurs diffèrent. Les cellules de dem_parcs prennent la valeur NA partout sauf à lintérieur des quatre parcs nationaux où elles prennent alors la même valeur que la cellule correspondante dans dem_lcc. 3. Trouver lélévation maximale Nous pouvons maintenant trouver la valeur délévation la plus élevée en utilisant la fonction getValues() suivi de la fonction max(). vmax &lt;- max(getValues(dem_parcs), na.rm = TRUE) vmax [1] 1083 Nous avons ainsi obtenu lélévation maximale de ces parcs qui est de 1083 m. Nous cherchons alors les coordonnées spatiales associées à cette valeur. Nous pouvons faire appel à la fonction which() pour trouver lindice de la cellule (ou les indices des cellules, si il y en a plusieurs) en question. ind_max &lt;- which(getValues(dem_parcs) == max(getValues(dem_parcs), na.rm = TRUE)) ind_max [1] 31561 Notons quil existe une fonction pour identifier le maximum, which.max(), qui réalise la même opération mais requière une syntaxe un peu plus simple. which.max(getValues(dem_parcs)) [1] 31561 4. Déterminer les coordonnées du plus haut sommet Pour déterminer les coordonnées de la cellule identifiée nous utilisons lindice ind_max et la fonction as.data.frame() avec xy = TRUE et centroid = TRUE comme vu au module 5 : df_max &lt;- as.data.frame(dem_parcs[ind_max, drop = FALSE], xy = TRUE, centroid = TRUE, na.rm = TRUE) df_max x y layer 1 -207329 165880 1083 Deux remarques méritent dêtre mentionnées concernant cette opération : Largument drop = FALSE permet déviter que R ne convertisse dem_parcs[ind_max, ] en un vecteur, cest important car nous voulons conserver sa forme matricielle. na.rm = TRUE permet dignorer toutes les valeurs masquées, comme nous lavons dans dautres fonctions (e.g. mean()). v. Déterminer le parc possédant le point délévation maximale Une fois isolées, les coordonnées x et y du pixel délévation maximale peuvent être utilisées pour créer un objet spatial de classe sf contenant le centroïde de ce pixel grâce à la fonction st_as_sf(). Nous nous servirons par la suite de ce point pour visualiser sa position et déterminer dans quel parc national il est situé. sf_point_max &lt;- st_as_sf(df_max, coords = c(&quot;x&quot;, &quot;y&quot;), crs = st_crs(dem_parcs)) sf_point_max Simple feature collection with 1 feature and 1 field Geometry type: POINT Dimension: XY Bounding box: xmin: -207300 ymin: 165900 xmax: -207300 ymax: 165900 Projected CRS: NAD83 / Quebec Lambert layer geometry 1 1083 POINT (-207329 165880) Remarquez que nous avons attribué à ce point le même SRC que celui du raster dem_parcs(). En superposant, avec mapview(), les trois couches dinformations spatiales que nous venons de manipuler, nous pouvons repérer le parc dans lequel se trouve ce point délévation maximale. map_point &lt;- mapview(dem_parcs) + mapview(parcs, alpha = 0.01) + mapview(sf_point_max, col.regions = &quot;red&quot;) map_point@map FIGURE 8.1: En cliquant sur le polygone du parc contenant le point rouge (point délévation maximal), il est possible de constater que le point se retrouve dans le Parc national du Mont-Mégantic Nous constatons que ce point est situé dans le Parc national du Mont-Mégantic. Au lieu de déduire sa localisation de manière visuelle, nous allons à présent réaliser une opération topologique pour isoler le polygone du parc abritant ce plus haut sommet. Pour ce faire, nous utilisons la fonction st_intersects() étudiée au module 7. Rappelons que cette fonction retourne la valeur TRUE lorsque deux objets vectoriels se recoupent et FALSE autrement. st_intersects(parcs, sf_point_max, sparse = FALSE) [,1] [1,] FALSE [2,] TRUE [3,] FALSE [4,] FALSE Nous utilisons ensuite ce vecteur logique pour identifier le parc auquel ce sommet appartient. Notez que le nom des parcs est donné par lattribut TRQ_NM_. parcs[st_intersects(parcs, sf_point_max, sparse = FALSE), ]$TRQ_NM_ [1] &quot;Parc national du Mont-Mégantic&quot; Cette opération peut être écrite plus simplement sous la forme: parcs[sf_point_max, ]$TRQ_NM_ [1] &quot;Parc national du Mont-Mégantic&quot; Cette dernière manipulation nous permet de répondre à notre première question: parmi les quatre parcs nationaux sélectionnés, cest le Parc national du Mont-Mégantic qui a le plus haut sommet, sommet qui culmine à 1083 m daltitude! Résolution de la question 2 Nous allons maintenant répondre à la deuxième question de notre problématique: Quelle est le profil topographique du sentier se rendant au plus proche de ce sommet? Nous allons nous placer dans la situation suivante : nous désirons faire une randonnée pédestre jusquau sommet que nous venons didentifier (à tout le moins, le plus proche possible de ce sommet). Afin de nous faire une idée précise de leffort physique que nous devrons fournir lors de cette randonnée, nous allons réaliser un profil topographique du sentier se rendant au plus proche de ce sommet. La figure 8.2 donne un exemple de profil topographique pour le sentier de la grande traversée dans le Parc national de la Gaspésie. FIGURE 8.2: Exemple de profil topographique: le sentier international des Appalaches taille réelle Voici les étapes que nous allons suivre en vue de répondre à la question posée: Créer un shapefile du Parc national du Mont-Mégantic, parc_megantic, à partir de parcs. Importer les données des sentiers estivaux de la SEPAQ et des données délévation plus précises. Sassurer que les nouveaux objets importés et parc_megantic ont le même SCR. Isoler les sentiers estivaux du Parc national du Mont-Mégantic. Trouver le chemin le plus proche du sommet identifié à la question 1. Extraire les cellules délévation de dem_lcc sur ce sentier. Réaliser un profile délévation. Commençons! 1. Créer un shapefile du Parc national du Mont-Mégantic Puisque le profil topographique que nous désirons créer se situe à lintérieur du Parc national du Mont-Mégantic, isolons le polygone constituant ce parc à partir du shapefile parcs regroupant les quatre parcs. Rappelons que le Parc national du Mont-Mégantic est celui qui possède le plus haut sommet. En nous basant sur les commandes réalisées plus haut, nous pouvons définir le shapefile parc_megantic de la façon suivante: parc_megantic &lt;- parcs[st_intersects(parcs, sf_point_max, sparse = FALSE), ] # Ou plus simplement: # parc_megantic &lt;- parcs[sf_point_max, ] 2. Importer les données Maintenant importons les données vectorielles pour tous les sentiers de la SEPAQ. Ce shapefile se trouve dans le dossier Module8_donnees que vous avez téléchargé au début de la leçon : sentiers &lt;- st_read(&quot;Module8/Module8_donnees/sentiers_sepaq/Sentier_ete_l.shp&quot;) Reading layer `Sentier_ete_l&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module8\\Module8_donnees\\sentiers_sepaq\\Sentier_ete_l.shp&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 3606 features and 22 fields Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: -822400 ymin: 150300 xmax: 437600 ymax: 689800 Projected CRS: NAD83 / Quebec Lambert mapview(sentiers) Notre objectif est de savoir comment lélévation varie le long du sentier qui conduit le plus près possible du plus haut sommet. Ainsi, en plus des données sur la localisation des sentiers, nous avons besoin des données délévation. Or, au lieu dutiliser le raster dem_lcc dont la résolution spatiale est de 521 par 741 m2, nous allons nous procurer une autre couche délévation de résolution plus fine afin dobtenir un profil topologique plus précis. Pour ce faire, nous utiliserons la fonction get_elev_raster() de la bibliothèque elevatr. Cette fonction permet daccéder aux données délévation disponibles sur le service dinfonuagique dAmazon (AWS) et cela à différents niveaux de résolution. La fonction get_elev_raster() requière deux arguments. Le premier argument spécifie la localisation des données recherchées. Dans notre cas, la localisation est définie le polygone parc_megantic. Le deuxième argument spécifie le niveau de résolution des données recherchées, cest-à-dire le zoom, une valeur allant de z = 1 à z = 14. # install.packages(&quot;elevatr&quot;) # install.packages(&quot;progress&quot;) #Installer aussi! library(elevatr) elv_megantic &lt;- get_elev_raster(parc_megantic, z = 13) Nous avons ainsi obtenu le raster délévation elv_megantic pour le Parc national du Mont-Mégantic. La résolution spatiale de cette couche est plus fine que celle de la couche dem_lcc : res(elv_megantic) [1] 3.353 3.353 Ce qui correspond à environ 3.4 par 3.4 m2. 3. Vérication des SRC Vérifions ensuite que les SCR utilisés pour répondre à la question 2 sont tous identiques en utilisant la fonction st_crs() : st_crs(sentiers) == st_crs(parc_megantic) [1] TRUE st_crs(elv_megantic) == st_crs(parc_megantic) [1] TRUE Puisque cest le cas, aucune transformation de SRC nest nécessaire et nous pouvons poursuivre la résolution de notre problème. 4. Isoler les sentiers estivaux du Parc national du Mont-Mégantic À présent, nous allons isoler les sentiers du parc du Mont-Mégantic qui se trouvent dans sentiers. Commençons par inspecter la table des attributs : head(sentiers) Simple feature collection with 6 features and 22 fields Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: 391200 ymin: 610200 xmax: 437600 ymax: 645500 Projected CRS: NAD83 / Quebec Lambert No_etab Code_etab No_reseau Code_res Reseau 1 15 PAN 2 PQ Parc national 2 15 PAN 2 PQ Parc national 3 15 PAN 2 PQ Parc national 4 15 PAN 2 PQ Parc national 5 15 PAN 2 PQ Parc national 6 15 PAN 2 PQ Parc national Nom_etab Maj Source Usager Etat 1 Anticosti 2011-02 n/a Pédestre Existant 2 Anticosti 2011-02 n/a Pédestre Existant 3 Anticosti 2011-02 n/a Pédestre Existant 4 Anticosti 2011-02 n/a Pédestre Existant 5 Anticosti 2011-02 n/a Pédestre Existant 6 Anticosti 2011-02 n/a Pédestre Existant Toponyme1 Toponyme2 Toponyme3 1 Le Canyon-de-la-Chicotte &lt;NA&gt; &lt;NA&gt; 2 Lac-Baie-de-la-Tour &lt;NA&gt; &lt;NA&gt; 3 Les Télégraphes &lt;NA&gt; &lt;NA&gt; 4 Le Garde-Feu &lt;NA&gt; &lt;NA&gt; 5 La Grotte-à-la-Patate &lt;NA&gt; &lt;NA&gt; 6 Observation-la-Mer &lt;NA&gt; &lt;NA&gt; Toponyme4 Niv_diff Secteur Usager_2 Toponyme5 1 &lt;NA&gt; Intermédiaire &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 2 &lt;NA&gt; Intermédiaire &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 3 &lt;NA&gt; Intermédiaire &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 4 &lt;NA&gt; Facile &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 5 &lt;NA&gt; Intermédiaire &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 6 &lt;NA&gt; Facile &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; Toponyme6 Usager_3 Usager_4 Shape_Leng 1 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 6647.8 2 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 601.4 3 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 3051.5 4 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 2499.2 5 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 1548.7 6 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 1973.8 geometry 1 MULTILINESTRING ((393116 61... 2 MULTILINESTRING ((435372 63... 3 MULTILINESTRING ((436291 63... 4 MULTILINESTRING ((396510 61... 5 MULTILINESTRING ((398004 64... 6 MULTILINESTRING ((409244 64... La colonne Nom_etab contient le non des parcs que nous pouvons lister rapidement avec la fonction unique() qui enlève les doublons. unique(sentiers$Nom_etab) [1] &quot;Anticosti&quot; [2] &quot;Duchesnay&quot; [3] &quot;Lac-Simon&quot; [4] &quot;Aiguebelle&quot; [5] &quot;Bic&quot; [6] &quot;Île-Bonaventure-et-Rocher-Percé&quot; [7] &quot;Îles-de-Boucherville&quot; [8] &quot;Frontenac&quot; [9] &quot;Gaspésie&quot; [10] &quot;Grands-Jardins&quot; [11] &quot;Hautes-Gorges-de-la-Rivière-Malbaie&quot; [12] &quot;Jacques-Cartier&quot; [13] &quot;Miguasha&quot; [14] &quot;Mont-Mégantic&quot; [15] &quot;Mont-Orford&quot; [16] &quot;Mont-Tremblant&quot; [17] &quot;Mont-Saint-Bruno&quot; [18] &quot;Monts-Valin&quot; [19] &quot;Oka&quot; [20] &quot;Plaisance&quot; [21] &quot;Pointe-Taillon&quot; [22] &quot;Fjord-du-Saguenay&quot; [23] &quot;Lac-Témiscouata&quot; [24] &quot;Yamaska&quot; [25] &quot;Saguenay-Saint-Laurent&quot; [26] &quot;Opémican&quot; [27] &quot;Ashuapmushuan&quot; [28] &quot;Chic-Chocs&quot; [29] &quot;Laurentides&quot; [30] &quot;La Vérendrye, Secteur Outaouais&quot; [31] &quot;La Vérendrye, Secteur Abitibi&quot; [32] &quot;Mastigouche&quot; [33] &quot;Matane&quot; [34] &quot;Auberge de Montagne des Chic-Chocs&quot; [35] &quot;Papineau-Labelle&quot; [36] &quot;Port-Daniel&quot; [37] &quot;Portneuf&quot; [38] &quot;Rouge-Matawin&quot; [39] &quot;Port-Cartier-Sept-Îles&quot; [40] &quot;Saint-Maurice&quot; Nous observons que le Parc national du Mont-Mégantic est identifié par le nom Mont-Mégantic. Pour isoler ses sentiers nous pouvons procéder de deux façons. La première façon consiste à utiliser la fonction subset() (vue au module 7) pour filtrer le shapefile sentiers et sélectionner seulement les sentiers pour lesquels lattribut Nom_etab prend la valeur Mont-Mégantic: sentiers_megantic &lt;- subset(sentiers, Nom_etab == &quot;Mont-Mégantic&quot;) La deuxième façon est dutiliser un filtre spatial avec les limites du Parc national du Mont-Mégantic contenues dans parc_megantic : sentiers_megantic &lt;- sentiers[parc_megantic, ] mapview(sentiers_megantic) Nous avons ainsi obtenu, quelle que soit la méthode choisie, un objet vectoriel, sentiers_megantic, qui contient les sentiers du Parc national du Mont-Mégantic. 5. Trouver le sentier le plus proche du sommet le plus haut Nous allons maintenant utiliser la fonction st_nearest_feature() de la bibliothèque sf pour déterminer quel sentier (LINES) se trouve le plus proche du sommet (POINT). Notez quen anglais near signifie proche et feature signifie éléments ou plus précisément une entité spatiale (aussi appelée une géométrie) dans le présent contexte. La fonction st_nearest_feature(x,y) comprend deux arguments x et y et retourne lindice de lentité spatiale dans y qui est le plus près de lentité x. id_nearest &lt;- st_nearest_feature(sf_point_max, sentiers_megantic) id_nearest [1] 6 Nous pouvons ainsi trouver le sentier recherché à partir de lindice que nous venons didentifier. sentier_top &lt;- sentiers_megantic[id_nearest, ] sentier_top Simple feature collection with 1 feature and 22 fields Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: -207500 ymin: 165100 xmax: -206500 ymax: 166000 Projected CRS: NAD83 / Quebec Lambert No_etab Code_etab No_reseau Code_res 1251 12 MME 2 PQ Reseau Nom_etab Maj Source 1251 Parc national Mont-Mégantic 2010-08 GPS Usager Etat Toponyme1 1251 Pédestre Existant Sentier du Mont-Mégantic Toponyme2 Toponyme3 Toponyme4 Niv_diff 1251 Les Trois-Sommets &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; Secteur Usager_2 Toponyme5 1251 Secteur de l&#39;Observatoire &lt;NA&gt; &lt;NA&gt; Toponyme6 Usager_3 Usager_4 Shape_Leng 1251 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 1456 geometry 1251 MULTILINESTRING ((-207526 1... Observez que la géométrie de cette entité spatiale est une multiligne (MULTILINESTRING). Notons que nous aurions pu faire la même opération directement sur lobjet sentiers, cest-à-dire par la commande suivante: sentiers[st_nearest_feature(sf_point_max, sentiers),] Regardons où ce sentier se situe par rapport aux autres sentiers du parc : mapview(sentiers_megantic) + mapview(sentier_top, color=&quot;red&quot;) Nous observons que ce sentier nest en fait quune petite portion du parcours quun.e randonneur.se devra faire pour se rendre le plus près possible du plus haut sommet. Or, nous voulons le sentier complet à parcourir depuis le pied de la montagne. Lattribut Toponyme1 nous donne justement le nom du sentier (Sentier du Mont-Mégantic) auquel appartient la section sentier_top que nous venons didentifier. Revenons maintenant au shapefile sentiers_megantic pour y extraire toutes les autres portions du sentier nommé Sentier du Mont-Mégantic qui ensemble formeront la randonnée complète. Pour ce faire nous utilisons la fonction subset() : rando_sections &lt;- subset(sentiers_megantic, Toponyme1 == &quot;Sentier du Mont-Mégantic&quot;) Visualisons ensuite ces différentes portions en les colorant selon un identifiant id : rando_sections$id &lt;- 1:5 mapview(rando_sections, zcol = &quot;id&quot;) Changeons lordre des portions afin quelles suivent lordre selon lequel elles seront parcourues à partir du sommet jusquau pied de la montagne (cest-à-dire de 1 à 5 plutôt que 5,1,2,3,4) : rando_sections &lt;- rando_sections[c(5, 1:4),] rando_sections$id &lt;-1:5 mapview(rando_sections, zcol = &quot;id&quot;) Combinons maintenant ces cinq portions en une seule entité spatiale (MULTILINESTRING) en utilisant la fonction st_combine() de la bibliothèque sftelle que vue au module 7 : rando &lt;- st_combine(rando_sections) rando Geometry set for 1 feature Geometry type: MULTILINESTRING Dimension: XY Bounding box: xmin: -207700 ymin: 163500 xmax: -206200 ymax: 166100 Projected CRS: NAD83 / Quebec Lambert MULTILINESTRING ((-207664 166072, -207663 16607... Observez que nous avons effectivement une seule entité spatiale. 6. Extraire les cellules délévation le long du sentier Pour faire le profil topographique du sentier rando, nous devons extraire des données délévation du parc (elv_megantic) celles qui se trouvent le long du sentier. Pour ce faire nous allons utiliser la fonction extract() de la bibliothèque raster comme suit. topo_elv &lt;- extract(elv_megantic, st_as_sf(rando), along = TRUE, cellnumbers = TRUE) Notons que cette opération peut prendre plusieurs secondes pour être complétée par votre ordinateur. Trois remarques méritent dêtre mentionnées concernant cette opération : Nous avons besoin de convertir rando qui est de classe sfc en objet de classe sf pour lutiliser avec extract(), ce que nous faisons avec st_as_sf(). along = TRUE permet dobtenir les cellules ordonnées le long des lignes de rando_sections. cellnumbers = TRUE nous permet davoir les indices des cellules extraites. Comme vu un peu plus haut, la fonction extract() retourne une liste. Ainsi, topo_elv est un objet de classe list, mais cette fois le premier élément est une matrice avec deux colonnes: la première colonne contient les identifiants des cellules, et la seconde, les valeurs délévation (précédemment, le résultat de extract() était simplement un vecteur avec des valeurs délévation). Nous pouvons confirmer ces propos par les commandes suivantes : class(topo_elv) #topo_elv est un objet de classe &quot;list&quot; [1] &quot;list&quot; length(topo_elv) #cette liste comprend une seule entrée [1] 1 dim(topo_elv[[1]]) #La première entrée de la liste est une matrice de 876 lignes et de 2 colonnes. [1] 1603 2 Attribuons des noms à chacune des colonnes de la matrice contenue dans la première entrée de la liste topo_elv  colnames(topo_elv[[1]]) &lt;- c(&quot;cellule_id&quot;, &quot;elevation&quot;) head(topo_elv[[1]]) cellule_id elevation v 3971831 1099 3971831 1099 3975080 1099 3975081 1099 3978330 1099 3981579 1099 Nous avons donc toutes les valeurs délévation le long du sentier. 7. Obtenir le profil topographique Rappelons quun profil topographique est une représentation graphique du relief qui affiche lélévation à chaque point le long dun sentier (voir la figure 8.2). Labscisse dun tel graphique (cest-à-dire laxe des x) correspond à la distance parcourue depuis le début de la randonnée (par exemple de 0 à 100 km) et lordonnée (cest-à-dire laxe des y) correspond à lélévation. Maintenant que nous avons lélévation pour chaque point le long du sentier (topo_elv), nous devons déterminer la distance parcourue depuis le début du trajet jusquà chaque point le long de ce sentier. Tout dabord, nous devons calculer la distance parcourue entre chaque paires de points qui se suivent le long du sentier. Pour ce faire, nous utiliserons la fonction st_distance() vue au module 7. Or, cette fonction ne peut être utilisée que sur un objet spatial, et comme nous venons de le constater topo_elv est un objet de classe list. Nous devons donc transformer topo_elv en objet spatial avec la fonction st_as_sf(). De plus, un objet spatial doit être défini par des coordonnées spatiales. Pour linstant, les cellules formant le sentier dans topo_elv sont identifiées par leur indice et non par leurs coordonnées. Une étape préliminaire est donc nécessaire pour retrouver les coordonnées spatiales correspondant à chaque indice. Cela est possible grâce à la fonction xyFromCell() de la bibliothèque raster qui retourne les coordonnées spatiales associées à chaque indice dans le raster à partir duquel nous avons extrait topo_elv, cest-à-dire elv_megantic. df_pts &lt;- as.data.frame(xyFromCell(elv_megantic, topo_elv[[1]][, 1])) head(df_pts) x y 1 -207662 166072 2 -207662 166072 3 -207662 166069 4 -207659 166069 5 -207659 166066 6 -207659 166062 Nous avons mis les coordonnées spatiales dans le tableau df_pts de type data.frame. Notez que largument topo_elv[[1]][, 1] correspond aux indices des cellules (cest la première colonne de la première entrée de la liste topo_elv). Nous pouvons ensuite utiliser la fonction st_as_sf() pour transformer df_pts en objet de classe sf : topo_pts &lt;- st_as_sf(df_pts, coords = c(&quot;x&quot;, &quot;y&quot;), crs = st_crs(sentiers_megantic) ) Remarquez que nous avons également attribué un SCR au nouvel objet spatial topo_pts. Nous pouvons finalement utiliser la fonction st_distance() pour calculer les distances entre points successifs de topo_pts. La fonction st_distance(x,y) nécessite obligatoirement deux objets spatiaux (x et y) en argument. Elle calcule alors la distance entre chaque paire déléments de x et de y, quelle retourne sous forme de matrice. Par exemple, lopération suivante calcule la distance entre toutes les paires de points compris dans topo_pts : dist_tout &lt;- st_distance(topo_pts,topo_pts) dist_tout[1:5,1:5] Units: [m] [,1] [,2] [,3] [,4] [,5] [1,] 0.000 0.000 3.353 4.742 7.498 [2,] 0.000 0.000 3.353 4.742 7.498 [3,] 3.353 3.353 0.000 3.353 4.742 [4,] 4.742 4.742 3.353 0.000 3.353 [5,] 7.498 7.498 4.742 3.353 0.000 Lélément dist_tout[1,1] est la distance entre le premier point de topo_pts et lui-même (donc zéro), lélément dist_tout[1,2] est la distance entre le premier et le deuxième points de topo_pts (auss zéro car ces deux points sont probablement très rapprochés), dist_tout[1,3] entre le premier et le troisième points de topo_pts, et ainsi de suite pour tous les points de topo_pts. La fonction st_distance() sutilise aussi avec largument by_element = TRUE. Dans ce cas, la fonction retourne un vecteur dont le premier élément correspond à la distance entre le premier élément de x et le premier élément de y; le deuxième élément, à la distance entre le deuxième élément de x et le deuxième élément de y, et ainsi de suite. Par exemple, lopération suivante : dist0 &lt;- st_distance(topo_pts,topo_pts,by_element = TRUE) dist0[1:5] Units: [m] 1 2 3 4 5 0 0 0 0 0 retourne un vecteur nul puisque chaque élément correspond à la distance entre un point et lui-même. Pour répondre à notre question, nous devons calculer la distance entre des points successifs de topo_pts (cest-à-dire la distance entre le premier et le deuxième point, entre le deuxième et le troisième point, entre le troisième et le quatrième point, etc.). Il sagit de calculer la distance pour des paires de points formés entre topo_pts et une version de topo_pts qui est décalée dun élément. Nous utilisons donc la fonction st_distance() avec comme premier argument topo_pts sans le premier point, et comme deuxième argument topo_pts aussi mais cette fois sans le dernier point: dist_pts &lt;- st_distance(topo_pts[-1, ], topo_pts[-nrow(topo_pts),], by_element = TRUE) Nous pouvons maintenant calculer la distance parcourue à chaque point le long du sentier depuis le début de la randonnée. Pour ce faire nous utilisons la fonction cumsum() qui calcule la somme cumulée des distances entre chaque point : dist_parcourue &lt;- cumsum(dist_pts) Nous pouvons finalement visualiser lélévation (la deuxième colonne de topo_elv[[1]][, 2]) en fonction de la somme cumulée des distances, dist_parcourue. Remarquons que le vecteur dist_parcourue comprend un élément de moins que le vecteur topo_elv[[1]][, 2]. Ceci sexplique par le fait que dist_pts, à partir duquel nous calculons dist_parcourue, mesure la distance entre les points (cest à dire des intervalles). Par conséquent, nous ajoutons la distance initiale de 0 m au vecteur des distances parcourues. plot(c(0, dist_parcourue), topo_elv[[1]][, 2], main = &quot;Profil topographique du Sentier du Mont-Mégantic&quot;, xlab = &quot;Distance depuis le sommet (en mètre)&quot;, ylab = &quot;Altitude (en mètre)&quot;, type = &quot;l&quot;, # pour utiliser une ligne lwd = 2 # augmente le trait de la ligne ) Et voilà qui complète la réalisation du profil topographique du sentier menant le plus près du sommet le plus haut. "],["ex_mat_manip.html", "8.2 Exercices", " 8.2 Exercices Dans cette section, vous mettrez en pratique certains concepts vus dans la section leçon de ce module. Bien que la réponse à chaque question soit disponible, il est très important de tenter dy répondre par vous même! Question 1 Identifier le point délévation maximale sur une carte du parc du Mont-Orford. Réponse Isoler le polygone du parc du Mont-Orford du shapefile parcs en utilisant la fonction subset: parc_orford &lt;- subset(parcs, TRQ_NM_== &quot;Parc national du Mont-Orford&quot;) Filtrer le raster dem_lcc pour ne retenir que les cellules situées à lintérieure du polygone délimitant les limites du parc du Mont-Orford dem_orford &lt;- mask(dem_lcc, parc_orford) mapview(dem_orford) Déterminer lindice de la cellule ou des cellules délévation maximale en utilisant les fonctions getValues() et which.max(). imax_orford&lt;-which.max(getValues(dem_orford)) Trouver les coordonnées correspondant à cet indice en utilisant la fonction xyFromCell. coordmax_orford &lt;- xyFromCell(dem_orford,imax_orford) coordmax_orford x y [1,] -293815 154024 Transformer ces coordonnées en une donnée vectorielle de type POINT en utilisant la fonction st_as_sf(). #Créer d&#39;abord un data.frame à partir de coordmax_orford coordmax_orford_df &lt;- as.data.frame(coordmax_orford) #ou simplement data.frame(coordmax_orford) #Créer un point pt_max_orford &lt;- st_as_sf(coordmax_orford_df, coords = c(&quot;x&quot;, &quot;y&quot;), crs = st_crs(dem_orford)) #attribuer le même SCR Visualiser la carte du parc du Mont-Orford ainsi que le point délévalion maximale. mapview(dem_orford) + mapview(pt_max_orford, col.regions=&quot;red&quot;) Question 2 Reclassifier le raster dem_orford selon quatre classes correspondant aux valeurs comprises entre le zéro et le \\(1^{er}\\) quantile, le \\(1^{er}\\) et le \\(2^{ième}\\), le \\(2^{ième}\\) et \\(3^{ième}\\), et le \\(3^{ième}\\) et \\(4^{ième}\\). Réponse Trouver dabord les quantiles des valeurs délévation dans le parc du Mont-Orford. quantile_orford &lt;- quantile(getValues(dem_orford), na.rm = TRUE) quantile_orford 0% 25% 50% 75% 100% 270.1 338.6 394.2 536.6 816.6 q_25 &lt;- as.numeric(quantile_orford[&quot;25%&quot;]) # as.numeric pour conserver seulement les chiffres q_50 &lt;- as.numeric(quantile_orford[&quot;50%&quot;]) q_75 &lt;- as.numeric(quantile_orford[&quot;75%&quot;]) q_100 &lt;- as.numeric(quantile_orford[&quot;100%&quot;]) En se servant de ces valeurs, construire une matrice qui détermine la nouvelle classification. classes_orford &lt;- matrix(c(0, q_25, 1, #1ere classe q_25, q_50, 2, #2e classe q_50, q_75, 3, #3e classe q_75, q_100, 4), #4e classe nrow = 4, ncol = 3, byrow = TRUE) # donner des titres aux colonnes de cette matrice colnames(classes_orford) &lt;- c(&quot;Limite_min&quot;, &quot;Limite_max&quot;, &quot;Classement_quantile&quot;) Utiliser la fonction reclassify() pour assigner les nouvelles classes au raster dem_orford. dem_orford_quantile &lt;- reclassify(dem_orford, classes_orford, rigth = FALSE) Confirmer visuellement la reclassification en utilisant la fonction mapview() mapview(dem_orford_quantile) Noter que nous aurions pu vouloir attribuer une nouvelle classification de type catégorique au raster dem_orford. Par exemple, Categorie_elevation &lt;- c(&quot;Faible&quot;, &quot;Intermediare&quot;, &quot;Forte&quot;, &quot;Très forte&quot;) # Ou encore Categorie_quantile &lt;- c(&quot;[0%, 25%[&quot;, &quot;[25%, 50%[&quot;, &quot;[50%, 75%[&quot;, &quot;[75%, 100%]&quot;) Dans ce cas, il faut ajouter ces catégories au raster dem_orford en utilisant la fonction levels(). levels(dem_orford_quantile) &lt;- data.frame(ID=1:4, quantile = Categorie_quantile) dem_orford_quantile class : RasterLayer dimensions : 178, 304, 54112 (nrow, ncol, ncell) resolution : 521, 741 (x, y) extent : -336797, -178413, 110676, 242574 (xmin, xmax, ymin, ymax) crs : +proj=lcc +lat_0=44 +lon_0=-68.5 +lat_1=60 +lat_2=46 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs source : memory names : DEM values : 1, 4 (min, max) attributes : ID quantile 1 [0%, 25%[ 2 [25%, 50%[ 3 [50%, 75%[ 4 [75%, 100%] La classification est maintenant traitée comme une variable catégorique. mapview(dem_orford_quantile) Question 3 À partir du raster dem_lcc, créer un seul raster composé de zones tampons circulaires, de 10 km de rayon, autour des points délévation maximale de chaque parc national de la région de Sherbrooke. Réponse Répéter les étapes de la Question 1 pour créer un shapefile correspondant au point délévation maximale de chaque parc. Pour le Parc du Mont-Orford: # Isoler les limites du parc parc_orford &lt;- subset(parcs, TRQ_NM_== &quot;Parc national du Mont-Orford&quot;) # Trouver dem à l&#39;intérieur du parc dem_orford &lt;- mask(dem_lcc, parc_orford) # Trouver l&#39;indice de la cellule d&#39;élévation maximale imax_orford&lt;-which.max(getValues(dem_orford)) # Trouver les coordonnées de cette cellule coordmax_orford &lt;- xyFromCell(dem_orford,imax_orford) # Transformer en data.frame coordmax_orford_df &lt;- as.data.frame(coordmax_orford) # Transformer en point pt_max_orford &lt;- st_as_sf(coordmax_orford_df, coords = c(&quot;x&quot;, &quot;y&quot;), crs = st_crs(dem_orford)) #attribuer le même SCR Pour le Parc national du Mont-Mégantic: parc_megantic &lt;- subset(parcs, TRQ_NM_== &quot;Parc national du Mont-Mégantic&quot;) dem_megantic &lt;- mask(dem_lcc, parc_megantic) imax_megantic &lt;- which.max(getValues(dem_megantic)) coordmax_megantic &lt;- xyFromCell(dem_megantic,imax_megantic) coordmax_megantic_df &lt;- as.data.frame(coordmax_megantic) pt_max_megantic &lt;- st_as_sf(coordmax_megantic_df, coords = c(&quot;x&quot;, &quot;y&quot;), crs = st_crs(dem_orford)) Pour le Parc national de la Yamaska: parc_yamaska &lt;- subset(parcs, TRQ_NM_== &quot;Parc national de la Yamaska&quot;) dem_yamaska &lt;- mask(dem_lcc, parc_yamaska) imax_yamaska &lt;- which.max(getValues(dem_yamaska)) coordmax_yamaska &lt;- xyFromCell(dem_yamaska,imax_yamaska) coordmax_yamaska_df &lt;- as.data.frame(coordmax_yamaska) pt_max_yamaska &lt;- st_as_sf(coordmax_yamaska_df, coords = c(&quot;x&quot;, &quot;y&quot;), crs = st_crs(dem_orford)) Pour le Parc national de Frontenac: parc_frontenac &lt;- subset(parcs, TRQ_NM_== &quot;Parc national de Frontenac&quot;) dem_frontenac &lt;- mask(dem_lcc, parc_frontenac) imax_frontenac &lt;- which.max(getValues(dem_frontenac)) coordmax_frontenac &lt;- xyFromCell(dem_frontenac,imax_frontenac) coordmax_frontenac_df &lt;- as.data.frame(coordmax_frontenac) pt_max_frontenac &lt;- st_as_sf(coordmax_frontenac_df, coords = c(&quot;x&quot;, &quot;y&quot;), crs = st_crs(dem_orford)) Confirmer vos calculs en visualisant les points trouvés. mapview(pt_max_orford, col.regions = &quot;red&quot;) + mapview(pt_max_megantic, col.regions = &quot;blue&quot;) + mapview(pt_max_yamaska, col.regions = &quot;green&quot;) + mapview(pt_max_frontenac, col.regions = &quot;yellow&quot;) m &lt;- mapview(pt_max_orford, col.regions = &quot;red&quot;) + mapview(pt_max_megantic, col.regions = &quot;blue&quot;) + mapview(pt_max_yamaska, col.regions = &quot;green&quot;) + mapview(pt_max_frontenac, col.regions = &quot;yellow&quot;) m@map Calculer une zone tampon de 10 km de rayon autour de chaque point en utilisant la fonction st_buffer(). tampon_orford &lt;- st_buffer(pt_max_orford, dist = 10e3) #nous savons que le CRS est d&#39;unité métrique tampon_megantic &lt;- st_buffer(pt_max_megantic, dist = 10e3) tampon_yamaska &lt;- st_buffer(pt_max_yamaska, dist = 10e3) tampon_frontenac &lt;- st_buffer(pt_max_frontenac, dist = 10e3) Filtrer le raster dem_lcc pour ne retenir que les cellules comprises à lintérieur des zones tampons grâce à la fonction mask(). dem_tampon_orford &lt;- mask(dem_lcc, tampon_orford) dem_tampon_megantic &lt;- mask(dem_lcc, tampon_megantic) dem_tampon_yasmaka &lt;- mask(dem_lcc, tampon_yamaska) dem_tampon_frontenac &lt;- mask(dem_lcc, tampon_frontenac) Combiner les quatre raster en un seul en utilisant la fonction merge() dem_tampon_max &lt;- merge(dem_tampon_orford, merge(dem_tampon_megantic, merge(dem_tampon_yasmaka, dem_tampon_frontenac))) Noter que la fonction merge() sutilise sur deux rasters à la fois. Il faut donc lappliquer successivement pour combiner quatre rasters. Visualiser le raster final contenant les quatre zones tampons: mapview(dem_tampon_max) "],["spatiotemp.html", "Module 9 Données spatiotemporelles", " Module 9 Données spatiotemporelles Manipuler le temps (les dates, les heures, les secondes, etc.) représente une compétence indispensable en science des données. Les données spatiales peuvent elles aussi être indexées sur le temps, cest-à-dire se faire attribuer un indice de classification (une «coordonnée») temporelle. On parle alors de données spatio-temporelles qui sont donc des données doublement indexées : indexées sur le temps et indexées sur lespace. Lobjectif principal de ce module est justement de manipuler ce type de données, des séries de vecteurs temporellement ordonnées, et cela pour différentes échelles temporelles. À la fin de ce module vous saurez: Manipuler le temps et les dates. Créer des animations simples qui montre lévolution de données spatialisées dans le temps. Utiliser les objets de classe rasterStack. Écrire des fonctions simples et les utiliser pour structurer vos codes danalyse R. Vous utiliserez les bibliothèques suivantes: mapview raster sf lubridate animation Vous apprendrez à utiliser les fonctions suivantes: hist() sort(), table() st_length() stopifnot st_cast() stack() calc() getZ(), setZ() as_date_time(), ym(), hour(), minute(), second() saveGIF() Et vous apprendrez aussi à créer vos propres fonctions avec function(). Vous utiliserez les données suivantes: Dans la section Leçon, vous utiliserez des données vectorielles de trajets de vélo dans la ville de Montréal ainsi que des données matricielles de températures et de précipitations dans le Parc national du Mont-Mégantic. Dans la section Exercices, vous mettrez en pratique les manipulations vues dans la leçon en utilisant les mêmes données. "],["lecon_spatiotemp.html", "9.1 Leçon", " 9.1 Leçon Cette leçon est divisée en deux parties. Dans la première partie, vous apprendrez à manipuler des données spatiotemporelles de type vectoriel, et dans la seconde partie, des données spatiotemporelles de type matriciel. Chacune des parties est structurée autour dune problématique à résoudre. Dans la première partie, vous analyser un jeu de données de 400 trajets de cyclistes à Montréal. Cette analyse vous amènera à manipuler des objets vectoriels à des échelles de temps fines (de lordre de quelques heures). Dans la seconde partie, vous étudierez lévolution des températures et des précipitations dans la région du Parc national du Mont-Mégantic de 2007 à 2016. Vous manipulerez alors des données climatiques mensuelles sous forme dune série de rasters. 9.1.1 Télécharger les données Les données Les données vectorielles et matricielles utilisées dans ce module peuvent être téléchargées en cliquant sur un seul lien: données pour le module 9. Sauvegardez le dossier compressé (zip) dans votre répertoire de travail Module9_donnees pour ce module, et dézippez-le. Le dossier comprend quatre fichiers: maxt.nc mint.nc pcp.nc trip400.geojson. 9.1.2 Données spatiotemporelles vectorielles Dans cette première partie, nous allons manipuler le temps et lespace dans un ensemble de données vectorielles. Plus précisément, nous utiliserons un ensemble de données comptabilisant 400 trajets en vélo dans la ville de Montréal, et répondrons aux questions suivantes : Quel trajet présente la vitesse moyenne la plus élevée? Quelle est la période de lannée préférée des cyclistes du jeu de données? Nous finirons cette partie avec un exercice de visualisation du trajet le plus long, que nous animerons. 9.1.2.1 Importer les données Le site de la ville de Montréal et le site Données Québec, mettent à disposition un jeu de données incluant près de 5000 trajets individuels à vélo. Ces trajets ont été obtenus avec lapplication Mon RésoVélo qui enregistre les positions de cyclistes à intervalle régulier. Les données de trajets brutes ont ensuite été traitées avant dêtre rendues disponibles en ligne sous licence creative common (CC-BY). Les trajets ont notamment été anonymisés - reportez-vous au lien précédent pour plus dinformations relatives au traitement de ces données. Ce jeu de données de 500 trajets est contenu dans un fichier zippé dextension GeoJSON trip5000.json que nous avons préalablement téléchargé. Ces données étant un peu volumineuses (&gt;150MB), nous avons seulement conservé les 400 premiers trajets. Aussi, nous avons enlevé la colonne liste_segments_jsonb qui permet didentifier les pistes cyclables et les portions du réseau routier emprunter par les cyclistes. Nous avons fait ce pré-traitement en utilisant des manipulations vues dans les modules précédents et que nous décrivons ci-dessous : library(sf) tmp &lt;- st_read(&quot;trip5000.json&quot;) st_write(tmp[1:400, names(tmp) != &quot;liste_segments_jsonb&quot;], &quot;trip400.geojson&quot;) Nous pouvons maintenant utiliser la fonction st_read() de la bibliothèque sf pour lire le fichier simplifié trip400.geojson disponible dans le répertoire Module9_donnees : library(sf) trajets &lt;- st_read(&quot;Module9/Module9_donnees/trip400.geojson&quot;) Reading layer `trip400&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module9\\Module9_donnees\\trip400.geojson&#39; using driver `GeoJSON&#39; Simple feature collection with 400 features and 7 fields Geometry type: LINESTRING Dimension: XY Bounding box: xmin: -73.84 ymin: 45.43 xmax: -73.4 ymax: 45.7 Geodetic CRS: WGS 84 Lobjet trajets est de classe sf et contient un ensemble de 400 lignes décrivant les trajets à vélo et pour lesquels nous avons les informations suivantes : names(trajets) [1] &quot;stop&quot; &quot;id_origine&quot; &quot;start&quot; &quot;length&quot; [5] &quot;purpose&quot; &quot;n_coord&quot; &quot;id&quot; &quot;geometry&quot; Afin de résoudre notre problématique, nous utiliserons les colonnes suivantes: start : date et heure associées au début du trajet, stop : date et heure associées à la fin du trajet, length: longueur du trajet en mètres. 9.1.2.2 Vitesse moyenne des trajets Commençons par résoudre la première question: Quel trajet présente la vitesse moyenne la plus élevée? Nous avons importé 400 trajets à vélo et nous cherchons celui qui présente la vitesse moyenne la plus élevée. Pour calculer une vitesse pour un trajet en particulier, nous devons diviser sa longueur par le temps de parcours. Nous avons donc besoin de trouver dabord la distance des trajets. Dans la table des attributs de trajets, il y a une colonne length qui nous donne cette distance. Par exemple, nous pouvons obtenir la longueur des 10 premiers trajets : trajets$length[1:10] [1] 3163 1066 5619 3115 5376 1153 11845 8033 [9] 21146 8315 Notons quen labsence de cette colonne length, nous pourrions estimer ces distances en utilisant la fonction st_length() vue au module 7 et qui calcule la longueur de chaque ligne de trajets. len &lt;- st_length(trajets) len[1:10] Units: [m] [1] 3157 1065 5614 3110 5367 1152 11828 8021 [9] 21126 8303 Comment nous assurer que les distances répertoriées dans la colonne length sont identiques à celles calculées avec la fonction st_length()? Un moyen simple de le vérifier est de visualiser une distance en fonction de lautre. # Tracer une distance en x, et l&#39;autre en y plot(trajets$length, st_length(trajets), xlab = &quot;distance - colonne &#39;length&#39; (m)&quot;, # ylab = &quot;distance - fonction &#39;st_length()&#39; (m)&quot;, pch = 19) # la forme des points est un cercle plein # Tracer une ligne droite de pente 1 passant par l&#39;origine. # La fonction abline(a,b) permet de créer facilement une ligne en spécifiant # le point d&#39;interception sur l&#39;axe des y (paramètre a) et la pente (paramètre b) abline(a = 0, b = 1, lty = 2) # lty = 2 donne une ligne discontinue Nous voyons ainsi rapidement que tous les points sont sur la ligne 1:1. Ceci nous permet de conclure que les valeurs sont identiques ou très proches - car nous navons pas fait de tests formels, et ils se pourraient donc quil y ait de minimes différences entre les deux distances. Nous devons ensuite quantifier la durée des trajets pour obtenir les vitesses moyennes. Pour cela, nous avons besoin des colonnes start et stop de lobjet trajets qui donnent la date et lheure associées au début et à la fin de chaque trajet. Par exemple, pour les 20 premiers trajets ces colonnes nous donnent : trajets$start[1:10] [1] &quot;2013-06-25 17:21:21 EDT&quot; [2] &quot;2013-07-25 15:37:42 EDT&quot; [3] &quot;2013-07-25 15:19:15 EDT&quot; [4] &quot;2013-06-25 17:21:20 EDT&quot; [5] &quot;2013-06-26 13:46:01 EDT&quot; [6] &quot;2013-07-02 13:21:56 EDT&quot; [7] &quot;2013-07-02 13:05:48 EDT&quot; [8] &quot;2013-07-25 17:45:52 EDT&quot; [9] &quot;2013-07-30 10:38:23 EDT&quot; [10] &quot;2013-07-30 10:19:08 EDT&quot; trajets$stop[1:10] [1] &quot;2013-06-25 17:34:16 EDT&quot; [2] &quot;2013-07-25 15:40:06 EDT&quot; [3] &quot;2013-07-25 15:43:12 EDT&quot; [4] &quot;2013-06-25 17:34:16 EDT&quot; [5] &quot;2013-06-26 14:00:05 EDT&quot; [6] &quot;2013-07-02 13:25:26 EDT&quot; [7] &quot;2013-07-02 13:45:14 EDT&quot; [8] &quot;2013-07-25 18:21:40 EDT&quot; [9] &quot;2013-07-30 11:55:12 EDT&quot; [10] &quot;2013-07-30 11:00:15 EDT&quot; Nous remarquons que la date et lheure sont exprimées dans un format particulier. Regardons la classe des colonnes start et stop  : class(trajets$start) [1] &quot;POSIXct&quot; &quot;POSIXt&quot; class(trajets$stop) [1] &quot;POSIXct&quot; &quot;POSIXt&quot; Les classes obtenues signifient que start et stop sont exprimés par des chaînes de caractères qui suivent une norme POSIX (Portable Operating System Interface). En loccurrence POSIXct (calendar time) est une variété de POSIXt (time) qui contient le nombre de secondes écoulées depuis lHeure Unix (Epoch time), le 1er janvier 1970 00:00:00 UTC (Temps Universel Coordonné). Ainsi, il est possible de convertir des objets de classe POSIXct en objet de classe numeric pour obtenir le temps écoulé en secondes, par exemple : nb_sec &lt;- as.numeric(trajets$start) nb_sec[1:10] [1] 1.372e+09 1.375e+09 1.375e+09 1.372e+09 1.372e+09 [6] 1.373e+09 1.373e+09 1.375e+09 1.375e+09 1.375e+09 Aussi, la soustraction de deux objets POSIXct nous donne un objet de classe difftime qui exprime une durée: duree &lt;- trajets$stop[1] - trajets$start[1] duree Time difference of 12.92 mins class(duree) [1] &quot;difftime&quot; Nous pouvons aussi spécifier lunité de temps dans laquelle nous voulons obtenir la durée entre deux évènements en utilisant la fonction R difftime(). Cette dernière est composée de trois arguments difftime(end, start, units) : la date et lheure de lévènement final, la date et lheure de lévènement initial, et lunité désirée. duree &lt;- difftime(trajets$stop[1], trajets$start[1], units = &#39;secs&#39;) duree Time difference of 775 secs Ainsi, nous pouvons calculer la durée de chaque trajet en seconde en utilisant la fonction difftime(). Ajoutons une colonne à lobjet trajets pour conserver le résultat de ce calcul. trajets$duree_s &lt;- difftime(trajets$stop, trajets$start, units = &#39;secs&#39;) trajets$duree_s[1:10] Time differences in secs [1] 775 144 1437 776 844 210 2366 2148 4609 2467 Regardons maintenant les distributions de longueurs et de durées de trajets en dessinant un histogramme avec la fonction hist(). par(mfrow = c(1, 2)) # figure à deux panneaux côte à côte hist(trajets$length, breaks = seq(0, 44000, 2000), # spécifie les catégories de longueur xlab = &quot;Longueur (m)&quot;, ylab = &quot;Fréquence&quot;, main = &quot;&quot; # pas de titre ) hist(as.numeric(trajets$duree_s), breaks = seq(0, 20000, 1000), # spécifie les catégories de durée xlab = &quot;Durée (s)&quot;, ylab = &quot;Fréquence&quot;, main = &quot;&quot; # pas de titre ) Nous rajoutons maintenant une colonne vitesse_m_s à trajets qui est la vitesse moyenne de chaque trajet, exprimée en mètre par seconde. trajets$vitesse_m_s &lt;- trajets$length/as.numeric(trajets$duree_s) trajets$vitesse_m_s[1:10] [1] 4.081 7.403 3.910 4.014 6.370 5.490 5.006 3.740 [9] 4.588 3.370 Notez que nous avons converti lobjet trajets$duree_s qui est de classe difftime en format numérique pour réaliser cette division. Il peut être plus intuitif dexprimer ces vitesses en kilomètre par heure, plutôt quen mètre par seconde, pour cela il nous suffit de diviser par 1000 [m/km] pour convertir les mètres en kilomètres et de multiplier les secondes par 3600 [s/h] pour les convertir en heures, ce qui revient à multiplier par 3.6 : trajets$vitesse_km_h &lt;- trajets$vitesse_m_s * 3.6 trajets$vitesse_km_h[1:10] [1] 14.69 26.65 14.08 14.45 22.93 19.77 18.02 13.46 [9] 16.52 12.13 Afin de déterminer le trajet le plus rapide, nous allons maintenant ordonner les vitesses par ordre décroissant, avec la fonction sort(), et regarder les 10 premières valeurs : vit_dec &lt;- sort(trajets$vitesse_km_h, decreasing = TRUE) vit_dec[1:10] [1] 365.08 39.60 38.89 34.30 34.12 33.20 30.67 [8] 30.46 29.99 29.51 Le ou la plus rapide des cyclistes circule à une vitesse moyenne de 365 km/h, ce qui ne semble pas réaliste! Nous supposons quun problème denregistrement de ce trajet est à lorigine de cette valeur abberante. Nous excluons donc ce trajet et retenons le second comme étant le plus rapide. Pour extraire le second trajet, nous utilisons la fonction order(). traj_rapide &lt;- trajets[order(trajets$vitesse_km_h, decreasing = TRUE)[2], ] traj_rapide Simple feature collection with 1 feature and 10 fields Geometry type: LINESTRING Dimension: XY Bounding box: xmin: -73.59 ymin: 45.53 xmax: -73.58 ymax: 45.53 Geodetic CRS: WGS 84 stop id_origine start 207 2013-08-05 22:00:02 3943 2013-08-05 21:58:45 length purpose n_coord id 207 847 Social 145 3943 geometry duree_s vitesse_m_s 207 LINESTRING (-73.58 45.53, -... 77 secs 11 vitesse_km_h 207 39.6 Notez que la fonction order() retourne lindice de lélément désiré, alors que la fonction sort() retourne la valeur de lélément. Nous pouvons visualiser ce trajet en utilisant la fonction mapview() de la bibliothèque mapview(). library(mapview) mapview(traj_rapide) Warning in clean_columns(as.data.frame(obj), factorsAsCharacter): Dropping column(s) duree_s of class(es) difftime Un trajet bien singulier, à 22h près du parc Laurier. Nous remarquons que lenregistrement du trajet manque probablement de précision, ce qui expliquerait son allure quelque peu tordue 9.1.2.3 Période de lannée préférée Penchons-nous maintenant sur la deuxième question. Quelle est la période de lannée préférée des cyclistes du jeu de données? Pour répondre à cette deuxième question, nous allons utiliser certaines fonctions de la bibliothèque lubridate. Bien que R dispose, de base, de toutes les fonctionnalités nécessaires à la manipulation des dates et du temps, lubridate rend ces manipulations plus intuitives (laide mémoire (https://github.com/rstudio/cheatsheets/raw/master/lubridate.pdf fait un tour dhorizon complet des fonctionnalités de lubridate). Installons donc la bibliothèque lubridate : install.packages(&quot;lubridate&quot;) Chargeons la bibliothèque lubridate dans notre session de travail R afin de manipuler les données de classes POSIXct des colonnes start et stop. Par exemple nous pouvons extraire lannée avec la fonction year() : library(lubridate) Warning: package &#39;lubridate&#39; was built under R version 4.2.2 year(trajets$start)[1:20] [1] 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 [11] 2013 2013 2013 2013 2013 2013 2013 2013 2013 2013 Afin de répondre à la question, nous commençons par identifier le mois de lannée qui compte le plus de trajets à vélo. Pour cela, nous allons utiliser la fonction month() de la bibliothèque lubridate. Cette fonction nous retourne le mois associé à un objet de classe POSIXct month(trajets$start[1]) [1] 6 La fonction month() nous offre aussi la possibilité dutiliser les noms de mois (en anglais) sous forme de facteurs, de manière abrégée  : month(trajets$start[1], label = TRUE) [1] Jun 12 Levels: Jan &lt; Feb &lt; Mar &lt; Apr &lt; May &lt; ... &lt; Dec ou intégrale : month(trajets$start[1], label = TRUE, abbr = FALSE) [1] June 12 Levels: January &lt; February &lt; March &lt; ... &lt; December Pour la tâche à réaliser, utilisons seulement le numéro des mois et créons une colonne mois dans la table dattributs de lobjet trajets pour les conserver : trajets$mois &lt;- month(trajets$start) trajets$mois[1:20] [1] 6 7 7 6 6 7 7 7 7 7 6 6 7 7 6 6 6 6 7 7 Une manière efficace de compter le nombre doccurrence est dappliquer la fonction table() sur la colonne nouvellement créée : nb_mois &lt;- table(trajets$mois) nb_mois 1 5 6 7 8 6 1 11 376 6 Juillet (le 7ième mois de lannée) est donc le mois qui concentre le plus de trajets à vélo dans le jeu de données étudié. Nous allons maintenant regarder le jour qui concentre le plus de trajets avec la fonction day() de la bibliothèque lubridate. Nous commençons par ajouter une colonne jour à lobjet trajets. trajets$jour &lt;- day(trajets$start) trajets$jour[1:10] [1] 25 25 25 25 26 2 2 25 30 30 Isolons ensuite les trajets effectués au mois de juillet. traj_juillet &lt;- trajets[trajets$mois == 7, ] Enfin, visualisons le nombre de trajets par jour avec les fonctions table() et barplot() cette fois-ci. barplot( table(traj_juillet$jour), xlab = &quot;Jour de juillet&quot;, ylab = &quot;Nombre de trajets&quot; ) Cest donc le 10 juillet que nous recensons le plus grand nombre de trajets. Nous allons même aller à léchelle de lheure et nous recommençons les étapes précédentes avec la fonction hour(). Au passage, mentionnons la bibliothèque hms pour manipuler les heures, minutes et secondes (nous ne lutiliserons pas ici, mais elles pourraient vous être utile dans vos projets futurs). trajets$heure &lt;- hour(trajets$start) traj_10juillet &lt;- trajets[trajets$mois == 7 &amp; trajets$jour == 10, ] barplot( table(traj_10juillet$heure), xlab = &quot;Jours de juillet&quot;, ylab = &quot;Nombre de trajets&quot; ) Cest donc à 17h le 10 juillet que les trajets sont les plus nombreux. 9.1.2.4 Animation du trajet le plus long Nous allons à présent animer le trajet de vélo le plus long. Nous voulons, en effet, créer un fichier GIF qui illustrera le parcours de la ou du cycliste. Pour y arriver nous devrons faire les étapes suivantes : Trouver le trajet le plus long. Associer un temps à chaque segment du parcours. Créer une carte pour différents états davancement du parcours. Rassembler les cartes ainsi créées et en faire un fichier GIF. Commençons! 1. Trajet le plus long La première étape est une manipulation de filtres que nous avons fait à maintes reprises. Cette fois-ci appliquons which.max() sur la colonne length() et nous filtrons avec [. traj_long &lt;- trajets[which.max(trajets$length), ] traj_long Simple feature collection with 1 feature and 13 fields Geometry type: LINESTRING Dimension: XY Bounding box: xmin: -73.69 ymin: 45.43 xmax: -73.55 ymax: 45.53 Geodetic CRS: WGS 84 stop id_origine start 69 2013-07-30 15:52:09 3082 2013-07-30 11:38:30 length purpose n_coord id 69 42503 Social 14511 3082 geometry duree_s 69 LINESTRING (-73.57 45.52, -... 15219 secs vitesse_m_s vitesse_km_h mois jour heure 69 2.793 10.05 7 30 11 Regardons ce trajet : mapview(traj_long) Warning in clean_columns(as.data.frame(obj), factorsAsCharacter): Dropping column(s) duree_s of class(es) difftime 2. Segmentation du trajet Nous allons segmenter le trajet le plus long en une série de points successifs. Chaque point marquera ainsi une portion du trajet total. Nous allons ensuite associer un temps à chacune de ces portions. Pour ce faire, nous commencons par convertir la géométrie de traj_long de LINESTRING à POINT avec la fonction st_cast() vue au module 7. traj_long_pts &lt;- st_as_sf(st_cast(st_geometry(traj_long), to = &quot;POINT&quot;)) traj_long_pts Simple feature collection with 10818 features and 0 fields Geometry type: POINT Dimension: XY Bounding box: xmin: -73.69 ymin: 45.43 xmax: -73.55 ymax: 45.53 Geodetic CRS: WGS 84 First 10 features: x 1 POINT (-73.57 45.52) 2 POINT (-73.57 45.52) 3 POINT (-73.57 45.52) 4 POINT (-73.57 45.52) 5 POINT (-73.57 45.52) 6 POINT (-73.57 45.52) 7 POINT (-73.57 45.52) 8 POINT (-73.57 45.52) 9 POINT (-73.57 45.52) 10 POINT (-73.57 45.52) Décortiquons cette ligne: Nous isolons dabord la géométrie de traj_long avec la fonction st_geometry(). Nous faisons ensuite la conversion point/ligne avec la fonction st_cast(). Finalement, nous convertissons lobjet de classe sfc ainsi obtenu en objet de classe sf avec st_as_sf(). Lobjet traj_long_pts ainsi créé contient 10818 points nrow(traj_long_pts) [1] 10818 Maintenant, nous allons associer un temps à chaque point du trajet. Demblée, il nous est possible de déterminer le temps de départ et le temps darrivée de ce trajet puisque ceux-ci sont donnés par les valeurs de traj_long$start et de traj_long$stop respectivement. De plus, lapplication Mon RésoVélo enregistre les coordonnées spatiales le long dun trajet à intervalle régulier. Ainsi, le temps associé à chaque point dun trajet est réparti de façon régulière entre son temps de départ et son temps darrivée. Nous créons donc une séquence régulière avec la fonction R seq() en spécifiant le temps de départ, le temps darrivé et le nombre de points que doit inclure la séquence (argument length.out) qui est le nombre de lignes (nrow()) de la table dattributs de traj_long_pts. Finalement, nous ajoutons cette séquence au nouvel objet traj_long_pts dans une colonne temps. traj_long_pts$temps &lt;- seq( from = traj_long$start, to = traj_long$stop, length.out = nrow(traj_long_pts) ) 3. Visualisation du trajet pour différentes périodes À présent, nous allons visualiser le trajet parcouru sur différentes périodes de temps. Pour chaque période, nous sauvegarderons la visualisation obtenue. À la prochaine étape, nous combinerons ces images pour obtenir une animation. Dans un premier temps, visualisons le trajet parcouru pour une période de temps arbitraire, autrement dit pour une période allant du premier point jusquà nimporte quel points \\(n\\) le long du trajet traj_long_pts. À titre dexemple, choisissons les 2000 premiers points. lin &lt;- st_cast(st_combine(traj_long_pts[1:2000, ]), &quot;LINESTRING&quot;) Cette ligne contient les étapes suivantes: Nous extrayons les 2000 premiers points avec [. Nous les combinons en MULTIPOINT avec st_combine(). Nous transformons le MULTIPOINT en LINESTRING avec st_cast(). Notons que sans létape (ii), st_cast() transformera chaque point en ligne ce qui donnera un ensemble de lignes de 1 seul point. Regardons cette section du trajet avec mapview(). mapview(lin) Grâce à létape précédente, nous pouvons facilement avoir accès à lheure correspondant au dernier point de cette section du trajet. traj_long_pts$temps[2000] [1] &quot;2013-07-30 12:25:22 EDT&quot; Avec la fonction st_length() de la bibliothèque sf nous pouvons connaître la distance parcourue pour cette section du trajet : st_length(lin) 7866 [m] Visualisons maintenant cette section du trajet en utilisant la bibliothèque tmap. Dans le titre de la carte, indiquons la distance parcourue ainsi que le temps associé. Des objets de classe caractère peuvent être combinés (cest-à-dire écrits lun à la suite des autres sans espacement) en utilisant la fonction R paste0(). library(tmap) tm_shape(lin, bbox = st_bbox(traj_long_pts)) + tm_lines(lwd = 2, col = &quot;#62852eaa&quot;) + tm_layout(main.title = paste0( &quot;temps: &quot;, traj_long_pts$temps[2000], &quot; / distance&quot;, st_length(lin) ), main.title.size = 0.9) Pour obtenir une animation pour la totalité du trajet traj_long, nous devons alors faire cette même carte pour un nombre croissant de points et combiner toutes ces cartes en un seul fichier GIF. Puisque le trajet total compte 10818 points, cette tâche est répétitive. Dans ce qui suit nous allons structurer notre code avec quelques fonctions. Cela nous permet disoler les différentes étapes à réaliser et déviter de répétées du code. De manière générales, structurer son code en différentes fonctions permet daugmenter la clarté du code et de diminuer les erreurs qui arrivent rapidement quand le code se complexifie. Nous devons donc prendre un peu de temps pour expliquer comment créer une fonction. Jusquici nous avons utilisé de nombreuses fonctions déjà définies dans R ou dans les bibliothèques employées sans que nous nayons eu besoin de créer nos propres fonctions. Pour comprendre comment est structurée une fonction, nous allons détailler un exemple simple. ma_fonction &lt;- function(a, b = 1) { if (b &gt; 0) { c &lt;- a + b } else { c &lt;- a - 2*b } return(c) # ou simplement c } Dans R, une fonction est un objet créé avec function(). Comme tout objet nous pouvons lassigner à une variable et dans notre exemple, nous lassignons à ma_fonction qui sera le nom de la fonction. Dans la parenthèse qui suit function, nous écrivons les arguments de la fonction, en loccurrence pour ma_fonction, nous avons a et b. Dans notre exemple, b a une valeur par défaut qui est 1, donc si nous ne spécifions pas b, alors b aura automatiquement une valeur de 1. Le corps de la fonction est lexpression juste après cette parenthèse, dans notre cas cela inclut tout ce qui est entre accolades ({ }). Une fonction peut comprendre autant de ligne de code que souhaité et peut contenir nimporte quelle expression R valide. À titre dexemple, nous avons utilisé un test logique if/else pour que la valeur retournée c change selon les valeurs de b. Avec R, une fonction retourne la dernière ligne de code (lutilisation de return() à la dernière ligne est ainsi optionnelle, mais elle permet de clarifier ce que retourne la fonction). Une fois la fonction créée, nous lappelons comme toute autre fonction. ma_fonction(1) # utlise b = 1 [1] 2 ma_fonction(1, 2) [1] 3 ma_fonction(1, -2) [1] 5 Nous sommes maintenant outillés pour créer différentes fonctions pour structurer notre code. Notre fonction principale, visual(), a pour argument les points du trajet, traj_pts, et le nombre de points à combiner, que nous appellerons n. Cette fonction reprend les étapes précédentes. visual &lt;- function(traj_pts, n = 100) { # extraction des n premiers points pts &lt;- traj_pts[1:n, ] # conversion des points en ligne lin &lt;- st_cast(st_combine(pts), &quot;LINESTRING&quot;) # carte de la ligne tm_shape(lin, bbox = st_bbox(traj_long_pts)) + tm_lines(lwd = 2, col = &quot;#62852eaa&quot;) + tm_layout(main.title = paste0( &quot;temps: &quot;, traj_long_pts$temps[n], &quot; / distance&quot;, st_length(lin) ), main.title.size = 0.9) } Nous allons faire quelques améliorations sur le texte accompagnant les cartes en créant deux autres fonctions. La première, txt_temps(), a pour argument un temps (nous utiliserons le temps du point n) et retourne un texte formaté grâce aux fonctionnalités de la bibliothèque lubridate. txt_temps &lt;- function(temps) { paste0(hour(temps), &quot;h &quot;, minute(temps), &quot;m &quot;, floor(second(temps)), &quot;s&quot;) } La seconde, txt_distance(), prend pour argument une ligne et retourne un texte formaté comprenant la distance en kilomètre. txt_distance &lt;- function(lin) { len &lt;- st_length(lin) paste0(&quot;Distance parcourue: &quot;, format(as.numeric(len)/1000, digits = 4), &quot;km&quot;) } Notons que la fonction R format() nous permet de contrôler le nombre de chiffres (digits) affiché. Nous allons reformuler notre fonction visual() pour quelle appelle ces deux fonctions. De plus, nous y ajoutons un argument, basemap, de la bibliothèque tmap, qui nous permet dajouter un fond de carte. Cet argument a pour valeur NULL par défaut, ce qui nous permet davoir, par défaut, une carte sans fond. Enfin, nous allons nous assurer que le nombre n de points à combiner soit supérieur à 1 car nous avons besoin dun minimum de 2 points pour créer une ligne. Cette condition est assurée par la fonction R stopifnot(). visual &lt;- function(traj_pts, n = 100, basemap = NULL) { stopifnot(n &gt; 1) tps &lt;- traj_pts$temps[n] pts &lt;- traj_pts[1:n, drop = FALSE] lin &lt;- st_cast(st_combine(pts), &quot;LINESTRING&quot;) basemap + tm_shape(lin, bbox = st_bbox(traj_long_pts)) + tm_lines(lwd = 2, col = &quot;#62852eaa&quot;) + tm_layout(main.title = paste0(txt_temps(tps), &quot; - &quot;, txt_distance(lin)), main.title.size = 0.9) } Nous pouvons maintenant faire la carte pour le nombre de points désirés, avec un minimum de 2 et un maximum de 10818 points. Pour faire la figure précédente nous utilisons le code suivant : visual(traj_long_pts, 2000) Lavantage du travail précédent est que nous pouvons maintenant très facilement faire la même carte en appelant notre fonction et en changeant simplement la valeur de n, par exemple, nous pouvons faire la même carte avec les 4000 premiers points. visual(traj_long_pts, 4000) 4. Créer une animation Nous allons maintenant créer une nouvelle fonction, anim(), qui nous permettra de générer une série de n_img images de notre trajet en appelant notre fonction visual() créée à létape précédente. anim &lt;- function(traj_pts, n_img, basemap = NULL) { for (i in floor(seq(2, nrow(traj_pts), length.out = n_img))) { print(visual(traj_pts, i, basemap)) } } Quelques remarques: La fonction for() constitue ce quon appelle une boucle en programmation informatique. La boucle vient répéter une action, donnée par les lignes de codes entre les accolades { }, pour chaque élément contenu dans une séquence. Nous utilisons seq() pour générer une séquence de n_img images entre 2 et le maximum de points (10818). La séquence peut générer des nombres décimaux, mais visual() demande des nombre entiers, nous utilisons alors floor() pour la conversion. Nous reprenons largument basemap pour quil puisse être passé à visual(). Observons, par exemple, la succession de cartes créées par la fonction anim() lorsque n_img = 5 : anim(traj_long_pts, n_img = 5, NULL) Une fois lanimation créée, pour un nombre dimages donné, nous voulons la sauvegarder en format GIF. Pour générer un fichier GIF, nous utilisons la fonction saveGIF() de la bibliothèque animation. Cette fonction prend en premier argument une expression (du code R) qui permet de générer une série de figures qui seront ensuite combinées en GIF. Installons la bibliothèque animation. install.packages(&quot;animation&quot;) Nous pouvons maintenant utiliser saveGIF(). library(animation) saveGIF(anim(traj_long_pts, 20, NULL), movie.name = &quot;anim1.gif&quot;, ani.height = 500, ani.width = 500) Pour finir, nous allons ajouter un fond de carte. Pour cela nous allons télécharger un fond de carte de OpenStreetMap grâce à fonction osm.raster() de la bibliothèque rosm. Installons la bibliothèque rosm. install.packages(&quot;rosm&quot;) La fonction osm.raster() sutilise avec la library raster. Nous devons donc charger également cette library dans notre session de travail R. Nous devons aussi spécifier à la fonction osm.raster() létendue de la carte de fond désirée. library(raster) library(rosm) carte_fond &lt;- osm.raster(extent(traj_long_pts), crop = TRUE) carte_fond Visualisons cette carte de fond avec les fonctionnalités de la library tmap: tm_shape(carte_fond) + tm_rgb() Maintenant, répétons notre animation en remplaçant la valeur NULL de largument basemap par la carte de fond. saveGIF(anim(traj_long_pts, 20, tm_shape(carte_fond) + tm_rgb()), movie.name = &quot;anim2.gif&quot;, ani.height = 500, ani.width = 500) 9.1.3 Données spatiotemporelles matricielles Dans cette deuxième partie de la leçon, nous allons manipuler le temps et lespace dans un ensemble de données matricielles. Plus précisément, nous nous intéresserons aux précipitations et aux températures moyennes autour du Parc national du Mont-Mégantic entre 2007 et 2016. Nous chercherons à répondre aux deux questions suivantes : Quel mois dispose du plus faible niveau de pluviométrie dans la région du Parc national du Mont-Mégantic? Où se situe le (ou les) point(s) le(s) plus chaud(s) dans la région du Parc national du Mont-Mégantic? De plus, nous terminerons cette partie par la réalisation de deux exercices de visualisation de données : Nous dessinerons les profils de températures et de précipitations pour la période étudiée. Nous animerons ces profils en ajoutant une carte, elle aussi animée. Pour pouvoir répondre à ces questions et réaliser ces exercices, nous utiliserons différents rasters qui seront manipulés sous forme dobjets rasterStack (mentionnés au Module 5). 9.1.3.1 Importer les données Les données que nous allons utiliser dans cette partie ont été préparées à partir de données climatiques historiques à haute résolution pour lAmérique du Nord (MacDonald et al. 2020). Ces données (issues dun travail de modélisation) sont disponibles sur lespace dédié à larchivage de données du Centre allemand de calcul pour le climat, DKRZ (pour y accéder, il faut dabord senregistrer sur le site). Les données sont disponibles dans le répertoire Module9_donnees et elles incluent, pour lensemble de lAmérique du Nord et pour chaque mois de 1901 à 2016, les trois variables suivantes: la température minimale moyenne (mint.nc), la température maximale moyenne (maxt.nc), les précipitations cumulées (pcp.nc), et ce, à une résolution de 60 arc-secondes. FIGURE 9.1: Température minimale moyenne au mois de janvier 2000. Par exemple, sur la figure 9.1, nous présentons les températures minimales moyennes pour le mois de janvier 2000. À partir des données brutes, nous avons sélectionné les données correspondantes aux années 2007 à 2016, puis nous avons fait une opération de rognage en utilisant létendue spatiale suivante (dans le système géodésique mondial WGS84): longitude : de 72°Ouest à 71°Ouest, latitude : de 45°Nord à 46°Nord. Les données préparées sont en format NetCDF (Network Common Data Form). Ces données peuvent être importées en utilisant la fonction stack() de la bibliothèque raster mais nécessitent lutilisation de la bibliothèque ncdf4. Commençons par installer cette bibliothèque : install.packages(&quot;ncdf4&quot;) Puis, chargeons les bibliothèques raster et ncdf4 et importons les données en utilisant la fonction stack() : library(raster) library(ncdf4) # temperature minimale par mois pour mint &lt;- stack(&quot;Module9/Module9_donnees/mint.nc&quot;) # temperature maximale par mois maxt &lt;- stack(&quot;Module9/Module9_donnees/maxt.nc&quot;) # total des precipitations par mois pcp &lt;- stack(&quot;Module9/Module9_donnees/pcp.nc&quot;) class(mint) [1] &quot;RasterStack&quot; attr(,&quot;package&quot;) [1] &quot;raster&quot; Il sagit là dobjets de classe rasterStack que nous détaillons dans la section suivante. 9.1.3.2 Les objets rasterStack Pour cette section, nous nous concentrons sur lobjet mint, notons cependant que tout ce que nous voyons ici sapplique aux autres objets rasterStack que nous avons importés. Inspectons rapidement ce nouvel objet. mint class : RasterStack dimensions : 60, 60, 3600, 120 (nrow, ncol, ncell, nlayers) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs names : X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, ... min values : -16.2, -19.9, -12.8, -4.5, 2.4, 8.2, 9.7, 9.2, 6.3, 2.7, -7.1, -13.6, -13.9, -14.5, -13.9, ... max values : -13.9, -18.0, -9.5, -0.6, 5.5, 11.8, 13.0, 11.7, 8.7, 5.3, -4.0, -10.6, -11.8, -12.7, -10.0, ... Nous obtenons des informations similaires à celles dun objet de classe rasterLayer, cependant la ligne qui indique les dimensions possède un élément de plus indiquant le nombre de couches, et les valeurs affichées correspondent aux valeurs minimales et maximales pour chacune des différentes couches. Extraire les informations générales Un raster rasterStack est en fait une collection derasterLayer qui ont la même projection spatiale, la même résolution, la même étendue spatiale et donc le même nombre de cellules. Pour obtenir ces informations individuellement, nous utilisons les mêmes fonctions que pour les rasterLayer. extent(mint) class : Extent xmin : -71.99 xmax : -70.99 ymin : 45.01 ymax : 46.01 projection(mint) [1] &quot;+proj=longlat +ellps=WGS84 +no_defs&quot; ncell(mint) [1] 3600 Les dimensions du rasterStack peuvent être aussi être affichées avec la fonction dim() dim(mint) [1] 60 60 120 Comme nous pouvons le constater, 3 nombres sont retournés, un de plus que pour les objets rasterLayer, le dernier chiffre est le nombre de couches que nous avons mentionné plus haut, ici 120. Ce nombre peut aussi être affiché en utilisant la fonction nlayers(). nlayers(mint) [1] 120 Lobjet mint est une donc collection de 120 objets de classe rasterLayer, chaque couche représente des valeurs de températures minimales moyennes sur toutes la zone pour un mois donné. Ici, les couches sont ordonnées dans le temps (elles ont été combinées ainsi) et nous avons 1 couche par mois sur 10 ans. Extraire une selection de couches Il est possible daccéder à nimporte quelle couche (rasterLayer) en utilisant [[: class(mint[[1]]) [1] &quot;RasterLayer&quot; attr(,&quot;package&quot;) [1] &quot;raster&quot; # Raster de Température minimale du mois de janvier de la première année (2007) mint[[1]] class : RasterLayer band : 1 (of 120 bands) dimensions : 60, 60, 3600 (nrow, ncol, ncell) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs source : mint.nc names : X1 values : -16.2, -13.9 (min, max) zvar : variable # Raster de Température minimale du mois de décembre de la dernière année (2016) mint[[120]] class : RasterLayer band : 120 (of 120 bands) dimensions : 60, 60, 3600 (nrow, ncol, ncell) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs source : mint.nc names : X120 values : -13, -9.5 (min, max) zvar : variable Nous pouvons aussi prendre une séquence dindices et obtenir un autre rasterStack. Par exemple, nous pouvons obtenir les données de la première année en utilisant les 12 premiers indices. mint[[1:12]] class : RasterStack dimensions : 60, 60, 3600, 12 (nrow, ncol, ncell, nlayers) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs names : X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12 min values : -16.2, -19.9, -12.8, -4.5, 2.4, 8.2, 9.7, 9.2, 6.3, 2.7, -7.1, -13.6 max values : -13.9, -18.0, -9.5, -0.6, 5.5, 11.8, 13.0, 11.7, 8.7, 5.3, -4.0, -10.6 Nous pouvons aussi obtenir les températures minimales pour les 10 mois de septembre, nous utilisons pour cela la fonction seq(). mint[[seq(9, by = 12, length.out = 10)]] class : RasterStack dimensions : 60, 60, 3600, 10 (nrow, ncol, ncell, nlayers) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs names : X9, X21, X33, X45, X57, X69, X81, X93, X105, X117 min values : 6.3, 6.3, 4.7, 7.4, 8.1, 5.1, 5.8, 5.8, 8.6, 7.0 max values : 8.7, 9.3, 7.3, 10.3, 10.7, 8.4, 9.1, 8.9, 11.5, 9.3 Il est aussi possible de combiner des couches du même rasterStack et de différents rasterStack (si les contraintes spatiales sont respectées) avec stack(). stack(mint[[1]], maxt[[1]], pcp[[1]]) class : RasterStack dimensions : 60, 60, 3600, 3 (nrow, ncol, ncell, nlayers) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs names : X1.1, X1.2, X1.3 min values : -16.2, -7.6, 66.8 max values : -13.9, -3.7, 107.0 Nous avons, ici, créé un rasterStack en combinant les températures minimales et maximales, et les précipitations cumulées du mois de janvier de la première année (2007). Extraire et manipuler les valeurs Nous pouvons extraire les valeurs en utilisant la double indexation : [[ pour choisir les couches désirées, et puis [ pour extraire les valeurs des couches sélectionnées. Ainsi, nous pouvons extraire les valeurs des 10 premières cellules pour la première année (cest-à-dire les 12 premiers mois). mint[[1:12]][1:10] X1 X2 X3 X4 X5 X6 X7 X8 X9 [1,] -15.0 -19.0 -9.7 -0.9 5.5 11.8 13.0 11.5 8.7 [2,] -15.1 -19.1 -9.7 -1.0 5.5 11.7 12.9 11.4 8.7 [3,] -15.2 -19.1 -9.9 -1.1 5.4 11.6 12.8 11.3 8.6 [4,] -15.2 -19.1 -9.9 -1.1 5.4 11.6 12.7 11.3 8.6 [5,] -15.2 -19.1 -9.9 -1.1 5.3 11.6 12.7 11.3 8.6 [6,] -15.2 -19.1 -9.9 -1.1 5.3 11.6 12.7 11.3 8.6 [7,] -15.2 -19.1 -9.8 -1.1 5.3 11.6 12.8 11.3 8.6 [8,] -15.2 -19.1 -9.9 -1.2 5.3 11.5 12.7 11.2 8.5 [9,] -15.2 -19.1 -10.0 -1.2 5.3 11.5 12.6 11.1 8.5 [10,] -15.3 -19.0 -10.0 -1.3 5.2 11.4 12.5 11.1 8.5 X10 X11 X12 [1,] 5.3 -4.0 -12.2 [2,] 5.2 -4.1 -12.3 [3,] 5.1 -4.3 -12.4 [4,] 5.1 -4.4 -12.4 [5,] 5.1 -4.3 -12.4 [6,] 5.1 -4.3 -12.4 [7,] 5.1 -4.2 -12.3 [8,] 5.1 -4.4 -12.4 [9,] 5.0 -4.5 -12.5 [10,] 4.9 -4.6 -12.5 Nous obtenons ainsi une matrice de 12 colonnes (1 colonne par mois) et 10 lignes (1 par cellule). Il est aussi possible dutiliser getValues() pour obtenir lensemble des valeurs dun objet rasterStack. Dans ce cas, les valeurs sont alors retournées sous forme de matrice. val &lt;- getValues(mint) dim(val) [1] 3600 120 Pour appliquer les mêmes opérations sur les différentes couches, il est possible dutiliser la fonction R apply() après avoir utilisée la fonction getValues(). Par exemple, pour connaître la valeur minimale de chaque couche, nous pouvons utiliser la ligne suivante : apply(val, 2, min) X1 X2 X3 X4 X5 X6 X7 X8 X9 -16.2 -19.9 -12.8 -4.5 2.4 8.2 9.7 9.2 6.3 X10 X11 X12 X13 X14 X15 X16 X17 X18 2.7 -7.1 -13.6 -13.9 -14.5 -13.9 -2.6 0.7 9.7 X19 X20 X21 X22 X23 X24 X25 X26 X27 11.6 9.5 6.3 -0.4 -4.9 -14.3 -21.2 -14.9 -11.2 X28 X29 X30 X31 X32 X33 X34 X35 X36 -3.2 2.1 7.6 10.1 10.9 4.7 -1.1 -2.8 -13.0 X37 X38 X39 X40 X41 X42 X43 X44 X45 -13.4 -11.2 -6.5 -1.1 3.8 8.2 12.8 10.2 7.4 X46 X47 X48 X49 X50 X51 X52 X53 X54 0.0 -5.1 -12.7 -16.2 -16.4 -11.6 -4.1 4.9 8.1 X55 X56 X57 X58 X59 X60 X61 X62 X63 11.3 10.6 8.1 1.9 -2.5 -10.3 -15.0 -12.8 -6.6 X64 X65 X66 X67 X68 X69 X70 X71 X72 -3.3 5.4 8.4 11.0 11.3 5.1 2.4 -6.8 -10.4 X73 X74 X75 X76 X77 X78 X79 X80 X81 -16.8 -14.1 -9.4 -5.0 3.5 8.5 12.7 9.8 5.8 X82 X83 X84 X85 X86 X87 X88 X89 X90 1.4 -7.6 -14.2 -17.5 -16.0 -17.8 -5.0 3.4 8.3 X91 X92 X93 X94 X95 X96 X97 X98 X99 11.1 9.8 5.8 3.0 -6.7 -10.0 -20.4 -23.2 -15.5 X100 X101 X102 X103 X104 X105 X106 X107 X108 -5.6 4.8 6.9 10.6 11.5 8.6 -1.7 -4.0 -5.7 X109 X110 X111 X112 X113 X114 X115 X116 X117 -14.0 -13.3 -9.3 -6.7 3.3 7.9 11.1 11.5 7.0 X118 X119 X120 1.5 -3.7 -13.0 Notez que largument 2 signifie que la fonction min() est appliquée sur la deuxième dimension de la matrice val (cest-à-dire la dimension associée aux couches). Nous pouvons aussi utiliser la fonction summary() qui nous donne un aperçu de la distribution des valeurs pour chaque couche. Par exemple, voici le résumé des cinq premières couches : su_mint &lt;- summary(mint) su_mint[,1:5] X1 X2 X3 X4 X5 Min. -16.2 -19.9 -12.8 -4.5 2.4 1st Qu. -15.2 -19.1 -11.0 -2.2 4.1 Median -15.0 -18.9 -10.4 -1.7 4.6 3rd Qu. -14.8 -18.7 -10.3 -1.4 4.9 Max. -13.9 -18.0 -9.5 -0.6 5.5 NA&#39;s 0.0 0.0 0.0 0.0 0.0 Aussi, certaines fonctions ont des comportements prédéfinies pour les objets rasterStack. Par exemple, la fonction min() retourne un objet de classe rasterLayer dont chaque cellule contient la valeur minimale des cellules des différentes couches ayant la même latitude et la même longitude (cest-à-dire à la même position dans le raster). min(mint) class : RasterLayer dimensions : 60, 60, 3600 (nrow, ncol, ncell) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs source : memory names : layer values : -23.2, -22 (min, max) La fonction max() a le même comportement, pour une combinaison (longitude, latitude) donnée, elle retourne la valeur maximale des différentes cellules. La fonction quantile() retourne les quantiles pour les différentes couches, par défaut, 5 quantiles sont retournées. Ci-dessous, nous présentons le résultat pour les 10 premières couches. quantile(mint)[1:10, ] 0% 25% 50% 75% 100% X1 -16.2 -15.2 -15.0 -14.8 -13.9 X2 -19.9 -19.1 -18.9 -18.7 -18.0 X3 -12.8 -11.0 -10.4 -10.3 -9.5 X4 -4.5 -2.2 -1.7 -1.4 -0.6 X5 2.4 4.1 4.6 4.9 5.5 X6 8.2 10.3 10.8 11.1 11.8 X7 9.7 11.3 12.0 12.2 13.0 X8 9.2 10.6 10.8 11.0 11.7 X9 6.3 7.6 8.1 8.3 8.7 X10 2.7 4.3 4.6 4.8 5.3 Cette opération est équivalente à appliquer la fonction apply() et quantile() après avoir utilisé getValues(). apply(val, 2, quantile)[, 1:10] X1 X2 X3 X4 X5 X6 X7 X8 X9 X10 0% -16.2 -19.9 -12.8 -4.5 2.4 8.2 9.7 9.2 6.3 2.7 25% -15.2 -19.1 -11.0 -2.2 4.1 10.3 11.3 10.6 7.6 4.3 50% -15.0 -18.9 -10.4 -1.7 4.6 10.8 12.0 10.8 8.1 4.6 75% -14.8 -18.7 -10.3 -1.4 4.9 11.1 12.2 11.0 8.3 4.8 100% -13.9 -18.0 -9.5 -0.6 5.5 11.8 13.0 11.7 8.7 5.3 Il est aussi possible de faire des calculs sur les différentes couches en utilisant la fonction calc(), par exemple nous pouvons obtenir le quantiles cellule par cellule de la manière suivante : calc(mint, quantile) class : RasterBrick dimensions : 60, 60, 3600, 5 (nrow, ncol, ncell, nlayers) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs source : memory names : X0., X25., X50., X75., X100. min values : -23.200, -11.300, -1.400, 7.675, 12.800 max values : -22.000, -8.325, 1.300, 10.625, 16.100 Ce qui nous donne un objet rasterStack qui loge, sur chacune de ses 5 couches, les valeurs des différents quantiles pour chacune des combinaisons (longitude, latitude). Nous noterons alors quutiliser calc(mint, min) revient à utiliser min(mint). Réaliser des opérations spatiales Les principales opérations spatiales pour les objets de classe rasterStack utilisent les mêmes fonctions que pour les objets de classe rasterLayer. Les opérations spatiales à réaliser seront alors, au besoin, répétées sur les différentes couches (cela étant dit, pour des raisons doptimisation algorithmiques, il se peut que les opérations soient plus rapides sur un rasterStack de \\(n\\) couches plutôt que dappliquer \\(n\\) fois les mêmes opérations sur \\(n\\) objets rasterLayer). En guise de démonstration, nous allons utiliser les fonctions projectRaster(), crop(), mask() et extract() sur le rasterStack mint (voir le Module 5 et le Module 8 pour plus de détails sur ces fonctions). Pour illustrer le changement de projections des rasterStack, projetons mint en utilisant la projection de Mercator. library(sf) mint_merc &lt;- projectRaster(mint, crs = st_crs(3857)$proj4string) mint_merc class : RasterBrick dimensions : 70, 74, 5180, 120 (nrow, ncol, ncell, nlayers) resolution : 1860, 2650 (x, y) extent : -8027100, -7889460, 5609433, 5794933 (xmin, xmax, ymin, ymax) crs : +proj=merc +a=6378137 +b=6378137 +lat_ts=0 +lon_0=0 +x_0=0 +y_0=0 +k=1 +units=m +nadgrids=@null +wktext +no_defs source : memory names : X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, ... min values : -1.616e+01, -1.986e+01, -1.276e+01, -4.459e+00, 2.427e+00, 8.241e+00, 9.727e+00, 9.227e+00, 6.285e+00, 2.741e+00, -7.032e+00, -1.355e+01, -1.390e+01, -1.451e+01, -1.386e+01, ... max values : -1.390e+01, -1.801e+01, -9.526e+00, -6.056e-01, 5.500e+00, 1.180e+01, 1.300e+01, 1.170e+01, 8.700e+00, 5.300e+00, -4.000e+00, -1.060e+01, -1.180e+01, -1.270e+01, -1.000e+01, ... Notons que la fonction st_crs() nécessite la bibliothèque sf. Nous allons maintenant faire une opération de rognage sur mint en utilisant létendue spatiale suivante (dans le système géodésique mondial WGS84): longitude : de 71.5°Ouest à 71°Ouest, latitude : de 45°Nord à 45.5°Nord. mint_crop &lt;- crop(mint, extent(c(-71.5, -71, 45, 45.5))) Pour les deux opérations suivantes nous allons utiliser les contours du Parc national de Frontenac qui est le premier élément de lobjet parcs_sherbrooke manipulé au Module 8 et disponible dans le répertoire Module8_donnees. # importer le raster parcs parcs &lt;- st_read(&quot;Module8/Module8_donnees/parcs_sherbrooke&quot;) Reading layer `parcs_sherbrooke&#39; from data source `E:\\ELF\\Dropbox\\Teluq\\Enseignement\\Cours\\SCI1031\\Developpement\\Structure_test\\sci1031\\Module8\\Module8_donnees\\parcs_sherbrooke&#39; using driver `ESRI Shapefile&#39; Simple feature collection with 4 features and 18 fields Geometry type: MULTIPOLYGON Dimension: XY Bounding box: xmin: -323500 ymin: 151800 xmax: -201900 ymax: 226200 Projected CRS: NAD83 / Quebec Lambert Nous isolons dabord les contours du Parc national de Frontenac (parcs[1, ]) puis nous créons le shapefile frontenac en utilisant la projection de mint. Ensuite, nous utilisons la fonction mask() pour isoler les cellules de mint qui sont dans les limites du parc frontenac, et cela, pour toutes les couches de mint. # isoler le premier élément de `parcs`, et le convertir dans le CRS de `mint` frontenac &lt;- st_transform(parcs[1, ], st_crs(mint)) # appliquer un mask à `mint` mint_mask &lt;- mask(mint, frontenac) Enfin nous pouvons extraire les valeurs des cellules de mint qui sont à lintérieur des limites de frontenac en utilisant la fonction extract(). val_frontenac &lt;- extract(mint, frontenac) # la fonction extract retourne une liste, qui associe la valeur de mint à chaque cellule de chaque couche. # Par exemple, retournons les 10 premières lignes et les 5 premiers éléments de cette liste val_frontenac[[1]][1:10, 1:5] X1 X2 X3 X4 X5 [1,] -15.2 -19.1 -10.3 -1.8 4.7 [2,] -15.2 -19.1 -10.3 -1.9 4.6 [3,] -15.2 -19.1 -10.3 -1.9 4.6 [4,] -15.2 -19.0 -10.3 -1.8 4.7 [5,] -15.2 -19.1 -10.3 -1.9 4.7 [6,] -15.2 -19.1 -10.3 -1.9 4.6 [7,] -15.2 -19.1 -10.4 -1.9 4.6 [8,] -15.2 -19.1 -10.4 -1.9 4.6 [9,] -15.2 -19.0 -10.3 -1.8 4.8 [10,] -15.2 -19.0 -10.3 -1.8 4.7 Notons quici, cette opération aurait aussi pu être réalisée en utilisant getValues() sur mint_mask(). Visualiser des rasterStack Comme pour les objets rasters, nous pouvons rapidement visualiser les objets rasterStack avec la fonction plot(). plot(mint) Par défaut, 16 couches sont affichées au maximum. Toutefois, il est possible daugmenter ce nombre en modifiant la valeur de largument maxnl : plot(mint, maxnl = 25) Avec un grand nombre de cartes (au-delà de 10), il peut savérer difficile de visualiser correctement les données et il est parfois souhaitable de sélectionner les couches à inspecter. Par exemple, il est possible de visualiser les données des 4 derniers mois en sélectionnant les 4 dernières couches de mint. plot(mint[[117:120]]) Par défaut, le titre utilisé pour chaque carte correspond au nom des couches. Pour modifier les titres, nous pouvons renommer les couches en utilisant la fonction names(). Cela dit, il y a des contraintes sur les noms des couches (par exemple, les espaces blancs sont à éviter). Pour avoir un titre libre de ces contraintes, nous pouvons utiliser largument main dans la fonction plot() auquel nous donnons un vecteur contenant les titres souhaités. plot(mint[[117:120]], main = c(&quot;09/2016&quot;, &quot;10/2016&quot;, &quot;11/2016&quot;, &quot;12/2016&quot;)) La fonction mapview() peut aussi être utilisée pour visualiser les rasterStack (voir [Module 8][#mat]). Les différentes couches seront alors mises les unes par dessus les autres dans lordre donné (la dernière étant sur le dessus de la pile). Un trop grand nombre de couches rendra la carte difficile à interpréter. Comme mentionner précédemment, mieux vaut sélectionner un nombre limité de couches à visualiser. Ci-dessous, nous visualisons les trois premières couches. library(mapview) mapview(mint[[1:3]]) Remarquer que vous pouvez sélectionner laffichage de lune ou lautre des couches dans le menu apparaissant dans le coin gauche de la carte. Lien entre rasterStack et objets spatio-temporels Jusquici nous avons implicitement utilisé un objet rasterStack comme un objet spatio-temporel: chaque couche est bien un objet spatial (avec son étendue spatiale, sa projection, etc.) les couches sont ordonnées dans le temps. Il est cependant important dinsister sur le fait quun rasterStack ne contient pas nécessairement un objet spatio-temporel. La seule contrainte sur les couches contenues est spatiale: étendue, projection et résolution doivent être identiques. Ainsi, il est commun de travailler sur une même période avec des objets rasterStack qui contiennent différentes variables pour une période donnée (par exemple, la température, les précipitations, lélévation, etc.). Cela permet, entre autres, déviter la répétition des mêmes opérations sur plusieurs objets rasterLayer. Aussi, certaines données sont, par nature, multi-couches, cest le cas des données dimagerie satellitaire (on parle alors de bandes). Jusquici, nous navons pas formalisé lutilisation du temps, nous savons simplement à quoi correspondent les différentes couches. Cette information a été donnée dans le texte plus haut. Toutefois, dans un contexte de partage de données, cette information aurait été ajoutée dans les métadonnées (les données qui décrivent les données). Il existe cependant un moyen de formaliser un peu plus linformation qui ordonne les couches avec la fonction setZ()de la bibliothèque raster. Nous allons utiliser cette fonction pour associer une date à chacune des couches contenues dans le rasterStack. En premier lieu, créons une séquence de date mois/année, que nous appèlerons moan, en utilisant les fonctions R rep() et paste0(): # ci-dessous la séquence 1, 2..., 12 est répétée 10 fois (i.e. chacun des 12 mois pour chacune des 10 années) # et chacune des 10 années (2007, ..., 2016) est répétée consécutivement 12 fois moan &lt;- paste0(rep(1:12, 10), &quot;/&quot;, rep(2007:2016, each = 12)) moan[1:12] [1] &quot;1/2007&quot; &quot;2/2007&quot; &quot;3/2007&quot; &quot;4/2007&quot; &quot;5/2007&quot; [6] &quot;6/2007&quot; &quot;7/2007&quot; &quot;8/2007&quot; &quot;9/2007&quot; &quot;10/2007&quot; [11] &quot;11/2007&quot; &quot;12/2007&quot; Nous utilisons ensuite la fonction my() de la bibliothèque lubridate pour formaliser la séquence de temps. Cette fonction transformera la séquence de caractères moan en objet de classe date donnant le mois et lannée (ainsi que le jour, correspondant au premier du mois par défaut). library(lubridate) temps &lt;- my(moan) class(temps) [1] &quot;Date&quot; temps[1:12] [1] &quot;2007-01-01&quot; &quot;2007-02-01&quot; &quot;2007-03-01&quot; [4] &quot;2007-04-01&quot; &quot;2007-05-01&quot; &quot;2007-06-01&quot; [7] &quot;2007-07-01&quot; &quot;2007-08-01&quot; &quot;2007-09-01&quot; [10] &quot;2007-10-01&quot; &quot;2007-11-01&quot; &quot;2007-12-01&quot; Le vecteur temps que nous venons de créer correspond à la date associée à chaque couche de lobjet mint. Nous sommes alors en mesure dajouter cette information à mint en utilisant la fonction setZ(). Notons que la longueur de cette séquence doit correspondre au nombre de couches du rasterStack, soit nlayers(mint) dans le cas présent, sinon un message derreur sera retourné. mint &lt;- setZ(mint, temps, name = &quot;temps&quot;) mint class : RasterStack dimensions : 60, 60, 3600, 120 (nrow, ncol, ncell, nlayers) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs names : X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, ... min values : -16.2, -19.9, -12.8, -4.5, 2.4, 8.2, 9.7, 9.2, 6.3, 2.7, -7.1, -13.6, -13.9, -14.5, -13.9, ... max values : -13.9, -18.0, -9.5, -0.6, 5.5, 11.8, 13.0, 11.7, 8.7, 5.3, -4.0, -10.6, -11.8, -12.7, -10.0, ... temps : 2007-01-01 - 2016-12-01 (range) Nous pouvons constater quune ligne temps a été ajoutée, résumant cette nouvelle information. Ces données sont facilement accessibles avec getZ() qui nous retourne les valeurs de ce nouvel axe z. getZ(mint)[1:10] [1] &quot;2007-01-01&quot; &quot;2007-02-01&quot; &quot;2007-03-01&quot; [4] &quot;2007-04-01&quot; &quot;2007-05-01&quot; &quot;2007-06-01&quot; [7] &quot;2007-07-01&quot; &quot;2007-08-01&quot; &quot;2007-09-01&quot; [10] &quot;2007-10-01&quot; La couche mint pour une année donnée le long de cette axe de temps est accessible en utilisant [[. Par exemple, la première couche est : mint[[1]] class : RasterLayer band : 1 (of 120 bands) dimensions : 60, 60, 3600 (nrow, ncol, ncell) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs source : mint.nc names : X1 values : -16.2, -13.9 (min, max) temps : 2007-01-01 zvar : variable Il devient alors plus aisé de trier les couches sur la date. Par exemple, nous pouvons sélectionner toutes les couches de 2015 en utilisant year() de lubridate. mint[[which(year(getZ(mint)) == 2015)]] class : RasterStack dimensions : 60, 60, 3600, 12 (nrow, ncol, ncell, nlayers) resolution : 0.01667, 0.01667 (x, y) extent : -71.99, -70.99, 45.01, 46.01 (xmin, xmax, ymin, ymax) crs : +proj=longlat +ellps=WGS84 +no_defs names : X97, X98, X99, X100, X101, X102, X103, X104, X105, X106, X107, X108 min values : -20.4, -23.2, -15.5, -5.6, 4.8, 6.9, 10.6, 11.5, 8.6, -1.7, -4.0, -5.7 max values : -18.6, -22.0, -11.5, -1.3, 8.1, 10.4, 14.1, 15.0, 11.5, 1.1, -0.9, -1.8 temps : 2015-01-01, 2015-02-01, 2015-03-01, 2015-04-01, 2015-05-01, 2015-06-01, 2015-07-01, 2015-08-01, 2015-09-01, 2015-10-01, 2015-11-01, 2015-12-01 Rappelons ici que la fonction which() retourne les indices des éléments qui satisfont à la condition. 9.1.3.3 Mois de plus faible pluviométrie Nous sommes maintenant en mesure de répondre à la première question : Quel mois dispose du plus faible niveau de pluviométrie dans la région du Parc national du Mont-Mégantic? Pour ce faire, nous devons réaliser trois étapes : Isoler les cellules du rasterstack pcp qui correspondent à la zone du Parc national du Mont-Mégantic. Calculer la pluviométrie moyenne pour toutes les couches (cest-à-dire tous les mois). Déterminer le mois et lannée pour lequel la pluviométrie moyenne ainsi calculée est la plus faible. Commençons! 1. Cellules du Parc national du Mont-Mégantic Nous décidons de prendre les cellules de nos couches qui sont à lintérieur du Parc du Mont-Mégantic ainsi que les cellules qui sont proches du parc, dans un rayon de 5 km. Cette opération de buffer est très souvent utilisée pour augmenter la couverture spatiale et ainsi obtenir une moyenne climatique à une plus large échelle. Nous commençons donc par extraire les limites du parc de lobjet parcs et nous y ajoutons une zone tampon de 5 km. megantic &lt;- parcs[2, ] megantic_buf &lt;- st_buffer(megantic, dist = 5000) Ici dist = 5000, car les distances sont à exprimer en mètre, nous pouvons le savoir en regardant le champ units retourner par st_crs(). st_crs(parcs)$units [1] &quot;m&quot; Nous affichons maintenant, les deux objets : les limites du parc et les mêmes limites auxquelles une zone tampon de 5 km a été ajoutée. parc_buffer &lt;- mapview(megantic, col.regions = &quot;seagreen&quot;) + mapview(megantic_buf, col.regions = &quot;lightgreen&quot;) parc_buffer@map Nous allons maintenant appeler la fonction mask() de la bibliothèque raster pour extraire les cellules désirées du raster pcp (précipitations cumulées). Utiliser cette fonction nous permet de visualiser spatialement les données extraites, mais notons que nous aurions pu aussi utiliser la fonction extract() pour répondre à la question. pcp_megantic &lt;- mask(pcp, st_transform(megantic_buf, st_crs(pcp))) Notez également, que nous nous sommes assurés que le raster utilisé pour créer le masque soit dans le même système de coordonnées de référence que le rasterStack interrogé. Visualisons les quatres premières couches de pcp_megantic : plot(pcp_megantic[[1:4]]) Celles-ci correspondent aux précipitations cumulées dans la région autour du Parc national du Mont-Mégantic pour les quatre premiers mois répertoriés. 2. Calculer la pluviométrie moyenne pour toutes les couches Nous pouvons alors extraire les valeurs des différentes couches avec la fonction getValues() et faire la moyenne couche par couche (cest-à-dire mois par mois) en utilisant les fonctions R apply() et mean(), sans oublier denlever les valeurs non attribuées (NA). mean_pcp &lt;- apply(getValues(pcp_megantic), 2, mean, na.rm = TRUE) Rappelez-vous que largument 2 signifie que la fonction mean() est appliquée sur la deuxième dimension de la matrice getValues(pcp_megantic) (cest-à-dire la dimension associée aux couches). Utilisons le vecteur temps créé plus tôt pour visualisons le changement dans les précipitations cumulées moyennes en fonction du temps : plot(temps, mean_pcp) 3. Déterminer le mois de plus faible pluviométrie moyenne Nous sommes maintenant en mesure de chercher le minimum de ces moyennes. min(mean_pcp) [1] 39.81 Cette valeur correspond à la plus faible pluviométrie moyenne. Pour quel mois cette valeur a-t-elle été enregistrée? which.min(mean_pcp) X71 71 temps[which.min(mean_pcp)] [1] &quot;2012-11-01&quot; # ou encore getZ(mint)[which.min(mean_pcp)] [1] &quot;2012-11-01&quot; Cest la couche 71 qui présente la plus faible valeur moyenne des précipitations totales, cette couche correspond au mois de novembre 2012. 9.1.3.4 Points les plus chauds Nous allons maintenant répondre à la deuxième question : Où se situe le (ou les) point(s) le(s) plus chaud(s) dans la région du Parc national du Mont-Mégantic? Pour ce faire, nous allons réaliser deux étapes : Isoler les cellules de maxt qui correspondent à la zone du parc du Mont-Mégantic. Trouver la ou les cellules pour laquelle cette valeur est maximale. Commençons! 1. Cellules du Parc national du Mont-Mégantic Pour répondre à cette question, nous utilisons seulement les cellules contenues dans les limites du Parc national du Mont-Mégantic. Ainsi, nous najouterons pas de zone tampon autour du parc. Nous appliquons la fonction mask() au rasterStack maxt qui contient les températures maximales moyennes en utilisant les limites du parc. Comme nous avons déjà réalisé des opérations de mask() à plusieurs reprises, nous allons faire cette première étape à laide dune seule ligne de commande. maxt_megantic &lt;- mask(maxt, st_transform(megantic, st_crs(maxt))) 2. Cellules de température maximale Pour la seconde étape, il y a plusieurs façons de procéder. Ici, nous allons procéder en deux temps : nous allons dabord trouver la couche (ou les couches) qui contient (ou contiennent) la valeur de température maximale, puis trouver les coordonnées du point (ou des points) associées. Nous calculons donc le maximum pour chaque couche, puis nous déterminons quel est le maximum de ces maxima. id &lt;- which.max(apply(getValues(maxt_megantic), 2, max, na.rm = TRUE)) id X43 43 Notez que la fonction apply() calcule le maximum pour chacune des couches contenues dans maxt_megantic, alors que le fonction which.max() détermine lindice de la couche qui contient le maximum de ces maxima. Cest donc la couche 43 qui contient ce maximum. Nous pouvons également déterminer que cest au mois de juillet 2010 que ce maximum a été atteint : temps[id] [1] &quot;2010-07-01&quot; et que cette température était de 24.7°C : max(apply(getValues(maxt_megantic), 2, max, na.rm = TRUE)) [1] 24.7 Utilisons maintenant la fonction xyFromCell() de la bibliothèque raster pour déterminer les coordonnées spatiales auxquelles cette température a été enregistrée. xyFromCell(maxt_megantic[[id]], which.max(maxt_megantic[[id]])) x y [1,] -71.22 45.48 [2,] -71.20 45.42 [3,] -71.18 45.42 Rappelons que la fonction xyFromCell(A,id) détermine les coordonnées (x,y) de la cellule dun raster A dont lindice est id. Ainsi, dans la ligne de code précédente, le premier argument de la fonction xyFromCell() correspond au raster au sein duquel on recherche les coordonnées (x,y). Dans le cas présent, ce raster est la couche 43 du rasterStack maxt_megantic. Le deuxième argument correspond à lindice de la ou des cellules qui contiennent le maximum. Ainsi, la température maximale a été enregistrée sur trois cellules à lintérieur du parc. 9.1.3.5 Profils de temperatures et de precipitations Nous allons maintenant réaliser des profils de températures et de précipitations. Ces profils correspondent à lévolution temporelle des températures (maximales et minimales) et des précipitations moyennes. Plus précisément, nous cherchons à créer des graphiques où lordonnée correspondra à lune des trois valeurs environnementales moyennes et labscisse au temps, selon une résolution mensuelle. Pour réaliser ces profils, nous allons faire une moyenne pour chaque couche des valeurs puis les afficher en fonction du temps. Nous allons répéter trois fois la même opération ici (une fois pour chaque rasterStack: maxt.nc, mint.nc et pcp.nc). Au lieu de copier/coller notre code pour les trois sources de données, nous allons créer une fonction profil(). Cette fonction prend en intrant ras, un objet rasterLayer ou rasterStack et masque, lobjet spatial qui sera utilisé pour découper le raster. profil &lt;- function(ras, masque) { # l&#39;argument masque doit utiliser le même SCR que ras masque_crs &lt;- st_transform(masque, st_crs(ras)) # extraire les valeurs de ras au sein du masque ainsi créé ras_extract &lt;- extract(ras, masque_crs)[[1]] # notons que la fonction `extract()` permet de faire des extractions # pour plusieurs polygones, ici masque_crs n&#39;aura qu&#39;un seul polygon et nous # utilisons donc que le premier élément de la liste retournée par `extract()` # calculer la moyenne pour chaque couche apply(ras_extract, 2, mean, na.rm = TRUE) } Cette fonction nous permet donc dobtenir les valeurs environnementales moyennes à mettre en ordonnées de nos profils. Il nous reste à obtenir les valeurs des abscisses, autrement dit les dates pour chacune des moyennes. Comme les dates sont les mêmes pour mint, maxt et pcp, nous utilisons getZ(mint) qui nous donne exactement ce dont nous avons besoin. Notez que nous pouvons également utiliser le vecteur temps créé plus tôt. Nous allons maintenant créer la figure. Celle-ci contiendra trois panneaux. Chaque panneau appelle la fonction profil() que nous venons de créer avec en argument lune ou lautre des variables environnementales (mint, maxt et pcp) ainsi que le raster correspondant aux frontières élargies du Parc national du Mont-Mégantic,megantic_buf. Pour illustrer les températures, nous utilisons des lignes et pour les précipitations nous utilisons des barres, ces réglages peuvent se faire avec largument type de la fonction plot(). Enfin comme laxe des abscisses est identique pour les trois panneaux, nous ajoutons un titre seulement à cet axe, donc seulement pour le dernier panneau. # figures de trois lignes et 1 seule colonne par(mfrow = c(3, 1), mar = c(4, 4, 1, 1)) plot(getZ(mint), profil(mint, megantic_buf), type = &quot;l&quot;, ylab = &quot;Températures minimales (°C)&quot;, xlab = &quot;&quot;) plot(getZ(mint), profil(maxt, megantic_buf), type = &quot;l&quot;, ylab = &quot;Températures maximales (°C)&quot;, xlab = &quot;&quot;) plot(getZ(mint), profil(pcp, megantic_buf), type = &quot;h&quot;, ylab = &quot;Précipitations totales (mm)&quot;, xlab = &quot;Années&quot;) Ces profils, séchelonnant sur plusieurs années, nous permettent dobserver la périodicité annuelle des variables environnementales illustrées. 9.1.3.6 Animations Pour finir, nous allons animer les profils que nous venons de dessiner. Ici, au lieu dappeler la fonction profil() dans la fonction plot(), comme fait précédemment, nous calculons les profils des trois variables environnementales (mint, maxt et pcp) en amont. Cela permet de gagner du temps de calcul. pr_mint &lt;- profil(mint, megantic_buf) pr_maxt &lt;- profil(maxt, megantic_buf) pr_pcp &lt;- profil(pcp, megantic_buf) Nous allons maintenant créer une nouvelle fonction, plot_profil(), pour produire une figure affichant les profils des trois variables dintérêt pour un nombre donné de mois. Cette fonction prend en entrée cinq arguments : n, le nombre de mois pour lequel nous voulons afficher les profils, les trois profils des variables environnementales dintérêt (pr_mint, pr_maxt et pr_pcp), et la variable temporelle temps. De plus, nous voulons améliorer quelque peu le rendu visuel obtenu avec la fonction plot(). Tout dabord, nous souhaitons utiliser les températures minimales et maximales moyennes pour créer une envelope de températures. Cela est possible en faisant appel à la fonction polygon(). Attention, la fonction polygon() nest pas liée à la fonction st_polygon()! La fonction polygon(x,y,...) dessine un polygone dont les coordonnées des sommets sont données par les vecteurs x et y. Par exemple : # soit les vecteurs x et y des sommets du polygone x &lt;- c(1:6,5:1) y &lt;- c(2,2,2,3,3,3,4,4,4,5,5) # tracer le polygone de couleur rose délimité par une ligne rouge plot(c(1,6),c(1,5), type = &quot;n&quot;) polygon(x, y, col = &quot;pink&quot;, lty = 2, lwd = 2, border = &quot;red&quot;) Deux remarques méritent dêtre mentionnées : Un polygone est une figure fermée. Le premier et le dernier sommets sont donc joints. largument type = \"n\" dans la fonction plot() permet de créer une figure vide (dans laquelle on ajoute le polygone). Ainsi, pour créer une enveloppe, nous définissions les sommets du polygone en utilisant la variable temporelle temps pour définir les coordonnées en x, et les profils pr_mintet pr_maxt pour définir les coordonnées en y. De plus, toujours dans lobjectif daméliorer le rendu visuel de la figure, nous ajoutons les valeurs de précipitations sur la même figure que celle des températures. La fonction plot_profil() prend la forme suivante : plot_profil &lt;- function(n, pr_mint, pr_maxt, pr_pcp, temps) { # Créer un vecteur allant de 1 à n id &lt;- seq_len(n) # Premier affichage sur la figure: les temperatures # definition des paramètres (par) de ce premier graphique: # les marges (mar) et le style d&#39;écriture horizontal sur les axes (las = 1) par(mar = c(4, 4.5, 1, 4.5), las = 1) # créer une figure vide (type = &quot;n&quot;) # dont la limite des axes est définie par les températures minimale et maximale plot(range(temps), c(min(pr_mint), max(pr_maxt)), type = &quot;n&quot;, xlab = &quot;Années&quot;, ylab = &quot;Températures minimales et maximales (°C)&quot;) # créer une enveloppe polygon(c(temps[id], rev(temps[id])), c(pr_mint[id], pr_maxt[rev(id)]), col = &quot;#aaaaaa&quot;, border = &quot;#6a6a6a&quot;) # Deuxième affichage sur la figure: les précipitations # permettre de recommencer à dessiner sur la figure par(new = TRUE) # créer une figure vide (type = &quot;n&quot;) # dont la limite des axes est définie par l&#39;étendue des valeurs de temps et de précipitations # sans ajout d&#39;axes (axes), et sans annotation sur les axes (ann) plot(range(temps), range(pr_pcp), type = &quot;n&quot;, axes = FALSE, ann = FALSE) # ajouter des points pour chaque valeur du vecteur id points(temps[id], pr_pcp[id], type = &quot;h&quot;, col = &quot;#c62b63&quot;, lwd = 2) # ajout d&#39;un axe à droite axis(4) # ajouts d&#39;un texte à droite mtext(&quot;Précipitations totales (mm)&quot;, side = 4, line = 3, las = 0, col = &quot;#c62b63&quot;) # Ajouter le mois en bas a gauche de la figure mtext(temps[n], side = 1, line = 2.5, at = as.Date(&quot;2007-01-01&quot;),cex = 1.4) } Nous devons maintenant passer les profils calculés précédemment à la fonction plot_profil() pour les afficher. Par exemple, pour visualiser les profils pour les 40 premiers mois, nous utilisons la valeur 40 pour n. plot_profil(40, pr_mint, pr_maxt, pr_pcp, temps) Finalement, nous utilisons la fonction saveGIF() de la bibliothèque animation, pour enregistrée une séquence de figures produites avec plot_profil() en faisant évoluer le nombre de mois : library(animation) saveGIF({ # nous générons une figure par trimestre en commençant au mois de mars for (i in seq(3, 120, by = 3)) plot_profil(i, pr_mint, pr_maxt, pr_pcp, temps) }, movie.name = &quot;anim3.gif&quot;, ani.height = 400, ani.width = 600) "],["ex_spatiotemp.html", "9.2 Exercice", " 9.2 Exercice Dans cette section, vous mettrez en pratique certains concepts vus dans la section leçon de ce module. Bien que la réponse à chaque question soit disponible, il est très important de tenter dy répondre par vous même! Question 1 Créer une animation de la carte des températures minimums pour les 12 premiers mois de lannée 2007. Votre animation doit avoir les caractéristiques suivantes : Couvrir seulement la région allant de 71.4°Ouest à 71°Ouest, en longitude, et de 45°Nord à 45.4°Nord en latitude dans le dans le système géodésique mondial WGS84. Comprendre légende affichant les températures de -24 C à +24 C par bond de 2 C. Afficher la légende à droite de la carte. Utiliser une palette de couleurs allant dune couleur froide pour les températeurs négatives vers une couleur chaude pour les températures négatives. Avoir un titre qui comprend le mois (en français) et lannée. Être construite avec la bibliothèque tmap. Réponse Pour commencer, il nous faut sélectionner la région demandée de mint en utilisant la fonction crop(). Nous savons que ce rasterStack utilise le système WGS84, nous navons donc pas à changer le SCR. region &lt;- extent(c(-71.5, -71, 45, 45.4)) mint_region &lt;- crop(mint,region) Ensuite, construisons une fonction pour afficher une seule couche du rasterStack mint_region avec les caractéristiques demandées. Définission dabord les éléments propres à la légende, aux couleurs, et au titre. # Légende allant de -24 à 24 par pas de 2. L &lt;- seq(-24, 24, by = 2) # Palette de couleurs allant de froid à chaud # Par exemple de bleu à rouge en passant par gris Pal &lt;- colorRampPalette( c(&quot;blue&quot;,&quot;grey&quot;, &quot;red&quot;)) # On assigne une couleur à chaque élément de la légende Coul &lt;- Pal(length(L)) # On peut également assigner des noms à chaque élément. # Par défaut, chaque élément aura la forme : &quot;-24 to -22&quot; noms &lt;- c(L[1:12], L[14:25]) noms &lt;- as.character(noms) # On se souvient que les dates associées à chacune des couches de mint # sont données par le vecteur `temps` # ainsi, la bibliothèque lubridate nous permet de connaitre # l&#39;année year(temps[1:12]) [1] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 [11] 2007 2007 # et le mois month(temps[1:12]) [1] 1 2 3 4 5 6 7 8 9 10 11 12 # qu&#39;on peut écrire en français FR &lt;- c(&quot;janvier&quot;, &quot;février&quot;, &quot;mars&quot;,&quot;avril&quot;,&quot;mai&quot;, &quot;juin&quot;, &quot;juillet&quot;, &quot;août&quot;, &quot;septembre&quot;, &quot;octobre&quot;, &quot;novembre&quot;, &quot;décembre&quot;) FR[month(temps[1:12])] [1] &quot;janvier&quot; &quot;février&quot; &quot;mars&quot; &quot;avril&quot; [5] &quot;mai&quot; &quot;juin&quot; &quot;juillet&quot; &quot;août&quot; [9] &quot;septembre&quot; &quot;octobre&quot; &quot;novembre&quot; &quot;décembre&quot; Créons maintenant la fonction pour afficher un seul mois. # La fonction comprend 2 arguments: # - RS, le rasterStack # - t, le mois library(tmap) fct_carte &lt;- function(RS,t){ tm_shape(RS[[t]])+ #couche correspondant au mois t tm_raster(palette=Coul, title = &quot;&quot;, #pas de titre pour la légende breaks = L, labels=noms, legend.is.portrait = TRUE, legend.reverse = TRUE) + #assure que les T négatives sont au bas de la légende tm_layout(main.title = paste0(&quot;Températures minimales (°C) - &quot;,FR[month(temps[t])],&quot; &quot;,year(temps[t])), main.title.size = 0.9, legend.outside = TRUE, legend.outside.position = &quot;right&quot;, legend.text.size = 0.8, legend.format = list(text.align = &quot;right&quot;)) } Par exemple, pour le premier mois, cette fonction affiche  : # Par exemple cette fonction donne fct_carte(mint_region,3) Nous devons à présent créer une fonction qui répètera laffichage de la carte pour tous les mois souhaités. # Cette fonction compte encore deux arguments: # - RS, le rasterStack # - T, le nombre de mois anim_carte &lt;- function(RS, T){ for(i in 1:T){ print(fct_carte(RS,i)) } } Pour les douzes premiers mois, cette fonction affichera la séquence suivante: anim_carte(mint_region,12) Vous pouvez également sauvegarder cette animation en exécutant cette ligne de commande : saveGIF(anim_carte(mint_region, 12), movie.name = &quot;anim_mint.gif&quot;, ani.height = 500, ani.width = 500) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
